{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "\n",
    "seed(1)\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(1)\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor \n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df=pd.read_excel('Pre-Processed-Data.xlsx')\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Dew Point  Wind Speed  Pressure  Pressure Grad\n",
       "0        4.8        2.47    1029.0             -8\n",
       "1        8.2        7.42    1021.4              0\n",
       "2        6.8        6.81    1021.8             11\n",
       "3        3.6        3.94    1033.7             -1\n",
       "4        6.1        3.33    1033.4            -11"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dew Point</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Pressure Grad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.8</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.2</td>\n",
       "      <td>7.42</td>\n",
       "      <td>1021.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8</td>\n",
       "      <td>6.81</td>\n",
       "      <td>1021.8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.6</td>\n",
       "      <td>3.94</td>\n",
       "      <td>1033.7</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.33</td>\n",
       "      <td>1033.4</td>\n",
       "      <td>-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df.isnull().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Dew Point        0\n",
       "Wind Speed       0\n",
       "Pressure         0\n",
       "Pressure Grad    0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "X = df.drop(['Wind Speed'], axis=1)\n",
    "#Assign the Target column as the output \n",
    "Y= df['Wind Speed']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "X_norm=(X-X.min())/(X.max()-X.min())\n",
    "X_norm"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Dew Point  Pressure  Pressure Grad\n",
       "0      0.487805  0.752055       0.449275\n",
       "1      0.606272  0.647945       0.565217\n",
       "2      0.557491  0.653425       0.724638\n",
       "3      0.445993  0.816438       0.550725\n",
       "4      0.533101  0.812329       0.405797\n",
       "...         ...       ...            ...\n",
       "1091   0.411150  0.706849       0.623188\n",
       "1092   0.470383  0.767123       0.594203\n",
       "1093   0.595819  0.795890       0.594203\n",
       "1094   0.564460  0.831507       0.565217\n",
       "1095   0.581882  0.836986       0.594203\n",
       "\n",
       "[1096 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dew Point</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Pressure Grad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.752055</td>\n",
       "      <td>0.449275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.606272</td>\n",
       "      <td>0.647945</td>\n",
       "      <td>0.565217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.557491</td>\n",
       "      <td>0.653425</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.445993</td>\n",
       "      <td>0.816438</td>\n",
       "      <td>0.550725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.533101</td>\n",
       "      <td>0.812329</td>\n",
       "      <td>0.405797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>0.411150</td>\n",
       "      <td>0.706849</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>0.470383</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.594203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>0.595819</td>\n",
       "      <td>0.795890</td>\n",
       "      <td>0.594203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>0.564460</td>\n",
       "      <td>0.831507</td>\n",
       "      <td>0.565217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>0.581882</td>\n",
       "      <td>0.836986</td>\n",
       "      <td>0.594203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1096 rows Ã— 3 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_norm, Y, test_size=0.2, random_state=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(45, input_dim=x_train.shape[1], activation=\"sigmoid\", kernel_initializer='normal'))\n",
    "model.add(Dropout(0.2)) #dropping a few neurons for generalizing the model\n",
    "\n",
    "model.add(Dense(1, activation=\"linear\", kernel_initializer='normal'))\n",
    "adam = Adam(learning_rate=1e-3, decay=1e-3)\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss=\"mean_squared_error\", optimizer='adam', metrics=['mse','mae'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print('Fit model...')\n",
    "filepath=\"/home/m-marouni/Documents/CE-901/Heathrow/best_weights\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_mae', verbose=1, save_best_only=True, mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_mae', patience=100, verbose=1, mode='min')\n",
    "callbacks_list = [checkpoint, early_stopping]\n",
    "\n",
    "log = model.fit(x_train, y_train,\n",
    "          validation_split=0.40, batch_size=30, epochs=1000, shuffle=True, callbacks=callbacks_list)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fit model...\n",
      "Epoch 1/1000\n",
      "18/18 [==============================] - 11s 40ms/step - loss: 42.6596 - mse: 42.6596 - mae: 5.9856 - val_loss: 34.7731 - val_mse: 34.7731 - val_mae: 5.3934\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 5.39338, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 37.1223 - mse: 37.1223 - mae: 5.5029 - val_loss: 30.3173 - val_mse: 30.3173 - val_mae: 4.9630\n",
      "\n",
      "Epoch 00002: val_mae improved from 5.39338 to 4.96295, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 33.4373 - mse: 33.4373 - mae: 5.1202 - val_loss: 26.2239 - val_mse: 26.2239 - val_mae: 4.5317\n",
      "\n",
      "Epoch 00003: val_mae improved from 4.96295 to 4.53174, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 28.4421 - mse: 28.4421 - mae: 4.6558 - val_loss: 22.4950 - val_mse: 22.4950 - val_mae: 4.1016\n",
      "\n",
      "Epoch 00004: val_mae improved from 4.53174 to 4.10157, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 24.8496 - mse: 24.8496 - mae: 4.2307 - val_loss: 19.0773 - val_mse: 19.0773 - val_mae: 3.6658\n",
      "\n",
      "Epoch 00005: val_mae improved from 4.10157 to 3.66575, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 22.5302 - mse: 22.5302 - mae: 3.8677 - val_loss: 16.0930 - val_mse: 16.0930 - val_mae: 3.2474\n",
      "\n",
      "Epoch 00006: val_mae improved from 3.66575 to 3.24739, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 17.5501 - mse: 17.5501 - mae: 3.3816 - val_loss: 13.5125 - val_mse: 13.5125 - val_mae: 2.8675\n",
      "\n",
      "Epoch 00007: val_mae improved from 3.24739 to 2.86753, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 15.3149 - mse: 15.3149 - mae: 2.9754 - val_loss: 11.3670 - val_mse: 11.3670 - val_mae: 2.5614\n",
      "\n",
      "Epoch 00008: val_mae improved from 2.86753 to 2.56136, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 13.7140 - mse: 13.7140 - mae: 2.7542 - val_loss: 9.6445 - val_mse: 9.6445 - val_mae: 2.3291\n",
      "\n",
      "Epoch 00009: val_mae improved from 2.56136 to 2.32915, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 11.3240 - mse: 11.3240 - mae: 2.4172 - val_loss: 8.3275 - val_mse: 8.3275 - val_mae: 2.1629\n",
      "\n",
      "Epoch 00010: val_mae improved from 2.32915 to 2.16289, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.2679 - mse: 9.2679 - mae: 2.2211 - val_loss: 7.3916 - val_mse: 7.3916 - val_mae: 2.0519\n",
      "\n",
      "Epoch 00011: val_mae improved from 2.16289 to 2.05186, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.3585 - mse: 8.3585 - mae: 2.1014 - val_loss: 6.7463 - val_mse: 6.7463 - val_mae: 1.9828\n",
      "\n",
      "Epoch 00012: val_mae improved from 2.05186 to 1.98278, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1539 - mse: 8.1539 - mae: 2.1388 - val_loss: 6.3089 - val_mse: 6.3089 - val_mae: 1.9410\n",
      "\n",
      "Epoch 00013: val_mae improved from 1.98278 to 1.94100, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.1165 - mse: 8.1165 - mae: 2.1602 - val_loss: 6.0628 - val_mse: 6.0628 - val_mae: 1.9315\n",
      "\n",
      "Epoch 00014: val_mae improved from 1.94100 to 1.93153, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.9700 - mse: 7.9700 - mae: 2.1360 - val_loss: 5.9209 - val_mse: 5.9209 - val_mae: 1.9317\n",
      "\n",
      "Epoch 00015: val_mae did not improve from 1.93153\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9559 - mse: 6.9559 - mae: 2.0743 - val_loss: 5.8421 - val_mse: 5.8421 - val_mae: 1.9364\n",
      "\n",
      "Epoch 00016: val_mae did not improve from 1.93153\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.6618 - mse: 7.6618 - mae: 2.1330 - val_loss: 5.8092 - val_mse: 5.8092 - val_mae: 1.9437\n",
      "\n",
      "Epoch 00017: val_mae did not improve from 1.93153\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9120 - mse: 6.9120 - mae: 2.0390 - val_loss: 5.8011 - val_mse: 5.8011 - val_mae: 1.9493\n",
      "\n",
      "Epoch 00018: val_mae did not improve from 1.93153\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4373 - mse: 6.4373 - mae: 2.0348 - val_loss: 5.8030 - val_mse: 5.8030 - val_mae: 1.9572\n",
      "\n",
      "Epoch 00019: val_mae did not improve from 1.93153\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.5606 - mse: 6.5606 - mae: 1.9775 - val_loss: 5.8085 - val_mse: 5.8085 - val_mae: 1.9621\n",
      "\n",
      "Epoch 00020: val_mae did not improve from 1.93153\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5201 - mse: 6.5201 - mae: 2.0499 - val_loss: 5.8154 - val_mse: 5.8154 - val_mae: 1.9663\n",
      "\n",
      "Epoch 00021: val_mae did not improve from 1.93153\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6370 - mse: 6.6370 - mae: 2.0390 - val_loss: 5.8198 - val_mse: 5.8198 - val_mae: 1.9690\n",
      "\n",
      "Epoch 00022: val_mae did not improve from 1.93153\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1096 - mse: 7.1096 - mae: 2.1322 - val_loss: 5.8205 - val_mse: 5.8205 - val_mae: 1.9700\n",
      "\n",
      "Epoch 00023: val_mae did not improve from 1.93153\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6198 - mse: 6.6198 - mae: 2.0381 - val_loss: 5.8120 - val_mse: 5.8120 - val_mae: 1.9670\n",
      "\n",
      "Epoch 00024: val_mae did not improve from 1.93153\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.1069 - mse: 8.1069 - mae: 2.2775 - val_loss: 5.8171 - val_mse: 5.8171 - val_mae: 1.9698\n",
      "\n",
      "Epoch 00025: val_mae did not improve from 1.93153\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.7193 - mse: 7.7193 - mae: 2.2270 - val_loss: 5.8157 - val_mse: 5.8157 - val_mae: 1.9700\n",
      "\n",
      "Epoch 00026: val_mae did not improve from 1.93153\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.0307 - mse: 7.0307 - mae: 2.1275 - val_loss: 5.8073 - val_mse: 5.8073 - val_mae: 1.9671\n",
      "\n",
      "Epoch 00027: val_mae did not improve from 1.93153\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.5269 - mse: 6.5269 - mae: 2.0673 - val_loss: 5.8002 - val_mse: 5.8002 - val_mae: 1.9647\n",
      "\n",
      "Epoch 00028: val_mae did not improve from 1.93153\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.8216 - mse: 6.8216 - mae: 2.0699 - val_loss: 5.7956 - val_mse: 5.7956 - val_mae: 1.9634\n",
      "\n",
      "Epoch 00029: val_mae did not improve from 1.93153\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.8006 - mse: 6.8006 - mae: 2.0921 - val_loss: 5.8008 - val_mse: 5.8008 - val_mae: 1.9665\n",
      "\n",
      "Epoch 00030: val_mae did not improve from 1.93153\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5986 - mse: 6.5986 - mae: 2.0649 - val_loss: 5.7964 - val_mse: 5.7964 - val_mae: 1.9653\n",
      "\n",
      "Epoch 00031: val_mae did not improve from 1.93153\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.3336 - mse: 6.3336 - mae: 2.0360 - val_loss: 5.7902 - val_mse: 5.7902 - val_mae: 1.9634\n",
      "\n",
      "Epoch 00032: val_mae did not improve from 1.93153\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.6754 - mse: 6.6754 - mae: 2.1112 - val_loss: 5.7908 - val_mse: 5.7908 - val_mae: 1.9644\n",
      "\n",
      "Epoch 00033: val_mae did not improve from 1.93153\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4016 - mse: 6.4016 - mae: 2.0589 - val_loss: 5.7893 - val_mse: 5.7893 - val_mae: 1.9647\n",
      "\n",
      "Epoch 00034: val_mae did not improve from 1.93153\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.7449 - mse: 6.7449 - mae: 2.0850 - val_loss: 5.7839 - val_mse: 5.7839 - val_mae: 1.9632\n",
      "\n",
      "Epoch 00035: val_mae did not improve from 1.93153\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.0975 - mse: 7.0975 - mae: 2.1124 - val_loss: 5.7849 - val_mse: 5.7849 - val_mae: 1.9644\n",
      "\n",
      "Epoch 00036: val_mae did not improve from 1.93153\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.5296 - mse: 7.5296 - mae: 2.2163 - val_loss: 5.7821 - val_mse: 5.7821 - val_mae: 1.9641\n",
      "\n",
      "Epoch 00037: val_mae did not improve from 1.93153\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.8529 - mse: 6.8529 - mae: 2.0890 - val_loss: 5.7826 - val_mse: 5.7826 - val_mae: 1.9650\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 1.93153\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3516 - mse: 6.3516 - mae: 2.0076 - val_loss: 5.7903 - val_mse: 5.7903 - val_mae: 1.9689\n",
      "\n",
      "Epoch 00039: val_mae did not improve from 1.93153\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5810 - mse: 6.5810 - mae: 2.0744 - val_loss: 5.7885 - val_mse: 5.7885 - val_mae: 1.9689\n",
      "\n",
      "Epoch 00040: val_mae did not improve from 1.93153\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.4097 - mse: 7.4097 - mae: 2.1852 - val_loss: 5.7759 - val_mse: 5.7759 - val_mae: 1.9647\n",
      "\n",
      "Epoch 00041: val_mae did not improve from 1.93153\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.7849 - mse: 6.7849 - mae: 2.0406 - val_loss: 5.7840 - val_mse: 5.7840 - val_mae: 1.9687\n",
      "\n",
      "Epoch 00042: val_mae did not improve from 1.93153\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4864 - mse: 6.4864 - mae: 2.0420 - val_loss: 5.7633 - val_mse: 5.7633 - val_mae: 1.9610\n",
      "\n",
      "Epoch 00043: val_mae did not improve from 1.93153\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.6042 - mse: 7.6042 - mae: 2.2611 - val_loss: 5.7595 - val_mse: 5.7595 - val_mae: 1.9603\n",
      "\n",
      "Epoch 00044: val_mae did not improve from 1.93153\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.5145 - mse: 6.5145 - mae: 2.0784 - val_loss: 5.7449 - val_mse: 5.7449 - val_mae: 1.9549\n",
      "\n",
      "Epoch 00045: val_mae did not improve from 1.93153\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.9949 - mse: 6.9949 - mae: 2.1202 - val_loss: 5.7530 - val_mse: 5.7530 - val_mae: 1.9594\n",
      "\n",
      "Epoch 00046: val_mae did not improve from 1.93153\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6758 - mse: 6.6758 - mae: 2.0344 - val_loss: 5.7486 - val_mse: 5.7486 - val_mae: 1.9584\n",
      "\n",
      "Epoch 00047: val_mae did not improve from 1.93153\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.2862 - mse: 7.2862 - mae: 2.1455 - val_loss: 5.7343 - val_mse: 5.7343 - val_mae: 1.9531\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 1.93153\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.4420 - mse: 7.4420 - mae: 2.1210 - val_loss: 5.7420 - val_mse: 5.7420 - val_mae: 1.9574\n",
      "\n",
      "Epoch 00049: val_mae did not improve from 1.93153\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.0022 - mse: 7.0022 - mae: 2.1176 - val_loss: 5.7336 - val_mse: 5.7336 - val_mae: 1.9546\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 1.93153\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6271 - mse: 6.6271 - mae: 2.0162 - val_loss: 5.7430 - val_mse: 5.7430 - val_mae: 1.9598\n",
      "\n",
      "Epoch 00051: val_mae did not improve from 1.93153\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.4764 - mse: 7.4764 - mae: 2.2065 - val_loss: 5.7309 - val_mse: 5.7309 - val_mae: 1.9556\n",
      "\n",
      "Epoch 00052: val_mae did not improve from 1.93153\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.0266 - mse: 7.0266 - mae: 2.1263 - val_loss: 5.7327 - val_mse: 5.7327 - val_mae: 1.9573\n",
      "\n",
      "Epoch 00053: val_mae did not improve from 1.93153\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7124 - mse: 6.7124 - mae: 2.0636 - val_loss: 5.7203 - val_mse: 5.7203 - val_mae: 1.9529\n",
      "\n",
      "Epoch 00054: val_mae did not improve from 1.93153\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7941 - mse: 6.7941 - mae: 2.0933 - val_loss: 5.7089 - val_mse: 5.7089 - val_mae: 1.9489\n",
      "\n",
      "Epoch 00055: val_mae did not improve from 1.93153\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6829 - mse: 6.6829 - mae: 2.0644 - val_loss: 5.7130 - val_mse: 5.7130 - val_mae: 1.9518\n",
      "\n",
      "Epoch 00056: val_mae did not improve from 1.93153\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.2425 - mse: 7.2425 - mae: 2.1414 - val_loss: 5.7091 - val_mse: 5.7091 - val_mae: 1.9511\n",
      "\n",
      "Epoch 00057: val_mae did not improve from 1.93153\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.2103 - mse: 7.2103 - mae: 2.1378 - val_loss: 5.7030 - val_mse: 5.7030 - val_mae: 1.9495\n",
      "\n",
      "Epoch 00058: val_mae did not improve from 1.93153\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.1926 - mse: 7.1926 - mae: 2.1734 - val_loss: 5.7035 - val_mse: 5.7035 - val_mae: 1.9508\n",
      "\n",
      "Epoch 00059: val_mae did not improve from 1.93153\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2527 - mse: 6.2527 - mae: 2.0126 - val_loss: 5.7003 - val_mse: 5.7003 - val_mae: 1.9504\n",
      "\n",
      "Epoch 00060: val_mae did not improve from 1.93153\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4626 - mse: 6.4626 - mae: 1.9972 - val_loss: 5.6834 - val_mse: 5.6834 - val_mae: 1.9439\n",
      "\n",
      "Epoch 00061: val_mae did not improve from 1.93153\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.8304 - mse: 6.8304 - mae: 2.0762 - val_loss: 5.6932 - val_mse: 5.6932 - val_mae: 1.9495\n",
      "\n",
      "Epoch 00062: val_mae did not improve from 1.93153\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5324 - mse: 6.5324 - mae: 2.0299 - val_loss: 5.6982 - val_mse: 5.6982 - val_mae: 1.9528\n",
      "\n",
      "Epoch 00063: val_mae did not improve from 1.93153\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.0707 - mse: 7.0707 - mae: 2.0832 - val_loss: 5.6894 - val_mse: 5.6894 - val_mae: 1.9502\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 1.93153\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1291 - mse: 8.1291 - mae: 2.2003 - val_loss: 5.6781 - val_mse: 5.6781 - val_mae: 1.9464\n",
      "\n",
      "Epoch 00065: val_mae did not improve from 1.93153\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.9158 - mse: 6.9158 - mae: 2.0595 - val_loss: 5.6687 - val_mse: 5.6687 - val_mae: 1.9434\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 1.93153\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.5562 - mse: 6.5562 - mae: 2.0684 - val_loss: 5.6599 - val_mse: 5.6599 - val_mae: 1.9405\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 1.93153\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 7.0741 - mse: 7.0741 - mae: 2.0943 - val_loss: 5.6692 - val_mse: 5.6692 - val_mae: 1.9459\n",
      "\n",
      "Epoch 00068: val_mae did not improve from 1.93153\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6871 - mse: 6.6871 - mae: 2.0561 - val_loss: 5.6702 - val_mse: 5.6702 - val_mae: 1.9475\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 1.93153\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6804 - mse: 6.6804 - mae: 2.0926 - val_loss: 5.6678 - val_mse: 5.6678 - val_mae: 1.9475\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 1.93153\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.1833 - mse: 7.1833 - mae: 2.1287 - val_loss: 5.6566 - val_mse: 5.6566 - val_mae: 1.9438\n",
      "\n",
      "Epoch 00071: val_mae did not improve from 1.93153\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6203 - mse: 6.6203 - mae: 2.0637 - val_loss: 5.6544 - val_mse: 5.6544 - val_mae: 1.9440\n",
      "\n",
      "Epoch 00072: val_mae did not improve from 1.93153\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.2971 - mse: 7.2971 - mae: 2.1761 - val_loss: 5.6378 - val_mse: 5.6378 - val_mae: 1.9379\n",
      "\n",
      "Epoch 00073: val_mae did not improve from 1.93153\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.7123 - mse: 6.7123 - mae: 2.0447 - val_loss: 5.6317 - val_mse: 5.6317 - val_mae: 1.9364\n",
      "\n",
      "Epoch 00074: val_mae did not improve from 1.93153\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2730 - mse: 6.2730 - mae: 1.9782 - val_loss: 5.6290 - val_mse: 5.6290 - val_mae: 1.9363\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 1.93153\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.5771 - mse: 6.5771 - mae: 2.0466 - val_loss: 5.6290 - val_mse: 5.6290 - val_mae: 1.9375\n",
      "\n",
      "Epoch 00076: val_mae did not improve from 1.93153\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.0575 - mse: 7.0575 - mae: 2.0757 - val_loss: 5.6340 - val_mse: 5.6340 - val_mae: 1.9409\n",
      "\n",
      "Epoch 00077: val_mae did not improve from 1.93153\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.9408 - mse: 6.9408 - mae: 2.1226 - val_loss: 5.6209 - val_mse: 5.6209 - val_mae: 1.9364\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 1.93153\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.8945 - mse: 6.8945 - mae: 2.0800 - val_loss: 5.6182 - val_mse: 5.6182 - val_mae: 1.9364\n",
      "\n",
      "Epoch 00079: val_mae did not improve from 1.93153\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3479 - mse: 6.3479 - mae: 2.0036 - val_loss: 5.6133 - val_mse: 5.6133 - val_mae: 1.9353\n",
      "\n",
      "Epoch 00080: val_mae did not improve from 1.93153\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4770 - mse: 6.4770 - mae: 2.0553 - val_loss: 5.6098 - val_mse: 5.6098 - val_mae: 1.9349\n",
      "\n",
      "Epoch 00081: val_mae did not improve from 1.93153\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7294 - mse: 6.7294 - mae: 2.0952 - val_loss: 5.6086 - val_mse: 5.6086 - val_mae: 1.9358\n",
      "\n",
      "Epoch 00082: val_mae did not improve from 1.93153\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.1513 - mse: 7.1513 - mae: 2.1711 - val_loss: 5.5975 - val_mse: 5.5975 - val_mae: 1.9321\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 1.93153\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.9092 - mse: 6.9092 - mae: 2.0880 - val_loss: 5.5982 - val_mse: 5.5982 - val_mae: 1.9337\n",
      "\n",
      "Epoch 00084: val_mae did not improve from 1.93153\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6669 - mse: 6.6669 - mae: 2.0477 - val_loss: 5.5758 - val_mse: 5.5758 - val_mae: 1.9248\n",
      "\n",
      "Epoch 00085: val_mae improved from 1.93153 to 1.92484, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.3556 - mse: 7.3556 - mae: 2.1756 - val_loss: 5.5771 - val_mse: 5.5771 - val_mae: 1.9269\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 1.92484\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.7164 - mse: 6.7164 - mae: 2.0707 - val_loss: 5.5701 - val_mse: 5.5701 - val_mae: 1.9251\n",
      "\n",
      "Epoch 00087: val_mae did not improve from 1.92484\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.1938 - mse: 7.1938 - mae: 2.1250 - val_loss: 5.5769 - val_mse: 5.5769 - val_mae: 1.9294\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 1.92484\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.5561 - mse: 6.5561 - mae: 1.9982 - val_loss: 5.5673 - val_mse: 5.5673 - val_mae: 1.9266\n",
      "\n",
      "Epoch 00089: val_mae did not improve from 1.92484\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.1981 - mse: 7.1981 - mae: 2.1000 - val_loss: 5.5677 - val_mse: 5.5677 - val_mae: 1.9281\n",
      "\n",
      "Epoch 00090: val_mae did not improve from 1.92484\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3948 - mse: 6.3948 - mae: 2.0486 - val_loss: 5.5616 - val_mse: 5.5616 - val_mae: 1.9266\n",
      "\n",
      "Epoch 00091: val_mae did not improve from 1.92484\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7164 - mse: 6.7164 - mae: 2.0660 - val_loss: 5.5610 - val_mse: 5.5610 - val_mae: 1.9277\n",
      "\n",
      "Epoch 00092: val_mae did not improve from 1.92484\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.1493 - mse: 7.1493 - mae: 2.1175 - val_loss: 5.5548 - val_mse: 5.5548 - val_mae: 1.9263\n",
      "\n",
      "Epoch 00093: val_mae did not improve from 1.92484\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.1727 - mse: 7.1727 - mae: 2.0931 - val_loss: 5.5549 - val_mse: 5.5549 - val_mae: 1.9275\n",
      "\n",
      "Epoch 00094: val_mae did not improve from 1.92484\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0429 - mse: 6.0429 - mae: 1.9389 - val_loss: 5.5437 - val_mse: 5.5437 - val_mae: 1.9242\n",
      "\n",
      "Epoch 00095: val_mae improved from 1.92484 to 1.92419, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.9128 - mse: 5.9128 - mae: 1.9705 - val_loss: 5.5444 - val_mse: 5.5444 - val_mae: 1.9256\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 1.92419\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2397 - mse: 7.2397 - mae: 2.1692 - val_loss: 5.5441 - val_mse: 5.5441 - val_mae: 1.9268\n",
      "\n",
      "Epoch 00097: val_mae did not improve from 1.92419\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3667 - mse: 6.3667 - mae: 2.0254 - val_loss: 5.5338 - val_mse: 5.5338 - val_mae: 1.9237\n",
      "\n",
      "Epoch 00098: val_mae improved from 1.92419 to 1.92371, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.8253 - mse: 6.8253 - mae: 2.1201 - val_loss: 5.5182 - val_mse: 5.5182 - val_mae: 1.9185\n",
      "\n",
      "Epoch 00099: val_mae improved from 1.92371 to 1.91851, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3510 - mse: 6.3510 - mae: 2.0182 - val_loss: 5.5283 - val_mse: 5.5283 - val_mae: 1.9239\n",
      "\n",
      "Epoch 00100: val_mae did not improve from 1.91851\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.1618 - mse: 6.1618 - mae: 2.0070 - val_loss: 5.5100 - val_mse: 5.5100 - val_mae: 1.9178\n",
      "\n",
      "Epoch 00101: val_mae improved from 1.91851 to 1.91778, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.0871 - mse: 7.0871 - mae: 2.1283 - val_loss: 5.5170 - val_mse: 5.5170 - val_mae: 1.9218\n",
      "\n",
      "Epoch 00102: val_mae did not improve from 1.91778\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.5738 - mse: 6.5738 - mae: 2.0595 - val_loss: 5.4967 - val_mse: 5.4967 - val_mae: 1.9147\n",
      "\n",
      "Epoch 00103: val_mae improved from 1.91778 to 1.91473, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.3440 - mse: 7.3440 - mae: 2.1725 - val_loss: 5.4974 - val_mse: 5.4974 - val_mae: 1.9164\n",
      "\n",
      "Epoch 00104: val_mae did not improve from 1.91473\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.0810 - mse: 7.0810 - mae: 2.0724 - val_loss: 5.4878 - val_mse: 5.4878 - val_mae: 1.9137\n",
      "\n",
      "Epoch 00105: val_mae improved from 1.91473 to 1.91370, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 7.1781 - mse: 7.1781 - mae: 2.1732 - val_loss: 5.5027 - val_mse: 5.5027 - val_mae: 1.9207\n",
      "\n",
      "Epoch 00106: val_mae did not improve from 1.91370\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.4003 - mse: 7.4003 - mae: 2.1906 - val_loss: 5.4816 - val_mse: 5.4816 - val_mae: 1.9136\n",
      "\n",
      "Epoch 00107: val_mae improved from 1.91370 to 1.91363, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 6.6403 - mse: 6.6403 - mae: 2.0571 - val_loss: 5.4773 - val_mse: 5.4773 - val_mae: 1.9131\n",
      "\n",
      "Epoch 00108: val_mae improved from 1.91363 to 1.91312, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.7192 - mse: 6.7192 - mae: 2.0545 - val_loss: 5.4768 - val_mse: 5.4768 - val_mae: 1.9140\n",
      "\n",
      "Epoch 00109: val_mae did not improve from 1.91312\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3635 - mse: 6.3635 - mae: 2.0741 - val_loss: 5.4675 - val_mse: 5.4675 - val_mae: 1.9116\n",
      "\n",
      "Epoch 00110: val_mae improved from 1.91312 to 1.91158, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1191 - mse: 7.1191 - mae: 2.0866 - val_loss: 5.4841 - val_mse: 5.4841 - val_mae: 1.9193\n",
      "\n",
      "Epoch 00111: val_mae did not improve from 1.91158\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.8828 - mse: 6.8828 - mae: 2.0705 - val_loss: 5.4517 - val_mse: 5.4517 - val_mae: 1.9076\n",
      "\n",
      "Epoch 00112: val_mae improved from 1.91158 to 1.90758, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7865 - mse: 6.7865 - mae: 2.0922 - val_loss: 5.4408 - val_mse: 5.4408 - val_mae: 1.9042\n",
      "\n",
      "Epoch 00113: val_mae improved from 1.90758 to 1.90420, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.0733 - mse: 6.0733 - mae: 1.9888 - val_loss: 5.4430 - val_mse: 5.4430 - val_mae: 1.9065\n",
      "\n",
      "Epoch 00114: val_mae did not improve from 1.90420\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4671 - mse: 6.4671 - mae: 2.0385 - val_loss: 5.4473 - val_mse: 5.4473 - val_mae: 1.9093\n",
      "\n",
      "Epoch 00115: val_mae did not improve from 1.90420\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4667 - mse: 6.4667 - mae: 1.9979 - val_loss: 5.4357 - val_mse: 5.4357 - val_mae: 1.9059\n",
      "\n",
      "Epoch 00116: val_mae did not improve from 1.90420\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.9368 - mse: 6.9368 - mae: 2.0721 - val_loss: 5.4364 - val_mse: 5.4364 - val_mae: 1.9073\n",
      "\n",
      "Epoch 00117: val_mae did not improve from 1.90420\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.7350 - mse: 6.7350 - mae: 2.0590 - val_loss: 5.4261 - val_mse: 5.4261 - val_mae: 1.9044\n",
      "\n",
      "Epoch 00118: val_mae did not improve from 1.90420\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 6.2072 - mse: 6.2072 - mae: 1.9579 - val_loss: 5.4089 - val_mse: 5.4089 - val_mae: 1.8985\n",
      "\n",
      "Epoch 00119: val_mae improved from 1.90420 to 1.89855, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9595 - mse: 5.9595 - mae: 1.9671 - val_loss: 5.4149 - val_mse: 5.4149 - val_mae: 1.9024\n",
      "\n",
      "Epoch 00120: val_mae did not improve from 1.89855\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.6775 - mse: 6.6775 - mae: 2.0761 - val_loss: 5.4218 - val_mse: 5.4218 - val_mae: 1.9062\n",
      "\n",
      "Epoch 00121: val_mae did not improve from 1.89855\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6671 - mse: 6.6671 - mae: 2.1179 - val_loss: 5.3983 - val_mse: 5.3983 - val_mae: 1.8983\n",
      "\n",
      "Epoch 00122: val_mae improved from 1.89855 to 1.89834, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.2800 - mse: 6.2800 - mae: 2.0183 - val_loss: 5.3973 - val_mse: 5.3973 - val_mae: 1.8991\n",
      "\n",
      "Epoch 00123: val_mae did not improve from 1.89834\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.0213 - mse: 7.0213 - mae: 2.0690 - val_loss: 5.3844 - val_mse: 5.3844 - val_mae: 1.8951\n",
      "\n",
      "Epoch 00124: val_mae improved from 1.89834 to 1.89515, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4108 - mse: 6.4108 - mae: 1.9915 - val_loss: 5.3774 - val_mse: 5.3774 - val_mae: 1.8935\n",
      "\n",
      "Epoch 00125: val_mae improved from 1.89515 to 1.89352, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7923 - mse: 6.7923 - mae: 2.0771 - val_loss: 5.3659 - val_mse: 5.3659 - val_mae: 1.8897\n",
      "\n",
      "Epoch 00126: val_mae improved from 1.89352 to 1.88969, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.0343 - mse: 6.0343 - mae: 1.9222 - val_loss: 5.3693 - val_mse: 5.3693 - val_mae: 1.8929\n",
      "\n",
      "Epoch 00127: val_mae did not improve from 1.88969\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.5943 - mse: 7.5943 - mae: 2.1240 - val_loss: 5.3667 - val_mse: 5.3667 - val_mae: 1.8931\n",
      "\n",
      "Epoch 00128: val_mae did not improve from 1.88969\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.9297 - mse: 6.9297 - mae: 2.1353 - val_loss: 5.3555 - val_mse: 5.3555 - val_mae: 1.8896\n",
      "\n",
      "Epoch 00129: val_mae improved from 1.88969 to 1.88963, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3145 - mse: 7.3145 - mae: 2.1285 - val_loss: 5.3419 - val_mse: 5.3419 - val_mae: 1.8846\n",
      "\n",
      "Epoch 00130: val_mae improved from 1.88963 to 1.88463, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5008 - mse: 6.5008 - mae: 2.0464 - val_loss: 5.3551 - val_mse: 5.3551 - val_mae: 1.8919\n",
      "\n",
      "Epoch 00131: val_mae did not improve from 1.88463\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.7394 - mse: 6.7394 - mae: 2.1073 - val_loss: 5.3631 - val_mse: 5.3631 - val_mae: 1.8960\n",
      "\n",
      "Epoch 00132: val_mae did not improve from 1.88463\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6267 - mse: 6.6267 - mae: 2.0934 - val_loss: 5.3371 - val_mse: 5.3371 - val_mae: 1.8871\n",
      "\n",
      "Epoch 00133: val_mae did not improve from 1.88463\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0195 - mse: 6.0195 - mae: 1.9731 - val_loss: 5.3406 - val_mse: 5.3406 - val_mae: 1.8897\n",
      "\n",
      "Epoch 00134: val_mae did not improve from 1.88463\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.2844 - mse: 7.2844 - mae: 2.1651 - val_loss: 5.3339 - val_mse: 5.3339 - val_mae: 1.8883\n",
      "\n",
      "Epoch 00135: val_mae did not improve from 1.88463\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1787 - mse: 6.1787 - mae: 2.0046 - val_loss: 5.3178 - val_mse: 5.3178 - val_mae: 1.8829\n",
      "\n",
      "Epoch 00136: val_mae improved from 1.88463 to 1.88286, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.8134 - mse: 6.8134 - mae: 2.0314 - val_loss: 5.3196 - val_mse: 5.3196 - val_mae: 1.8850\n",
      "\n",
      "Epoch 00137: val_mae did not improve from 1.88286\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.5202 - mse: 6.5202 - mae: 2.0534 - val_loss: 5.3175 - val_mse: 5.3175 - val_mae: 1.8853\n",
      "\n",
      "Epoch 00138: val_mae did not improve from 1.88286\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.7662 - mse: 6.7662 - mae: 2.0778 - val_loss: 5.3009 - val_mse: 5.3009 - val_mae: 1.8798\n",
      "\n",
      "Epoch 00139: val_mae improved from 1.88286 to 1.87980, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3917 - mse: 6.3917 - mae: 2.0346 - val_loss: 5.2889 - val_mse: 5.2889 - val_mae: 1.8756\n",
      "\n",
      "Epoch 00140: val_mae improved from 1.87980 to 1.87560, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5897 - mse: 6.5897 - mae: 2.0830 - val_loss: 5.2957 - val_mse: 5.2957 - val_mae: 1.8805\n",
      "\n",
      "Epoch 00141: val_mae did not improve from 1.87560\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.8869 - mse: 6.8869 - mae: 2.1061 - val_loss: 5.2830 - val_mse: 5.2830 - val_mae: 1.8762\n",
      "\n",
      "Epoch 00142: val_mae did not improve from 1.87560\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9407 - mse: 5.9407 - mae: 1.9676 - val_loss: 5.2822 - val_mse: 5.2822 - val_mae: 1.8775\n",
      "\n",
      "Epoch 00143: val_mae did not improve from 1.87560\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2244 - mse: 6.2244 - mae: 1.9816 - val_loss: 5.2910 - val_mse: 5.2910 - val_mae: 1.8822\n",
      "\n",
      "Epoch 00144: val_mae did not improve from 1.87560\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.1780 - mse: 6.1780 - mae: 1.9870 - val_loss: 5.2789 - val_mse: 5.2789 - val_mae: 1.8786\n",
      "\n",
      "Epoch 00145: val_mae did not improve from 1.87560\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.0123 - mse: 7.0123 - mae: 2.1063 - val_loss: 5.2705 - val_mse: 5.2705 - val_mae: 1.8767\n",
      "\n",
      "Epoch 00146: val_mae did not improve from 1.87560\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.6792 - mse: 6.6792 - mae: 2.0337 - val_loss: 5.2623 - val_mse: 5.2623 - val_mae: 1.8747\n",
      "\n",
      "Epoch 00147: val_mae improved from 1.87560 to 1.87467, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.9658 - mse: 5.9658 - mae: 1.9248 - val_loss: 5.2463 - val_mse: 5.2463 - val_mae: 1.8690\n",
      "\n",
      "Epoch 00148: val_mae improved from 1.87467 to 1.86896, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.8908 - mse: 6.8908 - mae: 2.0398 - val_loss: 5.2473 - val_mse: 5.2473 - val_mae: 1.8710\n",
      "\n",
      "Epoch 00149: val_mae did not improve from 1.86896\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.1075 - mse: 6.1075 - mae: 1.9864 - val_loss: 5.2327 - val_mse: 5.2327 - val_mae: 1.8656\n",
      "\n",
      "Epoch 00150: val_mae improved from 1.86896 to 1.86561, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6868 - mse: 6.6868 - mae: 2.0822 - val_loss: 5.2551 - val_mse: 5.2551 - val_mae: 1.8764\n",
      "\n",
      "Epoch 00151: val_mae did not improve from 1.86561\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.3079 - mse: 6.3079 - mae: 2.0081 - val_loss: 5.2327 - val_mse: 5.2327 - val_mae: 1.8690\n",
      "\n",
      "Epoch 00152: val_mae did not improve from 1.86561\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2744 - mse: 6.2744 - mae: 2.0275 - val_loss: 5.2273 - val_mse: 5.2273 - val_mae: 1.8680\n",
      "\n",
      "Epoch 00153: val_mae did not improve from 1.86561\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7944 - mse: 6.7944 - mae: 2.0738 - val_loss: 5.2203 - val_mse: 5.2203 - val_mae: 1.8661\n",
      "\n",
      "Epoch 00154: val_mae did not improve from 1.86561\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.8848 - mse: 6.8848 - mae: 2.0042 - val_loss: 5.2243 - val_mse: 5.2243 - val_mae: 1.8691\n",
      "\n",
      "Epoch 00155: val_mae did not improve from 1.86561\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2383 - mse: 6.2383 - mae: 2.0117 - val_loss: 5.2171 - val_mse: 5.2171 - val_mae: 1.8674\n",
      "\n",
      "Epoch 00156: val_mae did not improve from 1.86561\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.8986 - mse: 6.8986 - mae: 2.0933 - val_loss: 5.2052 - val_mse: 5.2052 - val_mae: 1.8639\n",
      "\n",
      "Epoch 00157: val_mae improved from 1.86561 to 1.86390, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3745 - mse: 6.3745 - mae: 2.0502 - val_loss: 5.1999 - val_mse: 5.1999 - val_mae: 1.8628\n",
      "\n",
      "Epoch 00158: val_mae improved from 1.86390 to 1.86283, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.5695 - mse: 7.5695 - mae: 2.1916 - val_loss: 5.1969 - val_mse: 5.1969 - val_mae: 1.8629\n",
      "\n",
      "Epoch 00159: val_mae did not improve from 1.86283\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.5842 - mse: 6.5842 - mae: 2.0372 - val_loss: 5.1772 - val_mse: 5.1772 - val_mae: 1.8553\n",
      "\n",
      "Epoch 00160: val_mae improved from 1.86283 to 1.85533, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.7820 - mse: 6.7820 - mae: 2.0789 - val_loss: 5.1901 - val_mse: 5.1901 - val_mae: 1.8626\n",
      "\n",
      "Epoch 00161: val_mae did not improve from 1.85533\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4763 - mse: 6.4763 - mae: 2.0619 - val_loss: 5.1809 - val_mse: 5.1809 - val_mae: 1.8599\n",
      "\n",
      "Epoch 00162: val_mae did not improve from 1.85533\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.9089 - mse: 6.9089 - mae: 2.0857 - val_loss: 5.1751 - val_mse: 5.1751 - val_mae: 1.8586\n",
      "\n",
      "Epoch 00163: val_mae did not improve from 1.85533\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7996 - mse: 6.7996 - mae: 2.1041 - val_loss: 5.1656 - val_mse: 5.1656 - val_mae: 1.8560\n",
      "\n",
      "Epoch 00164: val_mae did not improve from 1.85533\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.0413 - mse: 7.0413 - mae: 2.0857 - val_loss: 5.1582 - val_mse: 5.1582 - val_mae: 1.8542\n",
      "\n",
      "Epoch 00165: val_mae improved from 1.85533 to 1.85418, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.6888 - mse: 6.6888 - mae: 2.0237 - val_loss: 5.1532 - val_mse: 5.1532 - val_mae: 1.8533\n",
      "\n",
      "Epoch 00166: val_mae improved from 1.85418 to 1.85328, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.1781 - mse: 6.1781 - mae: 1.9732 - val_loss: 5.1477 - val_mse: 5.1477 - val_mae: 1.8520\n",
      "\n",
      "Epoch 00167: val_mae improved from 1.85328 to 1.85202, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.4811 - mse: 6.4811 - mae: 2.0209 - val_loss: 5.1434 - val_mse: 5.1434 - val_mae: 1.8514\n",
      "\n",
      "Epoch 00168: val_mae improved from 1.85202 to 1.85142, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.0903 - mse: 6.0903 - mae: 1.9761 - val_loss: 5.1298 - val_mse: 5.1298 - val_mae: 1.8462\n",
      "\n",
      "Epoch 00169: val_mae improved from 1.85142 to 1.84624, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.2961 - mse: 6.2961 - mae: 1.9902 - val_loss: 5.1343 - val_mse: 5.1343 - val_mae: 1.8500\n",
      "\n",
      "Epoch 00170: val_mae did not improve from 1.84624\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7990 - mse: 6.7990 - mae: 2.0765 - val_loss: 5.1345 - val_mse: 5.1345 - val_mae: 1.8513\n",
      "\n",
      "Epoch 00171: val_mae did not improve from 1.84624\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6737 - mse: 6.6737 - mae: 2.0634 - val_loss: 5.1280 - val_mse: 5.1280 - val_mae: 1.8498\n",
      "\n",
      "Epoch 00172: val_mae did not improve from 1.84624\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4383 - mse: 6.4383 - mae: 2.0111 - val_loss: 5.1243 - val_mse: 5.1243 - val_mae: 1.8494\n",
      "\n",
      "Epoch 00173: val_mae did not improve from 1.84624\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9542 - mse: 5.9542 - mae: 1.9180 - val_loss: 5.1159 - val_mse: 5.1159 - val_mae: 1.8470\n",
      "\n",
      "Epoch 00174: val_mae did not improve from 1.84624\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9098 - mse: 5.9098 - mae: 1.9792 - val_loss: 5.1130 - val_mse: 5.1130 - val_mae: 1.8470\n",
      "\n",
      "Epoch 00175: val_mae did not improve from 1.84624\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2817 - mse: 6.2817 - mae: 2.0199 - val_loss: 5.1144 - val_mse: 5.1144 - val_mae: 1.8486\n",
      "\n",
      "Epoch 00176: val_mae did not improve from 1.84624\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0478 - mse: 6.0478 - mae: 1.9988 - val_loss: 5.1201 - val_mse: 5.1201 - val_mae: 1.8514\n",
      "\n",
      "Epoch 00177: val_mae did not improve from 1.84624\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.3277 - mse: 6.3277 - mae: 2.0251 - val_loss: 5.1193 - val_mse: 5.1193 - val_mae: 1.8520\n",
      "\n",
      "Epoch 00178: val_mae did not improve from 1.84624\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.8977 - mse: 6.8977 - mae: 2.0938 - val_loss: 5.0895 - val_mse: 5.0895 - val_mae: 1.8417\n",
      "\n",
      "Epoch 00179: val_mae improved from 1.84624 to 1.84172, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7788 - mse: 6.7788 - mae: 2.0357 - val_loss: 5.0878 - val_mse: 5.0878 - val_mae: 1.8421\n",
      "\n",
      "Epoch 00180: val_mae did not improve from 1.84172\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.6134 - mse: 6.6134 - mae: 2.0983 - val_loss: 5.0719 - val_mse: 5.0719 - val_mae: 1.8360\n",
      "\n",
      "Epoch 00181: val_mae improved from 1.84172 to 1.83605, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2062 - mse: 6.2062 - mae: 2.0298 - val_loss: 5.0747 - val_mse: 5.0747 - val_mae: 1.8387\n",
      "\n",
      "Epoch 00182: val_mae did not improve from 1.83605\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.1409 - mse: 6.1409 - mae: 1.9981 - val_loss: 5.0675 - val_mse: 5.0675 - val_mae: 1.8368\n",
      "\n",
      "Epoch 00183: val_mae did not improve from 1.83605\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.1953 - mse: 7.1953 - mae: 2.1132 - val_loss: 5.0661 - val_mse: 5.0661 - val_mae: 1.8375\n",
      "\n",
      "Epoch 00184: val_mae did not improve from 1.83605\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1346 - mse: 6.1346 - mae: 2.0148 - val_loss: 5.0461 - val_mse: 5.0461 - val_mae: 1.8285\n",
      "\n",
      "Epoch 00185: val_mae improved from 1.83605 to 1.82845, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1942 - mse: 6.1942 - mae: 2.0181 - val_loss: 5.0569 - val_mse: 5.0569 - val_mae: 1.8357\n",
      "\n",
      "Epoch 00186: val_mae did not improve from 1.82845\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 5.7464 - mse: 5.7464 - mae: 1.9499 - val_loss: 5.0466 - val_mse: 5.0466 - val_mae: 1.8322\n",
      "\n",
      "Epoch 00187: val_mae did not improve from 1.82845\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.0511 - mse: 6.0511 - mae: 1.9674 - val_loss: 5.0464 - val_mse: 5.0464 - val_mae: 1.8334\n",
      "\n",
      "Epoch 00188: val_mae did not improve from 1.82845\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7207 - mse: 6.7207 - mae: 2.0342 - val_loss: 5.0418 - val_mse: 5.0418 - val_mae: 1.8324\n",
      "\n",
      "Epoch 00189: val_mae did not improve from 1.82845\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0681 - mse: 6.0681 - mae: 1.9815 - val_loss: 5.0422 - val_mse: 5.0422 - val_mae: 1.8336\n",
      "\n",
      "Epoch 00190: val_mae did not improve from 1.82845\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.1744 - mse: 7.1744 - mae: 2.1638 - val_loss: 5.0550 - val_mse: 5.0550 - val_mae: 1.8388\n",
      "\n",
      "Epoch 00191: val_mae did not improve from 1.82845\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8236 - mse: 5.8236 - mae: 1.9506 - val_loss: 5.0173 - val_mse: 5.0173 - val_mae: 1.8246\n",
      "\n",
      "Epoch 00192: val_mae improved from 1.82845 to 1.82457, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0622 - mse: 6.0622 - mae: 1.9740 - val_loss: 5.0243 - val_mse: 5.0243 - val_mae: 1.8292\n",
      "\n",
      "Epoch 00193: val_mae did not improve from 1.82457\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0393 - mse: 6.0393 - mae: 1.9568 - val_loss: 5.0197 - val_mse: 5.0197 - val_mae: 1.8283\n",
      "\n",
      "Epoch 00194: val_mae did not improve from 1.82457\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4782 - mse: 5.4782 - mae: 1.9032 - val_loss: 5.0000 - val_mse: 5.0000 - val_mae: 1.8200\n",
      "\n",
      "Epoch 00195: val_mae improved from 1.82457 to 1.82001, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.1857 - mse: 6.1857 - mae: 2.0069 - val_loss: 5.0201 - val_mse: 5.0201 - val_mae: 1.8302\n",
      "\n",
      "Epoch 00196: val_mae did not improve from 1.82001\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.7658 - mse: 5.7658 - mae: 1.9246 - val_loss: 5.0037 - val_mse: 5.0037 - val_mae: 1.8246\n",
      "\n",
      "Epoch 00197: val_mae did not improve from 1.82001\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.3256 - mse: 6.3256 - mae: 1.9977 - val_loss: 5.0166 - val_mse: 5.0166 - val_mae: 1.8303\n",
      "\n",
      "Epoch 00198: val_mae did not improve from 1.82001\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8960 - mse: 5.8960 - mae: 1.9485 - val_loss: 4.9968 - val_mse: 4.9968 - val_mae: 1.8236\n",
      "\n",
      "Epoch 00199: val_mae did not improve from 1.82001\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4537 - mse: 6.4537 - mae: 2.0558 - val_loss: 4.9889 - val_mse: 4.9889 - val_mae: 1.8212\n",
      "\n",
      "Epoch 00200: val_mae did not improve from 1.82001\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0971 - mse: 6.0971 - mae: 1.9897 - val_loss: 4.9776 - val_mse: 4.9776 - val_mae: 1.8171\n",
      "\n",
      "Epoch 00201: val_mae improved from 1.82001 to 1.81714, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2432 - mse: 6.2432 - mae: 2.0205 - val_loss: 4.9773 - val_mse: 4.9773 - val_mae: 1.8181\n",
      "\n",
      "Epoch 00202: val_mae did not improve from 1.81714\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4032 - mse: 6.4032 - mae: 2.0457 - val_loss: 4.9819 - val_mse: 4.9819 - val_mae: 1.8211\n",
      "\n",
      "Epoch 00203: val_mae did not improve from 1.81714\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3267 - mse: 6.3267 - mae: 2.0140 - val_loss: 4.9675 - val_mse: 4.9675 - val_mae: 1.8158\n",
      "\n",
      "Epoch 00204: val_mae improved from 1.81714 to 1.81583, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6823 - mse: 5.6823 - mae: 1.9378 - val_loss: 4.9532 - val_mse: 4.9532 - val_mae: 1.8098\n",
      "\n",
      "Epoch 00205: val_mae improved from 1.81583 to 1.80983, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.0629 - mse: 6.0629 - mae: 1.9483 - val_loss: 4.9600 - val_mse: 4.9600 - val_mae: 1.8147\n",
      "\n",
      "Epoch 00206: val_mae did not improve from 1.80983\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.1230 - mse: 6.1230 - mae: 1.9603 - val_loss: 4.9470 - val_mse: 4.9470 - val_mae: 1.8096\n",
      "\n",
      "Epoch 00207: val_mae improved from 1.80983 to 1.80955, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9625 - mse: 5.9625 - mae: 1.9389 - val_loss: 4.9473 - val_mse: 4.9473 - val_mae: 1.8111\n",
      "\n",
      "Epoch 00208: val_mae did not improve from 1.80955\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.8807 - mse: 6.8807 - mae: 2.0719 - val_loss: 4.9478 - val_mse: 4.9478 - val_mae: 1.8124\n",
      "\n",
      "Epoch 00209: val_mae did not improve from 1.80955\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9534 - mse: 5.9534 - mae: 1.9603 - val_loss: 4.9465 - val_mse: 4.9465 - val_mae: 1.8128\n",
      "\n",
      "Epoch 00210: val_mae did not improve from 1.80955\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5385 - mse: 6.5385 - mae: 2.0489 - val_loss: 4.9282 - val_mse: 4.9282 - val_mae: 1.8048\n",
      "\n",
      "Epoch 00211: val_mae improved from 1.80955 to 1.80482, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.3778 - mse: 6.3778 - mae: 2.0400 - val_loss: 4.9487 - val_mse: 4.9487 - val_mae: 1.8151\n",
      "\n",
      "Epoch 00212: val_mae did not improve from 1.80482\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0803 - mse: 6.0803 - mae: 1.9764 - val_loss: 4.9342 - val_mse: 4.9342 - val_mae: 1.8103\n",
      "\n",
      "Epoch 00213: val_mae did not improve from 1.80482\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6880 - mse: 6.6880 - mae: 2.0786 - val_loss: 4.9326 - val_mse: 4.9326 - val_mae: 1.8105\n",
      "\n",
      "Epoch 00214: val_mae did not improve from 1.80482\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.9493 - mse: 5.9493 - mae: 1.9299 - val_loss: 4.9110 - val_mse: 4.9110 - val_mae: 1.8013\n",
      "\n",
      "Epoch 00215: val_mae improved from 1.80482 to 1.80128, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.4871 - mse: 6.4871 - mae: 2.0197 - val_loss: 4.9151 - val_mse: 4.9151 - val_mae: 1.8049\n",
      "\n",
      "Epoch 00216: val_mae did not improve from 1.80128\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.2356 - mse: 6.2356 - mae: 1.9729 - val_loss: 4.9307 - val_mse: 4.9307 - val_mae: 1.8121\n",
      "\n",
      "Epoch 00217: val_mae did not improve from 1.80128\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.8829 - mse: 6.8829 - mae: 2.0966 - val_loss: 4.9162 - val_mse: 4.9162 - val_mae: 1.8074\n",
      "\n",
      "Epoch 00218: val_mae did not improve from 1.80128\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5981 - mse: 6.5981 - mae: 2.0631 - val_loss: 4.9102 - val_mse: 4.9102 - val_mae: 1.8057\n",
      "\n",
      "Epoch 00219: val_mae did not improve from 1.80128\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.2539 - mse: 6.2539 - mae: 1.9948 - val_loss: 4.9020 - val_mse: 4.9020 - val_mae: 1.8029\n",
      "\n",
      "Epoch 00220: val_mae did not improve from 1.80128\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 6.4529 - mse: 6.4529 - mae: 2.0210 - val_loss: 4.8932 - val_mse: 4.8932 - val_mae: 1.7996\n",
      "\n",
      "Epoch 00221: val_mae improved from 1.80128 to 1.79960, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 5.7874 - mse: 5.7874 - mae: 1.9470 - val_loss: 4.8959 - val_mse: 4.8959 - val_mae: 1.8020\n",
      "\n",
      "Epoch 00222: val_mae did not improve from 1.79960\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.6246 - mse: 6.6246 - mae: 2.0647 - val_loss: 4.8961 - val_mse: 4.8961 - val_mae: 1.8030\n",
      "\n",
      "Epoch 00223: val_mae did not improve from 1.79960\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5953 - mse: 5.5953 - mae: 1.9012 - val_loss: 4.8772 - val_mse: 4.8772 - val_mae: 1.7947\n",
      "\n",
      "Epoch 00224: val_mae improved from 1.79960 to 1.79472, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.7371 - mse: 6.7371 - mae: 2.0513 - val_loss: 4.9025 - val_mse: 4.9025 - val_mae: 1.8069\n",
      "\n",
      "Epoch 00225: val_mae did not improve from 1.79472\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.0171 - mse: 7.0171 - mae: 2.1255 - val_loss: 4.8822 - val_mse: 4.8822 - val_mae: 1.7995\n",
      "\n",
      "Epoch 00226: val_mae did not improve from 1.79472\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6203 - mse: 6.6203 - mae: 2.0247 - val_loss: 4.8692 - val_mse: 4.8692 - val_mae: 1.7940\n",
      "\n",
      "Epoch 00227: val_mae improved from 1.79472 to 1.79396, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.2141 - mse: 6.2141 - mae: 1.9768 - val_loss: 4.8709 - val_mse: 4.8709 - val_mae: 1.7958\n",
      "\n",
      "Epoch 00228: val_mae did not improve from 1.79396\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1587 - mse: 6.1587 - mae: 1.9907 - val_loss: 4.8571 - val_mse: 4.8571 - val_mae: 1.7894\n",
      "\n",
      "Epoch 00229: val_mae improved from 1.79396 to 1.78944, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7695 - mse: 5.7695 - mae: 1.9297 - val_loss: 4.8619 - val_mse: 4.8619 - val_mae: 1.7935\n",
      "\n",
      "Epoch 00230: val_mae did not improve from 1.78944\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3951 - mse: 6.3951 - mae: 2.0545 - val_loss: 4.8780 - val_mse: 4.8780 - val_mae: 1.8012\n",
      "\n",
      "Epoch 00231: val_mae did not improve from 1.78944\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4379 - mse: 6.4379 - mae: 2.0507 - val_loss: 4.8572 - val_mse: 4.8572 - val_mae: 1.7933\n",
      "\n",
      "Epoch 00232: val_mae did not improve from 1.78944\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2469 - mse: 6.2469 - mae: 2.0135 - val_loss: 4.8473 - val_mse: 4.8473 - val_mae: 1.7891\n",
      "\n",
      "Epoch 00233: val_mae improved from 1.78944 to 1.78914, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9382 - mse: 6.9382 - mae: 2.0467 - val_loss: 4.8523 - val_mse: 4.8523 - val_mae: 1.7926\n",
      "\n",
      "Epoch 00234: val_mae did not improve from 1.78914\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2447 - mse: 6.2447 - mae: 1.9522 - val_loss: 4.8457 - val_mse: 4.8457 - val_mae: 1.7903\n",
      "\n",
      "Epoch 00235: val_mae did not improve from 1.78914\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1169 - mse: 6.1169 - mae: 1.9543 - val_loss: 4.8446 - val_mse: 4.8446 - val_mae: 1.7907\n",
      "\n",
      "Epoch 00236: val_mae did not improve from 1.78914\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8659 - mse: 5.8659 - mae: 1.9492 - val_loss: 4.8389 - val_mse: 4.8389 - val_mae: 1.7887\n",
      "\n",
      "Epoch 00237: val_mae improved from 1.78914 to 1.78871, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.0362 - mse: 6.0362 - mae: 1.9450 - val_loss: 4.8301 - val_mse: 4.8301 - val_mae: 1.7851\n",
      "\n",
      "Epoch 00238: val_mae improved from 1.78871 to 1.78515, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 5.8677 - mse: 5.8677 - mae: 1.9132 - val_loss: 4.8300 - val_mse: 4.8300 - val_mae: 1.7862\n",
      "\n",
      "Epoch 00239: val_mae did not improve from 1.78515\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7039 - mse: 6.7039 - mae: 2.1001 - val_loss: 4.8324 - val_mse: 4.8324 - val_mae: 1.7882\n",
      "\n",
      "Epoch 00240: val_mae did not improve from 1.78515\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0416 - mse: 6.0416 - mae: 1.9764 - val_loss: 4.8293 - val_mse: 4.8293 - val_mae: 1.7877\n",
      "\n",
      "Epoch 00241: val_mae did not improve from 1.78515\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4231 - mse: 6.4231 - mae: 1.9939 - val_loss: 4.8200 - val_mse: 4.8200 - val_mae: 1.7840\n",
      "\n",
      "Epoch 00242: val_mae improved from 1.78515 to 1.78404, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.6591 - mse: 5.6591 - mae: 1.9310 - val_loss: 4.8146 - val_mse: 4.8146 - val_mae: 1.7820\n",
      "\n",
      "Epoch 00243: val_mae improved from 1.78404 to 1.78200, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.4463 - mse: 6.4463 - mae: 2.0405 - val_loss: 4.8146 - val_mse: 4.8146 - val_mae: 1.7830\n",
      "\n",
      "Epoch 00244: val_mae did not improve from 1.78200\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.9802 - mse: 6.9802 - mae: 2.1050 - val_loss: 4.8166 - val_mse: 4.8166 - val_mae: 1.7851\n",
      "\n",
      "Epoch 00245: val_mae did not improve from 1.78200\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3030 - mse: 6.3030 - mae: 2.0007 - val_loss: 4.8068 - val_mse: 4.8068 - val_mae: 1.7808\n",
      "\n",
      "Epoch 00246: val_mae improved from 1.78200 to 1.78080, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1290 - mse: 6.1290 - mae: 1.9959 - val_loss: 4.8071 - val_mse: 4.8071 - val_mae: 1.7820\n",
      "\n",
      "Epoch 00247: val_mae did not improve from 1.78080\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0706 - mse: 6.0706 - mae: 1.9398 - val_loss: 4.7985 - val_mse: 4.7985 - val_mae: 1.7781\n",
      "\n",
      "Epoch 00248: val_mae improved from 1.78080 to 1.77815, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3236 - mse: 6.3236 - mae: 2.0182 - val_loss: 4.7936 - val_mse: 4.7936 - val_mae: 1.7763\n",
      "\n",
      "Epoch 00249: val_mae improved from 1.77815 to 1.77632, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7529 - mse: 6.7529 - mae: 2.0573 - val_loss: 4.7906 - val_mse: 4.7906 - val_mae: 1.7754\n",
      "\n",
      "Epoch 00250: val_mae improved from 1.77632 to 1.77542, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1518 - mse: 6.1518 - mae: 1.9951 - val_loss: 4.7950 - val_mse: 4.7950 - val_mae: 1.7792\n",
      "\n",
      "Epoch 00251: val_mae did not improve from 1.77542\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.1867 - mse: 6.1867 - mae: 2.0036 - val_loss: 4.7898 - val_mse: 4.7898 - val_mae: 1.7772\n",
      "\n",
      "Epoch 00252: val_mae did not improve from 1.77542\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9654 - mse: 5.9654 - mae: 1.9269 - val_loss: 4.7844 - val_mse: 4.7844 - val_mae: 1.7752\n",
      "\n",
      "Epoch 00253: val_mae improved from 1.77542 to 1.77521, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.9184 - mse: 5.9184 - mae: 1.9252 - val_loss: 4.7834 - val_mse: 4.7834 - val_mae: 1.7758\n",
      "\n",
      "Epoch 00254: val_mae did not improve from 1.77521\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2869 - mse: 6.2869 - mae: 2.0079 - val_loss: 4.7830 - val_mse: 4.7830 - val_mae: 1.7766\n",
      "\n",
      "Epoch 00255: val_mae did not improve from 1.77521\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6325 - mse: 5.6325 - mae: 1.9111 - val_loss: 4.7804 - val_mse: 4.7804 - val_mae: 1.7760\n",
      "\n",
      "Epoch 00256: val_mae did not improve from 1.77521\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2235 - mse: 6.2235 - mae: 1.9989 - val_loss: 4.7807 - val_mse: 4.7807 - val_mae: 1.7773\n",
      "\n",
      "Epoch 00257: val_mae did not improve from 1.77521\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0007 - mse: 6.0007 - mae: 1.9778 - val_loss: 4.7688 - val_mse: 4.7688 - val_mae: 1.7709\n",
      "\n",
      "Epoch 00258: val_mae improved from 1.77521 to 1.77095, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 6.4571 - mse: 6.4571 - mae: 2.0289 - val_loss: 4.7712 - val_mse: 4.7712 - val_mae: 1.7737\n",
      "\n",
      "Epoch 00259: val_mae did not improve from 1.77095\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9115 - mse: 5.9115 - mae: 1.9715 - val_loss: 4.7787 - val_mse: 4.7787 - val_mae: 1.7789\n",
      "\n",
      "Epoch 00260: val_mae did not improve from 1.77095\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1890 - mse: 6.1890 - mae: 1.9816 - val_loss: 4.7738 - val_mse: 4.7738 - val_mae: 1.7772\n",
      "\n",
      "Epoch 00261: val_mae did not improve from 1.77095\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1887 - mse: 6.1887 - mae: 2.0000 - val_loss: 4.7720 - val_mse: 4.7720 - val_mae: 1.7770\n",
      "\n",
      "Epoch 00262: val_mae did not improve from 1.77095\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3224 - mse: 6.3224 - mae: 2.0237 - val_loss: 4.7568 - val_mse: 4.7568 - val_mae: 1.7688\n",
      "\n",
      "Epoch 00263: val_mae improved from 1.77095 to 1.76883, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 5.9471 - mse: 5.9471 - mae: 1.9749 - val_loss: 4.7580 - val_mse: 4.7580 - val_mae: 1.7711\n",
      "\n",
      "Epoch 00264: val_mae did not improve from 1.76883\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.6447 - mse: 5.6447 - mae: 1.8989 - val_loss: 4.7581 - val_mse: 4.7581 - val_mae: 1.7722\n",
      "\n",
      "Epoch 00265: val_mae did not improve from 1.76883\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3430 - mse: 6.3430 - mae: 2.0180 - val_loss: 4.7567 - val_mse: 4.7567 - val_mae: 1.7724\n",
      "\n",
      "Epoch 00266: val_mae did not improve from 1.76883\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9809 - mse: 5.9809 - mae: 1.8948 - val_loss: 4.7471 - val_mse: 4.7471 - val_mae: 1.7676\n",
      "\n",
      "Epoch 00267: val_mae improved from 1.76883 to 1.76758, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5908 - mse: 6.5908 - mae: 2.0084 - val_loss: 4.7417 - val_mse: 4.7417 - val_mae: 1.7648\n",
      "\n",
      "Epoch 00268: val_mae improved from 1.76758 to 1.76485, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9563 - mse: 5.9563 - mae: 1.9817 - val_loss: 4.7448 - val_mse: 4.7448 - val_mae: 1.7682\n",
      "\n",
      "Epoch 00269: val_mae did not improve from 1.76485\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.1987 - mse: 6.1987 - mae: 2.0184 - val_loss: 4.7366 - val_mse: 4.7366 - val_mae: 1.7637\n",
      "\n",
      "Epoch 00270: val_mae improved from 1.76485 to 1.76369, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 6.0634 - mse: 6.0634 - mae: 1.9348 - val_loss: 4.7441 - val_mse: 4.7441 - val_mae: 1.7696\n",
      "\n",
      "Epoch 00271: val_mae did not improve from 1.76369\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 6.1331 - mse: 6.1331 - mae: 1.9926 - val_loss: 4.7446 - val_mse: 4.7446 - val_mae: 1.7706\n",
      "\n",
      "Epoch 00272: val_mae did not improve from 1.76369\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 6.2279 - mse: 6.2279 - mae: 1.9531 - val_loss: 4.7404 - val_mse: 4.7404 - val_mae: 1.7692\n",
      "\n",
      "Epoch 00273: val_mae did not improve from 1.76369\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 5.6760 - mse: 5.6760 - mae: 1.8993 - val_loss: 4.7387 - val_mse: 4.7387 - val_mae: 1.7691\n",
      "\n",
      "Epoch 00274: val_mae did not improve from 1.76369\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.2179 - mse: 6.2179 - mae: 2.0094 - val_loss: 4.7328 - val_mse: 4.7328 - val_mae: 1.7668\n",
      "\n",
      "Epoch 00275: val_mae did not improve from 1.76369\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6477 - mse: 5.6477 - mae: 1.8771 - val_loss: 4.7333 - val_mse: 4.7333 - val_mae: 1.7680\n",
      "\n",
      "Epoch 00276: val_mae did not improve from 1.76369\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.3988 - mse: 6.3988 - mae: 1.9937 - val_loss: 4.7274 - val_mse: 4.7274 - val_mae: 1.7655\n",
      "\n",
      "Epoch 00277: val_mae did not improve from 1.76369\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8646 - mse: 5.8646 - mae: 1.9323 - val_loss: 4.7235 - val_mse: 4.7235 - val_mae: 1.7644\n",
      "\n",
      "Epoch 00278: val_mae did not improve from 1.76369\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3775 - mse: 6.3775 - mae: 1.9739 - val_loss: 4.7309 - val_mse: 4.7309 - val_mae: 1.7691\n",
      "\n",
      "Epoch 00279: val_mae did not improve from 1.76369\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.4049 - mse: 7.4049 - mae: 2.1635 - val_loss: 4.7221 - val_mse: 4.7221 - val_mae: 1.7653\n",
      "\n",
      "Epoch 00280: val_mae did not improve from 1.76369\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0786 - mse: 6.0786 - mae: 1.9884 - val_loss: 4.7068 - val_mse: 4.7068 - val_mae: 1.7548\n",
      "\n",
      "Epoch 00281: val_mae improved from 1.76369 to 1.75484, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.5094 - mse: 6.5094 - mae: 2.0640 - val_loss: 4.7140 - val_mse: 4.7140 - val_mae: 1.7621\n",
      "\n",
      "Epoch 00282: val_mae did not improve from 1.75484\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3485 - mse: 6.3485 - mae: 2.0060 - val_loss: 4.7128 - val_mse: 4.7128 - val_mae: 1.7624\n",
      "\n",
      "Epoch 00283: val_mae did not improve from 1.75484\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0790 - mse: 6.0790 - mae: 1.9941 - val_loss: 4.7145 - val_mse: 4.7145 - val_mae: 1.7642\n",
      "\n",
      "Epoch 00284: val_mae did not improve from 1.75484\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5563 - mse: 5.5563 - mae: 1.8864 - val_loss: 4.7077 - val_mse: 4.7077 - val_mae: 1.7610\n",
      "\n",
      "Epoch 00285: val_mae did not improve from 1.75484\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5520 - mse: 5.5520 - mae: 1.9281 - val_loss: 4.7106 - val_mse: 4.7106 - val_mae: 1.7635\n",
      "\n",
      "Epoch 00286: val_mae did not improve from 1.75484\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.7248 - mse: 5.7248 - mae: 1.9328 - val_loss: 4.7204 - val_mse: 4.7204 - val_mae: 1.7689\n",
      "\n",
      "Epoch 00287: val_mae did not improve from 1.75484\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2394 - mse: 6.2394 - mae: 1.9916 - val_loss: 4.7102 - val_mse: 4.7102 - val_mae: 1.7648\n",
      "\n",
      "Epoch 00288: val_mae did not improve from 1.75484\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.1767 - mse: 6.1767 - mae: 2.0361 - val_loss: 4.6988 - val_mse: 4.6988 - val_mae: 1.7592\n",
      "\n",
      "Epoch 00289: val_mae did not improve from 1.75484\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9932 - mse: 5.9932 - mae: 1.9355 - val_loss: 4.6930 - val_mse: 4.6930 - val_mae: 1.7565\n",
      "\n",
      "Epoch 00290: val_mae did not improve from 1.75484\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.6008 - mse: 6.6008 - mae: 2.0552 - val_loss: 4.7048 - val_mse: 4.7048 - val_mae: 1.7641\n",
      "\n",
      "Epoch 00291: val_mae did not improve from 1.75484\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4541 - mse: 5.4541 - mae: 1.8325 - val_loss: 4.6897 - val_mse: 4.6897 - val_mae: 1.7565\n",
      "\n",
      "Epoch 00292: val_mae did not improve from 1.75484\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4991 - mse: 6.4991 - mae: 2.0398 - val_loss: 4.6916 - val_mse: 4.6916 - val_mae: 1.7586\n",
      "\n",
      "Epoch 00293: val_mae did not improve from 1.75484\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 6.3796 - mse: 6.3796 - mae: 2.0028 - val_loss: 4.6941 - val_mse: 4.6941 - val_mae: 1.7606\n",
      "\n",
      "Epoch 00294: val_mae did not improve from 1.75484\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 5.9810 - mse: 5.9810 - mae: 1.9541 - val_loss: 4.6906 - val_mse: 4.6906 - val_mae: 1.7592\n",
      "\n",
      "Epoch 00295: val_mae did not improve from 1.75484\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5151 - mse: 5.5151 - mae: 1.8948 - val_loss: 4.6806 - val_mse: 4.6806 - val_mae: 1.7540\n",
      "\n",
      "Epoch 00296: val_mae improved from 1.75484 to 1.75398, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9935 - mse: 5.9935 - mae: 1.9579 - val_loss: 4.6972 - val_mse: 4.6972 - val_mae: 1.7635\n",
      "\n",
      "Epoch 00297: val_mae did not improve from 1.75398\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.1144 - mse: 6.1144 - mae: 1.9935 - val_loss: 4.6909 - val_mse: 4.6909 - val_mae: 1.7611\n",
      "\n",
      "Epoch 00298: val_mae did not improve from 1.75398\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7194 - mse: 6.7194 - mae: 2.0069 - val_loss: 4.6831 - val_mse: 4.6831 - val_mae: 1.7576\n",
      "\n",
      "Epoch 00299: val_mae did not improve from 1.75398\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.1984 - mse: 6.1984 - mae: 2.0294 - val_loss: 4.6758 - val_mse: 4.6758 - val_mae: 1.7539\n",
      "\n",
      "Epoch 00300: val_mae improved from 1.75398 to 1.75385, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.3253 - mse: 6.3253 - mae: 2.0156 - val_loss: 4.6843 - val_mse: 4.6843 - val_mae: 1.7592\n",
      "\n",
      "Epoch 00301: val_mae did not improve from 1.75385\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4846 - mse: 6.4846 - mae: 2.0596 - val_loss: 4.6758 - val_mse: 4.6758 - val_mae: 1.7554\n",
      "\n",
      "Epoch 00302: val_mae did not improve from 1.75385\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6403 - mse: 6.6403 - mae: 2.0378 - val_loss: 4.6723 - val_mse: 4.6723 - val_mae: 1.7539\n",
      "\n",
      "Epoch 00303: val_mae did not improve from 1.75385\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8748 - mse: 5.8748 - mae: 1.9640 - val_loss: 4.6690 - val_mse: 4.6690 - val_mae: 1.7524\n",
      "\n",
      "Epoch 00304: val_mae improved from 1.75385 to 1.75244, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.2946 - mse: 6.2946 - mae: 2.0200 - val_loss: 4.6791 - val_mse: 4.6791 - val_mae: 1.7588\n",
      "\n",
      "Epoch 00305: val_mae did not improve from 1.75244\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8037 - mse: 5.8037 - mae: 1.9163 - val_loss: 4.6795 - val_mse: 4.6795 - val_mae: 1.7594\n",
      "\n",
      "Epoch 00306: val_mae did not improve from 1.75244\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.3324 - mse: 6.3324 - mae: 2.0310 - val_loss: 4.6587 - val_mse: 4.6587 - val_mae: 1.7476\n",
      "\n",
      "Epoch 00307: val_mae improved from 1.75244 to 1.74760, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.5530 - mse: 5.5530 - mae: 1.8865 - val_loss: 4.6563 - val_mse: 4.6563 - val_mae: 1.7461\n",
      "\n",
      "Epoch 00308: val_mae improved from 1.74760 to 1.74610, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 5.8720 - mse: 5.8720 - mae: 1.9413 - val_loss: 4.6679 - val_mse: 4.6679 - val_mae: 1.7548\n",
      "\n",
      "Epoch 00309: val_mae did not improve from 1.74610\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 6.5483 - mse: 6.5483 - mae: 2.0501 - val_loss: 4.6683 - val_mse: 4.6683 - val_mae: 1.7557\n",
      "\n",
      "Epoch 00310: val_mae did not improve from 1.74610\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.2847 - mse: 6.2847 - mae: 2.0132 - val_loss: 4.6619 - val_mse: 4.6619 - val_mae: 1.7528\n",
      "\n",
      "Epoch 00311: val_mae did not improve from 1.74610\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.9072 - mse: 5.9072 - mae: 1.9762 - val_loss: 4.6542 - val_mse: 4.6542 - val_mae: 1.7485\n",
      "\n",
      "Epoch 00312: val_mae did not improve from 1.74610\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4498 - mse: 5.4498 - mae: 1.8846 - val_loss: 4.6533 - val_mse: 4.6533 - val_mae: 1.7484\n",
      "\n",
      "Epoch 00313: val_mae did not improve from 1.74610\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1964 - mse: 6.1964 - mae: 1.9845 - val_loss: 4.6570 - val_mse: 4.6570 - val_mae: 1.7515\n",
      "\n",
      "Epoch 00314: val_mae did not improve from 1.74610\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7458 - mse: 5.7458 - mae: 1.8901 - val_loss: 4.6607 - val_mse: 4.6607 - val_mae: 1.7540\n",
      "\n",
      "Epoch 00315: val_mae did not improve from 1.74610\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2150 - mse: 6.2150 - mae: 1.9514 - val_loss: 4.6533 - val_mse: 4.6533 - val_mae: 1.7502\n",
      "\n",
      "Epoch 00316: val_mae did not improve from 1.74610\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.2642 - mse: 5.2642 - mae: 1.8406 - val_loss: 4.6471 - val_mse: 4.6471 - val_mae: 1.7468\n",
      "\n",
      "Epoch 00317: val_mae did not improve from 1.74610\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.0106 - mse: 6.0106 - mae: 1.9546 - val_loss: 4.6652 - val_mse: 4.6652 - val_mae: 1.7572\n",
      "\n",
      "Epoch 00318: val_mae did not improve from 1.74610\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6055 - mse: 6.6055 - mae: 2.0286 - val_loss: 4.6550 - val_mse: 4.6550 - val_mae: 1.7528\n",
      "\n",
      "Epoch 00319: val_mae did not improve from 1.74610\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6080 - mse: 5.6080 - mae: 1.8619 - val_loss: 4.6490 - val_mse: 4.6490 - val_mae: 1.7499\n",
      "\n",
      "Epoch 00320: val_mae did not improve from 1.74610\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.1349 - mse: 6.1349 - mae: 1.9371 - val_loss: 4.6472 - val_mse: 4.6472 - val_mae: 1.7493\n",
      "\n",
      "Epoch 00321: val_mae did not improve from 1.74610\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.2237 - mse: 6.2237 - mae: 1.9708 - val_loss: 4.6449 - val_mse: 4.6449 - val_mae: 1.7484\n",
      "\n",
      "Epoch 00322: val_mae did not improve from 1.74610\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2244 - mse: 6.2244 - mae: 1.9305 - val_loss: 4.6365 - val_mse: 4.6365 - val_mae: 1.7432\n",
      "\n",
      "Epoch 00323: val_mae improved from 1.74610 to 1.74325, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4170 - mse: 6.4170 - mae: 1.9946 - val_loss: 4.6454 - val_mse: 4.6454 - val_mae: 1.7497\n",
      "\n",
      "Epoch 00324: val_mae did not improve from 1.74325\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8547 - mse: 5.8547 - mae: 1.9379 - val_loss: 4.6443 - val_mse: 4.6443 - val_mae: 1.7495\n",
      "\n",
      "Epoch 00325: val_mae did not improve from 1.74325\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5908 - mse: 5.5908 - mae: 1.9110 - val_loss: 4.6338 - val_mse: 4.6338 - val_mae: 1.7430\n",
      "\n",
      "Epoch 00326: val_mae improved from 1.74325 to 1.74299, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1286 - mse: 6.1286 - mae: 1.9678 - val_loss: 4.6473 - val_mse: 4.6473 - val_mae: 1.7519\n",
      "\n",
      "Epoch 00327: val_mae did not improve from 1.74299\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8969 - mse: 5.8969 - mae: 1.9280 - val_loss: 4.6557 - val_mse: 4.6557 - val_mae: 1.7560\n",
      "\n",
      "Epoch 00328: val_mae did not improve from 1.74299\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6778 - mse: 5.6778 - mae: 1.8936 - val_loss: 4.6401 - val_mse: 4.6401 - val_mae: 1.7489\n",
      "\n",
      "Epoch 00329: val_mae did not improve from 1.74299\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.0541 - mse: 6.0541 - mae: 1.9600 - val_loss: 4.6343 - val_mse: 4.6343 - val_mae: 1.7458\n",
      "\n",
      "Epoch 00330: val_mae did not improve from 1.74299\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1696 - mse: 6.1696 - mae: 1.9605 - val_loss: 4.6390 - val_mse: 4.6390 - val_mae: 1.7489\n",
      "\n",
      "Epoch 00331: val_mae did not improve from 1.74299\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5623 - mse: 6.5623 - mae: 2.0151 - val_loss: 4.6310 - val_mse: 4.6310 - val_mae: 1.7445\n",
      "\n",
      "Epoch 00332: val_mae did not improve from 1.74299\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0395 - mse: 6.0395 - mae: 1.9999 - val_loss: 4.6316 - val_mse: 4.6316 - val_mae: 1.7455\n",
      "\n",
      "Epoch 00333: val_mae did not improve from 1.74299\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3095 - mse: 6.3095 - mae: 2.0341 - val_loss: 4.6276 - val_mse: 4.6276 - val_mae: 1.7435\n",
      "\n",
      "Epoch 00334: val_mae did not improve from 1.74299\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9742 - mse: 5.9742 - mae: 1.9123 - val_loss: 4.6261 - val_mse: 4.6261 - val_mae: 1.7430\n",
      "\n",
      "Epoch 00335: val_mae did not improve from 1.74299\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7675 - mse: 5.7675 - mae: 1.9088 - val_loss: 4.6302 - val_mse: 4.6302 - val_mae: 1.7459\n",
      "\n",
      "Epoch 00336: val_mae did not improve from 1.74299\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0761 - mse: 6.0761 - mae: 1.9510 - val_loss: 4.6293 - val_mse: 4.6293 - val_mae: 1.7459\n",
      "\n",
      "Epoch 00337: val_mae did not improve from 1.74299\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.3258 - mse: 6.3258 - mae: 1.9874 - val_loss: 4.6212 - val_mse: 4.6212 - val_mae: 1.7411\n",
      "\n",
      "Epoch 00338: val_mae improved from 1.74299 to 1.74110, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.4171 - mse: 5.4171 - mae: 1.8751 - val_loss: 4.6218 - val_mse: 4.6218 - val_mae: 1.7419\n",
      "\n",
      "Epoch 00339: val_mae did not improve from 1.74110\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 5.7772 - mse: 5.7772 - mae: 1.8904 - val_loss: 4.6283 - val_mse: 4.6283 - val_mae: 1.7463\n",
      "\n",
      "Epoch 00340: val_mae did not improve from 1.74110\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.0383 - mse: 6.0383 - mae: 1.9660 - val_loss: 4.6191 - val_mse: 4.6191 - val_mae: 1.7411\n",
      "\n",
      "Epoch 00341: val_mae did not improve from 1.74110\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7460 - mse: 5.7460 - mae: 1.8889 - val_loss: 4.6179 - val_mse: 4.6179 - val_mae: 1.7412\n",
      "\n",
      "Epoch 00342: val_mae did not improve from 1.74110\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1352 - mse: 6.1352 - mae: 1.9396 - val_loss: 4.6298 - val_mse: 4.6298 - val_mae: 1.7482\n",
      "\n",
      "Epoch 00343: val_mae did not improve from 1.74110\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.8729 - mse: 5.8729 - mae: 1.9418 - val_loss: 4.6190 - val_mse: 4.6190 - val_mae: 1.7426\n",
      "\n",
      "Epoch 00344: val_mae did not improve from 1.74110\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9282 - mse: 5.9282 - mae: 1.9213 - val_loss: 4.6190 - val_mse: 4.6190 - val_mae: 1.7431\n",
      "\n",
      "Epoch 00345: val_mae did not improve from 1.74110\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4529 - mse: 5.4529 - mae: 1.8574 - val_loss: 4.6173 - val_mse: 4.6173 - val_mae: 1.7425\n",
      "\n",
      "Epoch 00346: val_mae did not improve from 1.74110\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0072 - mse: 6.0072 - mae: 1.9531 - val_loss: 4.6198 - val_mse: 4.6198 - val_mae: 1.7443\n",
      "\n",
      "Epoch 00347: val_mae did not improve from 1.74110\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4217 - mse: 5.4217 - mae: 1.8817 - val_loss: 4.6321 - val_mse: 4.6321 - val_mae: 1.7509\n",
      "\n",
      "Epoch 00348: val_mae did not improve from 1.74110\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6838 - mse: 5.6838 - mae: 1.8902 - val_loss: 4.6197 - val_mse: 4.6197 - val_mae: 1.7450\n",
      "\n",
      "Epoch 00349: val_mae did not improve from 1.74110\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4786 - mse: 6.4786 - mae: 1.9573 - val_loss: 4.6122 - val_mse: 4.6122 - val_mae: 1.7410\n",
      "\n",
      "Epoch 00350: val_mae improved from 1.74110 to 1.74102, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.3821 - mse: 6.3821 - mae: 2.0438 - val_loss: 4.6066 - val_mse: 4.6066 - val_mae: 1.7379\n",
      "\n",
      "Epoch 00351: val_mae improved from 1.74102 to 1.73791, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2933 - mse: 6.2933 - mae: 2.0091 - val_loss: 4.6146 - val_mse: 4.6146 - val_mae: 1.7430\n",
      "\n",
      "Epoch 00352: val_mae did not improve from 1.73791\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8292 - mse: 5.8292 - mae: 1.8932 - val_loss: 4.6171 - val_mse: 4.6171 - val_mae: 1.7447\n",
      "\n",
      "Epoch 00353: val_mae did not improve from 1.73791\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4676 - mse: 5.4676 - mae: 1.9008 - val_loss: 4.6062 - val_mse: 4.6062 - val_mae: 1.7387\n",
      "\n",
      "Epoch 00354: val_mae did not improve from 1.73791\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2741 - mse: 6.2741 - mae: 1.9939 - val_loss: 4.6109 - val_mse: 4.6109 - val_mae: 1.7418\n",
      "\n",
      "Epoch 00355: val_mae did not improve from 1.73791\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8968 - mse: 5.8968 - mae: 1.9531 - val_loss: 4.6110 - val_mse: 4.6110 - val_mae: 1.7422\n",
      "\n",
      "Epoch 00356: val_mae did not improve from 1.73791\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2260 - mse: 6.2260 - mae: 1.9760 - val_loss: 4.6188 - val_mse: 4.6188 - val_mae: 1.7467\n",
      "\n",
      "Epoch 00357: val_mae did not improve from 1.73791\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.3888 - mse: 5.3888 - mae: 1.8309 - val_loss: 4.5993 - val_mse: 4.5993 - val_mae: 1.7355\n",
      "\n",
      "Epoch 00358: val_mae improved from 1.73791 to 1.73554, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.4104 - mse: 5.4104 - mae: 1.8373 - val_loss: 4.6110 - val_mse: 4.6110 - val_mae: 1.7431\n",
      "\n",
      "Epoch 00359: val_mae did not improve from 1.73554\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.8260 - mse: 5.8260 - mae: 1.9421 - val_loss: 4.6069 - val_mse: 4.6069 - val_mae: 1.7413\n",
      "\n",
      "Epoch 00360: val_mae did not improve from 1.73554\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.7740 - mse: 5.7740 - mae: 1.9258 - val_loss: 4.6019 - val_mse: 4.6019 - val_mae: 1.7387\n",
      "\n",
      "Epoch 00361: val_mae did not improve from 1.73554\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9427 - mse: 5.9427 - mae: 1.9463 - val_loss: 4.6094 - val_mse: 4.6094 - val_mae: 1.7431\n",
      "\n",
      "Epoch 00362: val_mae did not improve from 1.73554\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5871 - mse: 5.5871 - mae: 1.8986 - val_loss: 4.6018 - val_mse: 4.6018 - val_mae: 1.7394\n",
      "\n",
      "Epoch 00363: val_mae did not improve from 1.73554\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1492 - mse: 6.1492 - mae: 1.9802 - val_loss: 4.6003 - val_mse: 4.6003 - val_mae: 1.7387\n",
      "\n",
      "Epoch 00364: val_mae did not improve from 1.73554\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8756 - mse: 5.8756 - mae: 1.8943 - val_loss: 4.6014 - val_mse: 4.6014 - val_mae: 1.7396\n",
      "\n",
      "Epoch 00365: val_mae did not improve from 1.73554\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4939 - mse: 6.4939 - mae: 2.0285 - val_loss: 4.5939 - val_mse: 4.5939 - val_mae: 1.7353\n",
      "\n",
      "Epoch 00366: val_mae improved from 1.73554 to 1.73535, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.3763 - mse: 6.3763 - mae: 2.0030 - val_loss: 4.5918 - val_mse: 4.5918 - val_mae: 1.7338\n",
      "\n",
      "Epoch 00367: val_mae improved from 1.73535 to 1.73378, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 5.7873 - mse: 5.7873 - mae: 1.8871 - val_loss: 4.5904 - val_mse: 4.5904 - val_mae: 1.7333\n",
      "\n",
      "Epoch 00368: val_mae improved from 1.73378 to 1.73329, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5238 - mse: 6.5238 - mae: 2.0084 - val_loss: 4.6092 - val_mse: 4.6092 - val_mae: 1.7447\n",
      "\n",
      "Epoch 00369: val_mae did not improve from 1.73329\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.3088 - mse: 6.3088 - mae: 2.0348 - val_loss: 4.6052 - val_mse: 4.6052 - val_mae: 1.7429\n",
      "\n",
      "Epoch 00370: val_mae did not improve from 1.73329\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0393 - mse: 6.0393 - mae: 1.9424 - val_loss: 4.6071 - val_mse: 4.6071 - val_mae: 1.7441\n",
      "\n",
      "Epoch 00371: val_mae did not improve from 1.73329\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6067 - mse: 5.6067 - mae: 1.8858 - val_loss: 4.5903 - val_mse: 4.5903 - val_mae: 1.7350\n",
      "\n",
      "Epoch 00372: val_mae did not improve from 1.73329\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6937 - mse: 5.6937 - mae: 1.9265 - val_loss: 4.5936 - val_mse: 4.5936 - val_mae: 1.7372\n",
      "\n",
      "Epoch 00373: val_mae did not improve from 1.73329\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.9778 - mse: 5.9778 - mae: 1.9708 - val_loss: 4.5955 - val_mse: 4.5955 - val_mae: 1.7385\n",
      "\n",
      "Epoch 00374: val_mae did not improve from 1.73329\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8319 - mse: 5.8319 - mae: 1.9380 - val_loss: 4.5962 - val_mse: 4.5962 - val_mae: 1.7392\n",
      "\n",
      "Epoch 00375: val_mae did not improve from 1.73329\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0973 - mse: 6.0973 - mae: 1.9836 - val_loss: 4.5950 - val_mse: 4.5950 - val_mae: 1.7387\n",
      "\n",
      "Epoch 00376: val_mae did not improve from 1.73329\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6358 - mse: 5.6358 - mae: 1.8790 - val_loss: 4.5941 - val_mse: 4.5941 - val_mae: 1.7383\n",
      "\n",
      "Epoch 00377: val_mae did not improve from 1.73329\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2821 - mse: 6.2821 - mae: 2.0160 - val_loss: 4.5960 - val_mse: 4.5960 - val_mae: 1.7396\n",
      "\n",
      "Epoch 00378: val_mae did not improve from 1.73329\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6085 - mse: 5.6085 - mae: 1.9245 - val_loss: 4.5884 - val_mse: 4.5884 - val_mae: 1.7356\n",
      "\n",
      "Epoch 00379: val_mae did not improve from 1.73329\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1514 - mse: 6.1514 - mae: 2.0012 - val_loss: 4.5848 - val_mse: 4.5848 - val_mae: 1.7333\n",
      "\n",
      "Epoch 00380: val_mae did not improve from 1.73329\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0220 - mse: 6.0220 - mae: 1.9539 - val_loss: 4.5843 - val_mse: 4.5843 - val_mae: 1.7334\n",
      "\n",
      "Epoch 00381: val_mae did not improve from 1.73329\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6084 - mse: 5.6084 - mae: 1.8870 - val_loss: 4.5799 - val_mse: 4.5799 - val_mae: 1.7296\n",
      "\n",
      "Epoch 00382: val_mae improved from 1.73329 to 1.72965, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.7196 - mse: 5.7196 - mae: 1.8963 - val_loss: 4.5877 - val_mse: 4.5877 - val_mae: 1.7360\n",
      "\n",
      "Epoch 00383: val_mae did not improve from 1.72965\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.9678 - mse: 5.9678 - mae: 1.9600 - val_loss: 4.5868 - val_mse: 4.5868 - val_mae: 1.7358\n",
      "\n",
      "Epoch 00384: val_mae did not improve from 1.72965\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3282 - mse: 6.3282 - mae: 2.0059 - val_loss: 4.5837 - val_mse: 4.5837 - val_mae: 1.7342\n",
      "\n",
      "Epoch 00385: val_mae did not improve from 1.72965\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7826 - mse: 5.7826 - mae: 1.9096 - val_loss: 4.5782 - val_mse: 4.5782 - val_mae: 1.7299\n",
      "\n",
      "Epoch 00386: val_mae did not improve from 1.72965\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.4467 - mse: 5.4467 - mae: 1.8455 - val_loss: 4.5871 - val_mse: 4.5871 - val_mae: 1.7365\n",
      "\n",
      "Epoch 00387: val_mae did not improve from 1.72965\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5936 - mse: 5.5936 - mae: 1.8899 - val_loss: 4.5782 - val_mse: 4.5782 - val_mae: 1.7305\n",
      "\n",
      "Epoch 00388: val_mae did not improve from 1.72965\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7761 - mse: 5.7761 - mae: 1.8802 - val_loss: 4.5972 - val_mse: 4.5972 - val_mae: 1.7422\n",
      "\n",
      "Epoch 00389: val_mae did not improve from 1.72965\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 6.8518 - mse: 6.8518 - mae: 2.0913 - val_loss: 4.5787 - val_mse: 4.5787 - val_mae: 1.7317\n",
      "\n",
      "Epoch 00390: val_mae did not improve from 1.72965\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4941 - mse: 5.4941 - mae: 1.8747 - val_loss: 4.5754 - val_mse: 4.5754 - val_mae: 1.7291\n",
      "\n",
      "Epoch 00391: val_mae improved from 1.72965 to 1.72911, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.6481 - mse: 5.6481 - mae: 1.9214 - val_loss: 4.5813 - val_mse: 4.5813 - val_mae: 1.7339\n",
      "\n",
      "Epoch 00392: val_mae did not improve from 1.72911\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 5.8008 - mse: 5.8008 - mae: 1.9110 - val_loss: 4.5815 - val_mse: 4.5815 - val_mae: 1.7342\n",
      "\n",
      "Epoch 00393: val_mae did not improve from 1.72911\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.3599 - mse: 5.3599 - mae: 1.8453 - val_loss: 4.5819 - val_mse: 4.5819 - val_mae: 1.7348\n",
      "\n",
      "Epoch 00394: val_mae did not improve from 1.72911\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6411 - mse: 5.6411 - mae: 1.8591 - val_loss: 4.5849 - val_mse: 4.5849 - val_mae: 1.7367\n",
      "\n",
      "Epoch 00395: val_mae did not improve from 1.72911\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7372 - mse: 5.7372 - mae: 1.9277 - val_loss: 4.5818 - val_mse: 4.5818 - val_mae: 1.7351\n",
      "\n",
      "Epoch 00396: val_mae did not improve from 1.72911\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4562 - mse: 5.4562 - mae: 1.8369 - val_loss: 4.5747 - val_mse: 4.5747 - val_mae: 1.7305\n",
      "\n",
      "Epoch 00397: val_mae did not improve from 1.72911\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.7232 - mse: 5.7232 - mae: 1.9313 - val_loss: 4.5910 - val_mse: 4.5910 - val_mae: 1.7403\n",
      "\n",
      "Epoch 00398: val_mae did not improve from 1.72911\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.9264 - mse: 6.9264 - mae: 2.1055 - val_loss: 4.5889 - val_mse: 4.5889 - val_mae: 1.7394\n",
      "\n",
      "Epoch 00399: val_mae did not improve from 1.72911\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9624 - mse: 5.9624 - mae: 1.9418 - val_loss: 4.5756 - val_mse: 4.5756 - val_mae: 1.7319\n",
      "\n",
      "Epoch 00400: val_mae did not improve from 1.72911\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7308 - mse: 5.7308 - mae: 1.9179 - val_loss: 4.5745 - val_mse: 4.5745 - val_mae: 1.7314\n",
      "\n",
      "Epoch 00401: val_mae did not improve from 1.72911\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.0966 - mse: 6.0966 - mae: 1.9704 - val_loss: 4.5760 - val_mse: 4.5760 - val_mae: 1.7328\n",
      "\n",
      "Epoch 00402: val_mae did not improve from 1.72911\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8782 - mse: 5.8782 - mae: 1.9161 - val_loss: 4.5715 - val_mse: 4.5715 - val_mae: 1.7298\n",
      "\n",
      "Epoch 00403: val_mae did not improve from 1.72911\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2834 - mse: 6.2834 - mae: 1.9804 - val_loss: 4.5762 - val_mse: 4.5762 - val_mae: 1.7332\n",
      "\n",
      "Epoch 00404: val_mae did not improve from 1.72911\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2543 - mse: 6.2543 - mae: 2.0231 - val_loss: 4.5814 - val_mse: 4.5814 - val_mae: 1.7363\n",
      "\n",
      "Epoch 00405: val_mae did not improve from 1.72911\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4818 - mse: 6.4818 - mae: 2.0514 - val_loss: 4.5711 - val_mse: 4.5711 - val_mae: 1.7299\n",
      "\n",
      "Epoch 00406: val_mae did not improve from 1.72911\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1455 - mse: 6.1455 - mae: 1.9431 - val_loss: 4.5704 - val_mse: 4.5704 - val_mae: 1.7299\n",
      "\n",
      "Epoch 00407: val_mae did not improve from 1.72911\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.8670 - mse: 5.8670 - mae: 1.9504 - val_loss: 4.5715 - val_mse: 4.5715 - val_mae: 1.7308\n",
      "\n",
      "Epoch 00408: val_mae did not improve from 1.72911\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6180 - mse: 6.6180 - mae: 1.9984 - val_loss: 4.5773 - val_mse: 4.5773 - val_mae: 1.7347\n",
      "\n",
      "Epoch 00409: val_mae did not improve from 1.72911\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5359 - mse: 5.5359 - mae: 1.9123 - val_loss: 4.5669 - val_mse: 4.5669 - val_mae: 1.7271\n",
      "\n",
      "Epoch 00410: val_mae improved from 1.72911 to 1.72711, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3850 - mse: 6.3850 - mae: 1.9737 - val_loss: 4.5763 - val_mse: 4.5763 - val_mae: 1.7343\n",
      "\n",
      "Epoch 00411: val_mae did not improve from 1.72711\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1421 - mse: 6.1421 - mae: 1.9600 - val_loss: 4.5722 - val_mse: 4.5722 - val_mae: 1.7318\n",
      "\n",
      "Epoch 00412: val_mae did not improve from 1.72711\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6513 - mse: 6.6513 - mae: 2.0545 - val_loss: 4.5804 - val_mse: 4.5804 - val_mae: 1.7369\n",
      "\n",
      "Epoch 00413: val_mae did not improve from 1.72711\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.5184 - mse: 6.5184 - mae: 1.9946 - val_loss: 4.5732 - val_mse: 4.5732 - val_mae: 1.7329\n",
      "\n",
      "Epoch 00414: val_mae did not improve from 1.72711\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7534 - mse: 5.7534 - mae: 1.9424 - val_loss: 4.5677 - val_mse: 4.5677 - val_mae: 1.7293\n",
      "\n",
      "Epoch 00415: val_mae did not improve from 1.72711\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.6492 - mse: 6.6492 - mae: 2.0374 - val_loss: 4.5772 - val_mse: 4.5772 - val_mae: 1.7354\n",
      "\n",
      "Epoch 00416: val_mae did not improve from 1.72711\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.4264 - mse: 6.4264 - mae: 2.0128 - val_loss: 4.5652 - val_mse: 4.5652 - val_mae: 1.7279\n",
      "\n",
      "Epoch 00417: val_mae did not improve from 1.72711\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5030 - mse: 6.5030 - mae: 2.0344 - val_loss: 4.5635 - val_mse: 4.5635 - val_mae: 1.7263\n",
      "\n",
      "Epoch 00418: val_mae improved from 1.72711 to 1.72628, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7164 - mse: 5.7164 - mae: 1.9136 - val_loss: 4.5620 - val_mse: 4.5620 - val_mae: 1.7249\n",
      "\n",
      "Epoch 00419: val_mae improved from 1.72628 to 1.72488, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.3407 - mse: 6.3407 - mae: 1.9720 - val_loss: 4.5745 - val_mse: 4.5745 - val_mae: 1.7344\n",
      "\n",
      "Epoch 00420: val_mae did not improve from 1.72488\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2067 - mse: 6.2067 - mae: 1.9789 - val_loss: 4.5673 - val_mse: 4.5673 - val_mae: 1.7299\n",
      "\n",
      "Epoch 00421: val_mae did not improve from 1.72488\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.3396 - mse: 5.3396 - mae: 1.8401 - val_loss: 4.5698 - val_mse: 4.5698 - val_mae: 1.7317\n",
      "\n",
      "Epoch 00422: val_mae did not improve from 1.72488\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.7502 - mse: 5.7502 - mae: 1.8851 - val_loss: 4.5837 - val_mse: 4.5837 - val_mae: 1.7394\n",
      "\n",
      "Epoch 00423: val_mae did not improve from 1.72488\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2133 - mse: 6.2133 - mae: 1.9920 - val_loss: 4.5828 - val_mse: 4.5828 - val_mae: 1.7392\n",
      "\n",
      "Epoch 00424: val_mae did not improve from 1.72488\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.3522 - mse: 6.3522 - mae: 1.9355 - val_loss: 4.5675 - val_mse: 4.5675 - val_mae: 1.7307\n",
      "\n",
      "Epoch 00425: val_mae did not improve from 1.72488\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7525 - mse: 5.7525 - mae: 1.9455 - val_loss: 4.5704 - val_mse: 4.5704 - val_mae: 1.7327\n",
      "\n",
      "Epoch 00426: val_mae did not improve from 1.72488\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3238 - mse: 6.3238 - mae: 1.9871 - val_loss: 4.5743 - val_mse: 4.5743 - val_mae: 1.7351\n",
      "\n",
      "Epoch 00427: val_mae did not improve from 1.72488\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9050 - mse: 5.9050 - mae: 1.9274 - val_loss: 4.5659 - val_mse: 4.5659 - val_mae: 1.7301\n",
      "\n",
      "Epoch 00428: val_mae did not improve from 1.72488\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7601 - mse: 5.7601 - mae: 1.9014 - val_loss: 4.5621 - val_mse: 4.5621 - val_mae: 1.7274\n",
      "\n",
      "Epoch 00429: val_mae did not improve from 1.72488\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6671 - mse: 5.6671 - mae: 1.8887 - val_loss: 4.5681 - val_mse: 4.5681 - val_mae: 1.7317\n",
      "\n",
      "Epoch 00430: val_mae did not improve from 1.72488\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1787 - mse: 6.1787 - mae: 1.9589 - val_loss: 4.5714 - val_mse: 4.5714 - val_mae: 1.7335\n",
      "\n",
      "Epoch 00431: val_mae did not improve from 1.72488\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7282 - mse: 5.7282 - mae: 1.8905 - val_loss: 4.5689 - val_mse: 4.5689 - val_mae: 1.7323\n",
      "\n",
      "Epoch 00432: val_mae did not improve from 1.72488\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.1164 - mse: 6.1164 - mae: 1.9836 - val_loss: 4.5713 - val_mse: 4.5713 - val_mae: 1.7339\n",
      "\n",
      "Epoch 00433: val_mae did not improve from 1.72488\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6709 - mse: 6.6709 - mae: 2.0263 - val_loss: 4.5647 - val_mse: 4.5647 - val_mae: 1.7301\n",
      "\n",
      "Epoch 00434: val_mae did not improve from 1.72488\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0291 - mse: 6.0291 - mae: 1.9488 - val_loss: 4.5589 - val_mse: 4.5589 - val_mae: 1.7257\n",
      "\n",
      "Epoch 00435: val_mae did not improve from 1.72488\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.5447 - mse: 5.5447 - mae: 1.9018 - val_loss: 4.5644 - val_mse: 4.5644 - val_mae: 1.7303\n",
      "\n",
      "Epoch 00436: val_mae did not improve from 1.72488\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9260 - mse: 5.9260 - mae: 1.9057 - val_loss: 4.5727 - val_mse: 4.5727 - val_mae: 1.7353\n",
      "\n",
      "Epoch 00437: val_mae did not improve from 1.72488\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3230 - mse: 6.3230 - mae: 1.9783 - val_loss: 4.5661 - val_mse: 4.5661 - val_mae: 1.7315\n",
      "\n",
      "Epoch 00438: val_mae did not improve from 1.72488\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 6.0037 - mse: 6.0037 - mae: 1.9479 - val_loss: 4.5642 - val_mse: 4.5642 - val_mae: 1.7307\n",
      "\n",
      "Epoch 00439: val_mae did not improve from 1.72488\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2162 - mse: 6.2162 - mae: 1.9852 - val_loss: 4.5648 - val_mse: 4.5648 - val_mae: 1.7311\n",
      "\n",
      "Epoch 00440: val_mae did not improve from 1.72488\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4058 - mse: 6.4058 - mae: 1.9832 - val_loss: 4.5610 - val_mse: 4.5610 - val_mae: 1.7290\n",
      "\n",
      "Epoch 00441: val_mae did not improve from 1.72488\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3902 - mse: 6.3902 - mae: 2.0137 - val_loss: 4.5531 - val_mse: 4.5531 - val_mae: 1.7216\n",
      "\n",
      "Epoch 00442: val_mae improved from 1.72488 to 1.72163, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3486 - mse: 6.3486 - mae: 1.9797 - val_loss: 4.5621 - val_mse: 4.5621 - val_mae: 1.7298\n",
      "\n",
      "Epoch 00443: val_mae did not improve from 1.72163\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.8228 - mse: 5.8228 - mae: 1.9183 - val_loss: 4.5591 - val_mse: 4.5591 - val_mae: 1.7280\n",
      "\n",
      "Epoch 00444: val_mae did not improve from 1.72163\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5534 - mse: 6.5534 - mae: 2.0085 - val_loss: 4.5606 - val_mse: 4.5606 - val_mae: 1.7291\n",
      "\n",
      "Epoch 00445: val_mae did not improve from 1.72163\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1365 - mse: 6.1365 - mae: 1.9260 - val_loss: 4.5635 - val_mse: 4.5635 - val_mae: 1.7310\n",
      "\n",
      "Epoch 00446: val_mae did not improve from 1.72163\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.4626 - mse: 5.4626 - mae: 1.8514 - val_loss: 4.5557 - val_mse: 4.5557 - val_mae: 1.7257\n",
      "\n",
      "Epoch 00447: val_mae did not improve from 1.72163\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5812 - mse: 5.5812 - mae: 1.9016 - val_loss: 4.5661 - val_mse: 4.5661 - val_mae: 1.7328\n",
      "\n",
      "Epoch 00448: val_mae did not improve from 1.72163\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4337 - mse: 5.4337 - mae: 1.9019 - val_loss: 4.5562 - val_mse: 4.5562 - val_mae: 1.7264\n",
      "\n",
      "Epoch 00449: val_mae did not improve from 1.72163\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.4010 - mse: 5.4010 - mae: 1.8617 - val_loss: 4.5685 - val_mse: 4.5685 - val_mae: 1.7344\n",
      "\n",
      "Epoch 00450: val_mae did not improve from 1.72163\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8756 - mse: 5.8756 - mae: 1.9011 - val_loss: 4.5667 - val_mse: 4.5667 - val_mae: 1.7334\n",
      "\n",
      "Epoch 00451: val_mae did not improve from 1.72163\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7315 - mse: 5.7315 - mae: 1.9027 - val_loss: 4.5639 - val_mse: 4.5639 - val_mae: 1.7319\n",
      "\n",
      "Epoch 00452: val_mae did not improve from 1.72163\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5665 - mse: 5.5665 - mae: 1.8865 - val_loss: 4.5579 - val_mse: 4.5579 - val_mae: 1.7284\n",
      "\n",
      "Epoch 00453: val_mae did not improve from 1.72163\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.5977 - mse: 6.5977 - mae: 2.0239 - val_loss: 4.5698 - val_mse: 4.5698 - val_mae: 1.7354\n",
      "\n",
      "Epoch 00454: val_mae did not improve from 1.72163\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2152 - mse: 6.2152 - mae: 2.0215 - val_loss: 4.5524 - val_mse: 4.5524 - val_mae: 1.7245\n",
      "\n",
      "Epoch 00455: val_mae did not improve from 1.72163\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8951 - mse: 5.8951 - mae: 1.9140 - val_loss: 4.5560 - val_mse: 4.5560 - val_mae: 1.7274\n",
      "\n",
      "Epoch 00456: val_mae did not improve from 1.72163\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7417 - mse: 5.7417 - mae: 1.9171 - val_loss: 4.5518 - val_mse: 4.5518 - val_mae: 1.7240\n",
      "\n",
      "Epoch 00457: val_mae did not improve from 1.72163\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1510 - mse: 6.1510 - mae: 1.9622 - val_loss: 4.5631 - val_mse: 4.5631 - val_mae: 1.7320\n",
      "\n",
      "Epoch 00458: val_mae did not improve from 1.72163\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5739 - mse: 5.5739 - mae: 1.8711 - val_loss: 4.5569 - val_mse: 4.5569 - val_mae: 1.7282\n",
      "\n",
      "Epoch 00459: val_mae did not improve from 1.72163\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.4544 - mse: 6.4544 - mae: 1.9494 - val_loss: 4.5557 - val_mse: 4.5557 - val_mae: 1.7274\n",
      "\n",
      "Epoch 00460: val_mae did not improve from 1.72163\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4907 - mse: 5.4907 - mae: 1.8647 - val_loss: 4.5586 - val_mse: 4.5586 - val_mae: 1.7291\n",
      "\n",
      "Epoch 00461: val_mae did not improve from 1.72163\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1131 - mse: 6.1131 - mae: 1.9581 - val_loss: 4.5693 - val_mse: 4.5693 - val_mae: 1.7354\n",
      "\n",
      "Epoch 00462: val_mae did not improve from 1.72163\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.7295 - mse: 5.7295 - mae: 1.9243 - val_loss: 4.5548 - val_mse: 4.5548 - val_mae: 1.7269\n",
      "\n",
      "Epoch 00463: val_mae did not improve from 1.72163\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8682 - mse: 5.8682 - mae: 1.9205 - val_loss: 4.5646 - val_mse: 4.5646 - val_mae: 1.7331\n",
      "\n",
      "Epoch 00464: val_mae did not improve from 1.72163\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.3481 - mse: 5.3481 - mae: 1.8515 - val_loss: 4.5557 - val_mse: 4.5557 - val_mae: 1.7276\n",
      "\n",
      "Epoch 00465: val_mae did not improve from 1.72163\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4715 - mse: 5.4715 - mae: 1.8458 - val_loss: 4.5576 - val_mse: 4.5576 - val_mae: 1.7291\n",
      "\n",
      "Epoch 00466: val_mae did not improve from 1.72163\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9808 - mse: 5.9808 - mae: 1.9337 - val_loss: 4.5602 - val_mse: 4.5602 - val_mae: 1.7311\n",
      "\n",
      "Epoch 00467: val_mae did not improve from 1.72163\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.4625 - mse: 6.4625 - mae: 2.0493 - val_loss: 4.5620 - val_mse: 4.5620 - val_mae: 1.7321\n",
      "\n",
      "Epoch 00468: val_mae did not improve from 1.72163\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.8580 - mse: 5.8580 - mae: 1.9094 - val_loss: 4.5492 - val_mse: 4.5492 - val_mae: 1.7235\n",
      "\n",
      "Epoch 00469: val_mae did not improve from 1.72163\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.6671 - mse: 5.6671 - mae: 1.8812 - val_loss: 4.5466 - val_mse: 4.5466 - val_mae: 1.7209\n",
      "\n",
      "Epoch 00470: val_mae improved from 1.72163 to 1.72085, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.3644 - mse: 6.3644 - mae: 1.9778 - val_loss: 4.5543 - val_mse: 4.5543 - val_mae: 1.7277\n",
      "\n",
      "Epoch 00471: val_mae did not improve from 1.72085\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8392 - mse: 5.8392 - mae: 1.9247 - val_loss: 4.5533 - val_mse: 4.5533 - val_mae: 1.7270\n",
      "\n",
      "Epoch 00472: val_mae did not improve from 1.72085\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4474 - mse: 6.4474 - mae: 1.9658 - val_loss: 4.5565 - val_mse: 4.5565 - val_mae: 1.7291\n",
      "\n",
      "Epoch 00473: val_mae did not improve from 1.72085\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.9566 - mse: 5.9566 - mae: 1.8969 - val_loss: 4.5543 - val_mse: 4.5543 - val_mae: 1.7278\n",
      "\n",
      "Epoch 00474: val_mae did not improve from 1.72085\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1551 - mse: 6.1551 - mae: 1.9638 - val_loss: 4.5539 - val_mse: 4.5539 - val_mae: 1.7276\n",
      "\n",
      "Epoch 00475: val_mae did not improve from 1.72085\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0653 - mse: 6.0653 - mae: 1.9308 - val_loss: 4.5560 - val_mse: 4.5560 - val_mae: 1.7291\n",
      "\n",
      "Epoch 00476: val_mae did not improve from 1.72085\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2747 - mse: 6.2747 - mae: 1.9661 - val_loss: 4.5507 - val_mse: 4.5507 - val_mae: 1.7257\n",
      "\n",
      "Epoch 00477: val_mae did not improve from 1.72085\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4292 - mse: 5.4292 - mae: 1.8681 - val_loss: 4.5523 - val_mse: 4.5523 - val_mae: 1.7270\n",
      "\n",
      "Epoch 00478: val_mae did not improve from 1.72085\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6943 - mse: 6.6943 - mae: 2.0180 - val_loss: 4.5533 - val_mse: 4.5533 - val_mae: 1.7276\n",
      "\n",
      "Epoch 00479: val_mae did not improve from 1.72085\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8303 - mse: 5.8303 - mae: 1.9431 - val_loss: 4.5483 - val_mse: 4.5483 - val_mae: 1.7241\n",
      "\n",
      "Epoch 00480: val_mae did not improve from 1.72085\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1127 - mse: 6.1127 - mae: 1.9645 - val_loss: 4.5492 - val_mse: 4.5492 - val_mae: 1.7254\n",
      "\n",
      "Epoch 00481: val_mae did not improve from 1.72085\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8331 - mse: 5.8331 - mae: 1.9114 - val_loss: 4.5553 - val_mse: 4.5553 - val_mae: 1.7293\n",
      "\n",
      "Epoch 00482: val_mae did not improve from 1.72085\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7840 - mse: 5.7840 - mae: 1.9344 - val_loss: 4.5487 - val_mse: 4.5487 - val_mae: 1.7252\n",
      "\n",
      "Epoch 00483: val_mae did not improve from 1.72085\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4935 - mse: 5.4935 - mae: 1.8665 - val_loss: 4.5549 - val_mse: 4.5549 - val_mae: 1.7293\n",
      "\n",
      "Epoch 00484: val_mae did not improve from 1.72085\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.0012 - mse: 6.0012 - mae: 1.9627 - val_loss: 4.5588 - val_mse: 4.5588 - val_mae: 1.7316\n",
      "\n",
      "Epoch 00485: val_mae did not improve from 1.72085\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7772 - mse: 5.7772 - mae: 1.8976 - val_loss: 4.5521 - val_mse: 4.5521 - val_mae: 1.7277\n",
      "\n",
      "Epoch 00486: val_mae did not improve from 1.72085\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7829 - mse: 5.7829 - mae: 1.8938 - val_loss: 4.5453 - val_mse: 4.5453 - val_mae: 1.7227\n",
      "\n",
      "Epoch 00487: val_mae did not improve from 1.72085\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.3682 - mse: 5.3682 - mae: 1.8188 - val_loss: 4.5486 - val_mse: 4.5486 - val_mae: 1.7255\n",
      "\n",
      "Epoch 00488: val_mae did not improve from 1.72085\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.1570 - mse: 6.1570 - mae: 1.9495 - val_loss: 4.5513 - val_mse: 4.5513 - val_mae: 1.7273\n",
      "\n",
      "Epoch 00489: val_mae did not improve from 1.72085\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.2573 - mse: 5.2573 - mae: 1.8254 - val_loss: 4.5441 - val_mse: 4.5441 - val_mae: 1.7218\n",
      "\n",
      "Epoch 00490: val_mae did not improve from 1.72085\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.2870 - mse: 6.2870 - mae: 1.9433 - val_loss: 4.5548 - val_mse: 4.5548 - val_mae: 1.7295\n",
      "\n",
      "Epoch 00491: val_mae did not improve from 1.72085\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.7130 - mse: 6.7130 - mae: 2.0990 - val_loss: 4.5607 - val_mse: 4.5607 - val_mae: 1.7330\n",
      "\n",
      "Epoch 00492: val_mae did not improve from 1.72085\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9364 - mse: 5.9364 - mae: 1.9199 - val_loss: 4.5577 - val_mse: 4.5577 - val_mae: 1.7315\n",
      "\n",
      "Epoch 00493: val_mae did not improve from 1.72085\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7430 - mse: 5.7430 - mae: 1.9700 - val_loss: 4.5481 - val_mse: 4.5481 - val_mae: 1.7256\n",
      "\n",
      "Epoch 00494: val_mae did not improve from 1.72085\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.1773 - mse: 6.1773 - mae: 1.9557 - val_loss: 4.5508 - val_mse: 4.5508 - val_mae: 1.7277\n",
      "\n",
      "Epoch 00495: val_mae did not improve from 1.72085\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.9988 - mse: 5.9988 - mae: 1.9788 - val_loss: 4.5442 - val_mse: 4.5442 - val_mae: 1.7233\n",
      "\n",
      "Epoch 00496: val_mae did not improve from 1.72085\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0540 - mse: 6.0540 - mae: 1.9415 - val_loss: 4.5422 - val_mse: 4.5422 - val_mae: 1.7213\n",
      "\n",
      "Epoch 00497: val_mae did not improve from 1.72085\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8243 - mse: 5.8243 - mae: 1.9265 - val_loss: 4.5458 - val_mse: 4.5458 - val_mae: 1.7245\n",
      "\n",
      "Epoch 00498: val_mae did not improve from 1.72085\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3025 - mse: 6.3025 - mae: 1.9735 - val_loss: 4.5478 - val_mse: 4.5478 - val_mae: 1.7258\n",
      "\n",
      "Epoch 00499: val_mae did not improve from 1.72085\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0125 - mse: 6.0125 - mae: 1.9227 - val_loss: 4.5571 - val_mse: 4.5571 - val_mae: 1.7318\n",
      "\n",
      "Epoch 00500: val_mae did not improve from 1.72085\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0332 - mse: 6.0332 - mae: 2.0132 - val_loss: 4.5444 - val_mse: 4.5444 - val_mae: 1.7237\n",
      "\n",
      "Epoch 00501: val_mae did not improve from 1.72085\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6116 - mse: 5.6116 - mae: 1.8797 - val_loss: 4.5459 - val_mse: 4.5459 - val_mae: 1.7249\n",
      "\n",
      "Epoch 00502: val_mae did not improve from 1.72085\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0193 - mse: 6.0193 - mae: 1.9343 - val_loss: 4.5543 - val_mse: 4.5543 - val_mae: 1.7304\n",
      "\n",
      "Epoch 00503: val_mae did not improve from 1.72085\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7155 - mse: 5.7155 - mae: 1.9484 - val_loss: 4.5447 - val_mse: 4.5447 - val_mae: 1.7241\n",
      "\n",
      "Epoch 00504: val_mae did not improve from 1.72085\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7159 - mse: 5.7159 - mae: 1.9037 - val_loss: 4.5407 - val_mse: 4.5407 - val_mae: 1.7202\n",
      "\n",
      "Epoch 00505: val_mae improved from 1.72085 to 1.72019, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.1421 - mse: 6.1421 - mae: 1.9682 - val_loss: 4.5540 - val_mse: 4.5540 - val_mae: 1.7301\n",
      "\n",
      "Epoch 00506: val_mae did not improve from 1.72019\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.3265 - mse: 5.3265 - mae: 1.8569 - val_loss: 4.5459 - val_mse: 4.5459 - val_mae: 1.7247\n",
      "\n",
      "Epoch 00507: val_mae did not improve from 1.72019\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1434 - mse: 6.1434 - mae: 1.9790 - val_loss: 4.5675 - val_mse: 4.5675 - val_mae: 1.7370\n",
      "\n",
      "Epoch 00508: val_mae did not improve from 1.72019\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4109 - mse: 6.4109 - mae: 2.0118 - val_loss: 4.5572 - val_mse: 4.5572 - val_mae: 1.7320\n",
      "\n",
      "Epoch 00509: val_mae did not improve from 1.72019\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6968 - mse: 5.6968 - mae: 1.9118 - val_loss: 4.5474 - val_mse: 4.5474 - val_mae: 1.7262\n",
      "\n",
      "Epoch 00510: val_mae did not improve from 1.72019\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6800 - mse: 6.6800 - mae: 2.0667 - val_loss: 4.5412 - val_mse: 4.5412 - val_mae: 1.7217\n",
      "\n",
      "Epoch 00511: val_mae did not improve from 1.72019\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9530 - mse: 5.9530 - mae: 1.9286 - val_loss: 4.5419 - val_mse: 4.5419 - val_mae: 1.7223\n",
      "\n",
      "Epoch 00512: val_mae did not improve from 1.72019\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.1683 - mse: 6.1683 - mae: 1.9650 - val_loss: 4.5414 - val_mse: 4.5414 - val_mae: 1.7221\n",
      "\n",
      "Epoch 00513: val_mae did not improve from 1.72019\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9902 - mse: 5.9902 - mae: 1.9419 - val_loss: 4.5437 - val_mse: 4.5437 - val_mae: 1.7239\n",
      "\n",
      "Epoch 00514: val_mae did not improve from 1.72019\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.6142 - mse: 5.6142 - mae: 1.8769 - val_loss: 4.5455 - val_mse: 4.5455 - val_mae: 1.7253\n",
      "\n",
      "Epoch 00515: val_mae did not improve from 1.72019\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0669 - mse: 6.0669 - mae: 1.9722 - val_loss: 4.5506 - val_mse: 4.5506 - val_mae: 1.7288\n",
      "\n",
      "Epoch 00516: val_mae did not improve from 1.72019\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0731 - mse: 6.0731 - mae: 1.9522 - val_loss: 4.5411 - val_mse: 4.5411 - val_mae: 1.7223\n",
      "\n",
      "Epoch 00517: val_mae did not improve from 1.72019\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0459 - mse: 6.0459 - mae: 1.9461 - val_loss: 4.5416 - val_mse: 4.5416 - val_mae: 1.7227\n",
      "\n",
      "Epoch 00518: val_mae did not improve from 1.72019\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4934 - mse: 6.4934 - mae: 2.0732 - val_loss: 4.5572 - val_mse: 4.5572 - val_mae: 1.7326\n",
      "\n",
      "Epoch 00519: val_mae did not improve from 1.72019\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8586 - mse: 5.8586 - mae: 1.8938 - val_loss: 4.5407 - val_mse: 4.5407 - val_mae: 1.7220\n",
      "\n",
      "Epoch 00520: val_mae did not improve from 1.72019\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.6628 - mse: 5.6628 - mae: 1.8608 - val_loss: 4.5469 - val_mse: 4.5469 - val_mae: 1.7265\n",
      "\n",
      "Epoch 00521: val_mae did not improve from 1.72019\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9606 - mse: 5.9606 - mae: 1.9300 - val_loss: 4.5439 - val_mse: 4.5439 - val_mae: 1.7245\n",
      "\n",
      "Epoch 00522: val_mae did not improve from 1.72019\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.8329 - mse: 6.8329 - mae: 2.0312 - val_loss: 4.5509 - val_mse: 4.5509 - val_mae: 1.7291\n",
      "\n",
      "Epoch 00523: val_mae did not improve from 1.72019\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1717 - mse: 6.1717 - mae: 1.9383 - val_loss: 4.5496 - val_mse: 4.5496 - val_mae: 1.7283\n",
      "\n",
      "Epoch 00524: val_mae did not improve from 1.72019\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4023 - mse: 6.4023 - mae: 1.9770 - val_loss: 4.5442 - val_mse: 4.5442 - val_mae: 1.7247\n",
      "\n",
      "Epoch 00525: val_mae did not improve from 1.72019\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1708 - mse: 6.1708 - mae: 1.9887 - val_loss: 4.5419 - val_mse: 4.5419 - val_mae: 1.7231\n",
      "\n",
      "Epoch 00526: val_mae did not improve from 1.72019\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.1769 - mse: 6.1769 - mae: 1.9659 - val_loss: 4.5392 - val_mse: 4.5392 - val_mae: 1.7209\n",
      "\n",
      "Epoch 00527: val_mae did not improve from 1.72019\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4876 - mse: 5.4876 - mae: 1.8501 - val_loss: 4.5386 - val_mse: 4.5386 - val_mae: 1.7203\n",
      "\n",
      "Epoch 00528: val_mae did not improve from 1.72019\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.4453 - mse: 6.4453 - mae: 1.9705 - val_loss: 4.5576 - val_mse: 4.5576 - val_mae: 1.7329\n",
      "\n",
      "Epoch 00529: val_mae did not improve from 1.72019\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.1752 - mse: 6.1752 - mae: 1.9791 - val_loss: 4.5412 - val_mse: 4.5412 - val_mae: 1.7228\n",
      "\n",
      "Epoch 00530: val_mae did not improve from 1.72019\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.5331 - mse: 6.5331 - mae: 2.0210 - val_loss: 4.5406 - val_mse: 4.5406 - val_mae: 1.7223\n",
      "\n",
      "Epoch 00531: val_mae did not improve from 1.72019\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.9225 - mse: 5.9225 - mae: 1.9102 - val_loss: 4.5410 - val_mse: 4.5410 - val_mae: 1.7225\n",
      "\n",
      "Epoch 00532: val_mae did not improve from 1.72019\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8410 - mse: 5.8410 - mae: 1.9373 - val_loss: 4.5451 - val_mse: 4.5451 - val_mae: 1.7255\n",
      "\n",
      "Epoch 00533: val_mae did not improve from 1.72019\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3675 - mse: 6.3675 - mae: 1.9701 - val_loss: 4.5453 - val_mse: 4.5453 - val_mae: 1.7258\n",
      "\n",
      "Epoch 00534: val_mae did not improve from 1.72019\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5119 - mse: 5.5119 - mae: 1.8776 - val_loss: 4.5473 - val_mse: 4.5473 - val_mae: 1.7271\n",
      "\n",
      "Epoch 00535: val_mae did not improve from 1.72019\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7878 - mse: 5.7878 - mae: 1.8355 - val_loss: 4.5412 - val_mse: 4.5412 - val_mae: 1.7227\n",
      "\n",
      "Epoch 00536: val_mae did not improve from 1.72019\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 6.3710 - mse: 6.3710 - mae: 1.9807 - val_loss: 4.5422 - val_mse: 4.5422 - val_mae: 1.7235\n",
      "\n",
      "Epoch 00537: val_mae did not improve from 1.72019\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.0043 - mse: 6.0043 - mae: 1.9532 - val_loss: 4.5493 - val_mse: 4.5493 - val_mae: 1.7285\n",
      "\n",
      "Epoch 00538: val_mae did not improve from 1.72019\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8284 - mse: 5.8284 - mae: 1.8958 - val_loss: 4.5400 - val_mse: 4.5400 - val_mae: 1.7222\n",
      "\n",
      "Epoch 00539: val_mae did not improve from 1.72019\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3803 - mse: 6.3803 - mae: 1.9624 - val_loss: 4.5351 - val_mse: 4.5351 - val_mae: 1.7160\n",
      "\n",
      "Epoch 00540: val_mae improved from 1.72019 to 1.71602, saving model to /home/m-marouni/Documents/CE-901/Heathrow/best_weights\n",
      "INFO:tensorflow:Assets written to: /home/m-marouni/Documents/CE-901/Heathrow/best_weights/assets\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6359 - mse: 5.6359 - mae: 1.9021 - val_loss: 4.5379 - val_mse: 4.5379 - val_mae: 1.7200\n",
      "\n",
      "Epoch 00541: val_mae did not improve from 1.71602\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.2368 - mse: 6.2368 - mae: 2.0017 - val_loss: 4.5557 - val_mse: 4.5557 - val_mae: 1.7322\n",
      "\n",
      "Epoch 00542: val_mae did not improve from 1.71602\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 6.2850 - mse: 6.2850 - mae: 1.9907 - val_loss: 4.5536 - val_mse: 4.5536 - val_mae: 1.7312\n",
      "\n",
      "Epoch 00543: val_mae did not improve from 1.71602\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0190 - mse: 6.0190 - mae: 1.9152 - val_loss: 4.5433 - val_mse: 4.5433 - val_mae: 1.7248\n",
      "\n",
      "Epoch 00544: val_mae did not improve from 1.71602\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.6877 - mse: 5.6877 - mae: 1.9151 - val_loss: 4.5375 - val_mse: 4.5375 - val_mae: 1.7201\n",
      "\n",
      "Epoch 00545: val_mae did not improve from 1.71602\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.7013 - mse: 5.7013 - mae: 1.9252 - val_loss: 4.5430 - val_mse: 4.5430 - val_mae: 1.7246\n",
      "\n",
      "Epoch 00546: val_mae did not improve from 1.71602\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1454 - mse: 6.1454 - mae: 1.9613 - val_loss: 4.5402 - val_mse: 4.5402 - val_mae: 1.7228\n",
      "\n",
      "Epoch 00547: val_mae did not improve from 1.71602\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.4461 - mse: 5.4461 - mae: 1.8586 - val_loss: 4.5404 - val_mse: 4.5404 - val_mae: 1.7232\n",
      "\n",
      "Epoch 00548: val_mae did not improve from 1.71602\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.9444 - mse: 5.9444 - mae: 1.9279 - val_loss: 4.5458 - val_mse: 4.5458 - val_mae: 1.7269\n",
      "\n",
      "Epoch 00549: val_mae did not improve from 1.71602\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.5026 - mse: 5.5026 - mae: 1.9015 - val_loss: 4.5441 - val_mse: 4.5441 - val_mae: 1.7260\n",
      "\n",
      "Epoch 00550: val_mae did not improve from 1.71602\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5532 - mse: 5.5532 - mae: 1.8621 - val_loss: 4.5456 - val_mse: 4.5456 - val_mae: 1.7270\n",
      "\n",
      "Epoch 00551: val_mae did not improve from 1.71602\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 5.7349 - mse: 5.7349 - mae: 1.9089 - val_loss: 4.5461 - val_mse: 4.5461 - val_mae: 1.7275\n",
      "\n",
      "Epoch 00552: val_mae did not improve from 1.71602\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.7619 - mse: 5.7619 - mae: 1.8894 - val_loss: 4.5422 - val_mse: 4.5422 - val_mae: 1.7248\n",
      "\n",
      "Epoch 00553: val_mae did not improve from 1.71602\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 5.8938 - mse: 5.8938 - mae: 1.9436 - val_loss: 4.5442 - val_mse: 4.5442 - val_mae: 1.7264\n",
      "\n",
      "Epoch 00554: val_mae did not improve from 1.71602\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.0721 - mse: 6.0721 - mae: 1.9432 - val_loss: 4.5378 - val_mse: 4.5378 - val_mae: 1.7219\n",
      "\n",
      "Epoch 00555: val_mae did not improve from 1.71602\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8065 - mse: 5.8065 - mae: 1.8907 - val_loss: 4.5348 - val_mse: 4.5348 - val_mae: 1.7191\n",
      "\n",
      "Epoch 00556: val_mae did not improve from 1.71602\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 6.0589 - mse: 6.0589 - mae: 1.9535 - val_loss: 4.5482 - val_mse: 4.5482 - val_mae: 1.7290\n",
      "\n",
      "Epoch 00557: val_mae did not improve from 1.71602\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.8674 - mse: 5.8674 - mae: 1.9072 - val_loss: 4.5407 - val_mse: 4.5407 - val_mae: 1.7240\n",
      "\n",
      "Epoch 00558: val_mae did not improve from 1.71602\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.4265 - mse: 5.4265 - mae: 1.8851 - val_loss: 4.5393 - val_mse: 4.5393 - val_mae: 1.7233\n",
      "\n",
      "Epoch 00559: val_mae did not improve from 1.71602\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.0470 - mse: 6.0470 - mae: 1.9695 - val_loss: 4.5507 - val_mse: 4.5507 - val_mae: 1.7305\n",
      "\n",
      "Epoch 00560: val_mae did not improve from 1.71602\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.6337 - mse: 6.6337 - mae: 2.0368 - val_loss: 4.5434 - val_mse: 4.5434 - val_mae: 1.7262\n",
      "\n",
      "Epoch 00561: val_mae did not improve from 1.71602\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2170 - mse: 6.2170 - mae: 1.9939 - val_loss: 4.5332 - val_mse: 4.5332 - val_mae: 1.7178\n",
      "\n",
      "Epoch 00562: val_mae did not improve from 1.71602\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.0212 - mse: 6.0212 - mae: 1.9502 - val_loss: 4.5440 - val_mse: 4.5440 - val_mae: 1.7267\n",
      "\n",
      "Epoch 00563: val_mae did not improve from 1.71602\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.0535 - mse: 6.0535 - mae: 1.9699 - val_loss: 4.5382 - val_mse: 4.5382 - val_mae: 1.7227\n",
      "\n",
      "Epoch 00564: val_mae did not improve from 1.71602\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.7959 - mse: 5.7959 - mae: 1.8711 - val_loss: 4.5453 - val_mse: 4.5453 - val_mae: 1.7276\n",
      "\n",
      "Epoch 00565: val_mae did not improve from 1.71602\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0353 - mse: 6.0353 - mae: 1.9116 - val_loss: 4.5471 - val_mse: 4.5471 - val_mae: 1.7288\n",
      "\n",
      "Epoch 00566: val_mae did not improve from 1.71602\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.2438 - mse: 6.2438 - mae: 1.9874 - val_loss: 4.5373 - val_mse: 4.5373 - val_mae: 1.7223\n",
      "\n",
      "Epoch 00567: val_mae did not improve from 1.71602\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 5.9949 - mse: 5.9949 - mae: 1.9228 - val_loss: 4.5387 - val_mse: 4.5387 - val_mae: 1.7233\n",
      "\n",
      "Epoch 00568: val_mae did not improve from 1.71602\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4415 - mse: 6.4415 - mae: 1.9872 - val_loss: 4.5366 - val_mse: 4.5366 - val_mae: 1.7217\n",
      "\n",
      "Epoch 00569: val_mae did not improve from 1.71602\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6717 - mse: 5.6717 - mae: 1.9069 - val_loss: 4.5373 - val_mse: 4.5373 - val_mae: 1.7222\n",
      "\n",
      "Epoch 00570: val_mae did not improve from 1.71602\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7576 - mse: 5.7576 - mae: 1.8775 - val_loss: 4.5422 - val_mse: 4.5422 - val_mae: 1.7256\n",
      "\n",
      "Epoch 00571: val_mae did not improve from 1.71602\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7511 - mse: 5.7511 - mae: 1.9204 - val_loss: 4.5428 - val_mse: 4.5428 - val_mae: 1.7261\n",
      "\n",
      "Epoch 00572: val_mae did not improve from 1.71602\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.2465 - mse: 6.2465 - mae: 1.9676 - val_loss: 4.5494 - val_mse: 4.5494 - val_mae: 1.7301\n",
      "\n",
      "Epoch 00573: val_mae did not improve from 1.71602\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6018 - mse: 5.6018 - mae: 1.9101 - val_loss: 4.5363 - val_mse: 4.5363 - val_mae: 1.7216\n",
      "\n",
      "Epoch 00574: val_mae did not improve from 1.71602\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.4803 - mse: 5.4803 - mae: 1.8350 - val_loss: 4.5506 - val_mse: 4.5506 - val_mae: 1.7308\n",
      "\n",
      "Epoch 00575: val_mae did not improve from 1.71602\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.5951 - mse: 6.5951 - mae: 2.0370 - val_loss: 4.5360 - val_mse: 4.5360 - val_mae: 1.7213\n",
      "\n",
      "Epoch 00576: val_mae did not improve from 1.71602\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4865 - mse: 6.4865 - mae: 1.9940 - val_loss: 4.5467 - val_mse: 4.5467 - val_mae: 1.7286\n",
      "\n",
      "Epoch 00577: val_mae did not improve from 1.71602\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0444 - mse: 6.0444 - mae: 1.9745 - val_loss: 4.5400 - val_mse: 4.5400 - val_mae: 1.7242\n",
      "\n",
      "Epoch 00578: val_mae did not improve from 1.71602\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.9483 - mse: 5.9483 - mae: 1.9011 - val_loss: 4.5382 - val_mse: 4.5382 - val_mae: 1.7230\n",
      "\n",
      "Epoch 00579: val_mae did not improve from 1.71602\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.2135 - mse: 6.2135 - mae: 1.9615 - val_loss: 4.5369 - val_mse: 4.5369 - val_mae: 1.7221\n",
      "\n",
      "Epoch 00580: val_mae did not improve from 1.71602\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.4558 - mse: 5.4558 - mae: 1.8637 - val_loss: 4.5332 - val_mse: 4.5332 - val_mae: 1.7189\n",
      "\n",
      "Epoch 00581: val_mae did not improve from 1.71602\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.7010 - mse: 5.7010 - mae: 1.8869 - val_loss: 4.5444 - val_mse: 4.5444 - val_mae: 1.7273\n",
      "\n",
      "Epoch 00582: val_mae did not improve from 1.71602\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.4460 - mse: 5.4460 - mae: 1.8668 - val_loss: 4.5406 - val_mse: 4.5406 - val_mae: 1.7248\n",
      "\n",
      "Epoch 00583: val_mae did not improve from 1.71602\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.4647 - mse: 6.4647 - mae: 1.9929 - val_loss: 4.5430 - val_mse: 4.5430 - val_mae: 1.7265\n",
      "\n",
      "Epoch 00584: val_mae did not improve from 1.71602\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.8430 - mse: 6.8430 - mae: 2.0917 - val_loss: 4.5387 - val_mse: 4.5387 - val_mae: 1.7237\n",
      "\n",
      "Epoch 00585: val_mae did not improve from 1.71602\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.6491 - mse: 5.6491 - mae: 1.8782 - val_loss: 4.5341 - val_mse: 4.5341 - val_mae: 1.7204\n",
      "\n",
      "Epoch 00586: val_mae did not improve from 1.71602\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.1094 - mse: 6.1094 - mae: 1.9584 - val_loss: 4.5358 - val_mse: 4.5358 - val_mae: 1.7219\n",
      "\n",
      "Epoch 00587: val_mae did not improve from 1.71602\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.9751 - mse: 6.9751 - mae: 2.0866 - val_loss: 4.5408 - val_mse: 4.5408 - val_mae: 1.7252\n",
      "\n",
      "Epoch 00588: val_mae did not improve from 1.71602\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.4348 - mse: 5.4348 - mae: 1.8297 - val_loss: 4.5358 - val_mse: 4.5358 - val_mae: 1.7216\n",
      "\n",
      "Epoch 00589: val_mae did not improve from 1.71602\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.0367 - mse: 6.0367 - mae: 1.9711 - val_loss: 4.5392 - val_mse: 4.5392 - val_mae: 1.7241\n",
      "\n",
      "Epoch 00590: val_mae did not improve from 1.71602\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.7496 - mse: 5.7496 - mae: 1.9237 - val_loss: 4.5356 - val_mse: 4.5356 - val_mae: 1.7216\n",
      "\n",
      "Epoch 00591: val_mae did not improve from 1.71602\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.5384 - mse: 5.5384 - mae: 1.8767 - val_loss: 4.5431 - val_mse: 4.5431 - val_mae: 1.7269\n",
      "\n",
      "Epoch 00592: val_mae did not improve from 1.71602\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.7872 - mse: 5.7872 - mae: 1.8800 - val_loss: 4.5410 - val_mse: 4.5410 - val_mae: 1.7255\n",
      "\n",
      "Epoch 00593: val_mae did not improve from 1.71602\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.6669 - mse: 6.6669 - mae: 1.9908 - val_loss: 4.5411 - val_mse: 4.5411 - val_mae: 1.7256\n",
      "\n",
      "Epoch 00594: val_mae did not improve from 1.71602\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.4457 - mse: 6.4457 - mae: 2.0135 - val_loss: 4.5381 - val_mse: 4.5381 - val_mae: 1.7238\n",
      "\n",
      "Epoch 00595: val_mae did not improve from 1.71602\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.9201 - mse: 5.9201 - mae: 1.8973 - val_loss: 4.5344 - val_mse: 4.5344 - val_mae: 1.7211\n",
      "\n",
      "Epoch 00596: val_mae did not improve from 1.71602\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.1245 - mse: 6.1245 - mae: 1.9816 - val_loss: 4.5339 - val_mse: 4.5339 - val_mae: 1.7208\n",
      "\n",
      "Epoch 00597: val_mae did not improve from 1.71602\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.8221 - mse: 5.8221 - mae: 1.9024 - val_loss: 4.5382 - val_mse: 4.5382 - val_mae: 1.7240\n",
      "\n",
      "Epoch 00598: val_mae did not improve from 1.71602\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.1404 - mse: 6.1404 - mae: 1.9443 - val_loss: 4.5420 - val_mse: 4.5420 - val_mae: 1.7265\n",
      "\n",
      "Epoch 00599: val_mae did not improve from 1.71602\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5515 - mse: 6.5515 - mae: 1.9980 - val_loss: 4.5357 - val_mse: 4.5357 - val_mae: 1.7223\n",
      "\n",
      "Epoch 00600: val_mae did not improve from 1.71602\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1820 - mse: 6.1820 - mae: 1.9371 - val_loss: 4.5367 - val_mse: 4.5367 - val_mae: 1.7229\n",
      "\n",
      "Epoch 00601: val_mae did not improve from 1.71602\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.4995 - mse: 6.4995 - mae: 1.9506 - val_loss: 4.5380 - val_mse: 4.5380 - val_mae: 1.7239\n",
      "\n",
      "Epoch 00602: val_mae did not improve from 1.71602\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.7550 - mse: 5.7550 - mae: 1.9490 - val_loss: 4.5369 - val_mse: 4.5369 - val_mae: 1.7232\n",
      "\n",
      "Epoch 00603: val_mae did not improve from 1.71602\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.3794 - mse: 6.3794 - mae: 1.9904 - val_loss: 4.5362 - val_mse: 4.5362 - val_mae: 1.7226\n",
      "\n",
      "Epoch 00604: val_mae did not improve from 1.71602\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.4168 - mse: 5.4168 - mae: 1.8640 - val_loss: 4.5326 - val_mse: 4.5326 - val_mae: 1.7198\n",
      "\n",
      "Epoch 00605: val_mae did not improve from 1.71602\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.4161 - mse: 6.4161 - mae: 2.0107 - val_loss: 4.5448 - val_mse: 4.5448 - val_mae: 1.7282\n",
      "\n",
      "Epoch 00606: val_mae did not improve from 1.71602\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1117 - mse: 6.1117 - mae: 1.9574 - val_loss: 4.5427 - val_mse: 4.5427 - val_mae: 1.7269\n",
      "\n",
      "Epoch 00607: val_mae did not improve from 1.71602\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.7216 - mse: 5.7216 - mae: 1.8972 - val_loss: 4.5348 - val_mse: 4.5348 - val_mae: 1.7217\n",
      "\n",
      "Epoch 00608: val_mae did not improve from 1.71602\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.9958 - mse: 5.9958 - mae: 1.9535 - val_loss: 4.5341 - val_mse: 4.5341 - val_mae: 1.7212\n",
      "\n",
      "Epoch 00609: val_mae did not improve from 1.71602\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7426 - mse: 5.7426 - mae: 1.9335 - val_loss: 4.5333 - val_mse: 4.5333 - val_mae: 1.7208\n",
      "\n",
      "Epoch 00610: val_mae did not improve from 1.71602\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.0524 - mse: 6.0524 - mae: 1.9185 - val_loss: 4.5354 - val_mse: 4.5354 - val_mae: 1.7222\n",
      "\n",
      "Epoch 00611: val_mae did not improve from 1.71602\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.3807 - mse: 5.3807 - mae: 1.8474 - val_loss: 4.5371 - val_mse: 4.5371 - val_mae: 1.7234\n",
      "\n",
      "Epoch 00612: val_mae did not improve from 1.71602\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.5622 - mse: 6.5622 - mae: 2.0161 - val_loss: 4.5386 - val_mse: 4.5386 - val_mae: 1.7243\n",
      "\n",
      "Epoch 00613: val_mae did not improve from 1.71602\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.5583 - mse: 5.5583 - mae: 1.9087 - val_loss: 4.5370 - val_mse: 4.5370 - val_mae: 1.7233\n",
      "\n",
      "Epoch 00614: val_mae did not improve from 1.71602\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.0710 - mse: 6.0710 - mae: 1.9665 - val_loss: 4.5405 - val_mse: 4.5405 - val_mae: 1.7256\n",
      "\n",
      "Epoch 00615: val_mae did not improve from 1.71602\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.1816 - mse: 6.1816 - mae: 1.9806 - val_loss: 4.5395 - val_mse: 4.5395 - val_mae: 1.7249\n",
      "\n",
      "Epoch 00616: val_mae did not improve from 1.71602\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6551 - mse: 5.6551 - mae: 1.9387 - val_loss: 4.5402 - val_mse: 4.5402 - val_mae: 1.7254\n",
      "\n",
      "Epoch 00617: val_mae did not improve from 1.71602\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.3976 - mse: 6.3976 - mae: 2.0257 - val_loss: 4.5351 - val_mse: 4.5351 - val_mae: 1.7221\n",
      "\n",
      "Epoch 00618: val_mae did not improve from 1.71602\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3093 - mse: 6.3093 - mae: 1.9811 - val_loss: 4.5357 - val_mse: 4.5357 - val_mae: 1.7226\n",
      "\n",
      "Epoch 00619: val_mae did not improve from 1.71602\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.3385 - mse: 6.3385 - mae: 1.9675 - val_loss: 4.5379 - val_mse: 4.5379 - val_mae: 1.7240\n",
      "\n",
      "Epoch 00620: val_mae did not improve from 1.71602\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.7209 - mse: 5.7209 - mae: 1.9302 - val_loss: 4.5305 - val_mse: 4.5305 - val_mae: 1.7179\n",
      "\n",
      "Epoch 00621: val_mae did not improve from 1.71602\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.4725 - mse: 6.4725 - mae: 1.9872 - val_loss: 4.5321 - val_mse: 4.5321 - val_mae: 1.7196\n",
      "\n",
      "Epoch 00622: val_mae did not improve from 1.71602\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.1474 - mse: 6.1474 - mae: 1.9813 - val_loss: 4.5330 - val_mse: 4.5330 - val_mae: 1.7203\n",
      "\n",
      "Epoch 00623: val_mae did not improve from 1.71602\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1983 - mse: 6.1983 - mae: 1.9917 - val_loss: 4.5347 - val_mse: 4.5347 - val_mae: 1.7219\n",
      "\n",
      "Epoch 00624: val_mae did not improve from 1.71602\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.0117 - mse: 6.0117 - mae: 1.9582 - val_loss: 4.5375 - val_mse: 4.5375 - val_mae: 1.7238\n",
      "\n",
      "Epoch 00625: val_mae did not improve from 1.71602\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.5020 - mse: 5.5020 - mae: 1.8622 - val_loss: 4.5310 - val_mse: 4.5310 - val_mae: 1.7187\n",
      "\n",
      "Epoch 00626: val_mae did not improve from 1.71602\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.2651 - mse: 6.2651 - mae: 1.9724 - val_loss: 4.5311 - val_mse: 4.5311 - val_mae: 1.7187\n",
      "\n",
      "Epoch 00627: val_mae did not improve from 1.71602\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.7590 - mse: 6.7590 - mae: 2.0385 - val_loss: 4.5350 - val_mse: 4.5350 - val_mae: 1.7221\n",
      "\n",
      "Epoch 00628: val_mae did not improve from 1.71602\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.0447 - mse: 6.0447 - mae: 1.9165 - val_loss: 4.5336 - val_mse: 4.5336 - val_mae: 1.7211\n",
      "\n",
      "Epoch 00629: val_mae did not improve from 1.71602\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.4601 - mse: 6.4601 - mae: 2.0476 - val_loss: 4.5390 - val_mse: 4.5390 - val_mae: 1.7247\n",
      "\n",
      "Epoch 00630: val_mae did not improve from 1.71602\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.1061 - mse: 6.1061 - mae: 1.9803 - val_loss: 4.5427 - val_mse: 4.5427 - val_mae: 1.7273\n",
      "\n",
      "Epoch 00631: val_mae did not improve from 1.71602\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8739 - mse: 5.8739 - mae: 1.9478 - val_loss: 4.5358 - val_mse: 4.5358 - val_mae: 1.7229\n",
      "\n",
      "Epoch 00632: val_mae did not improve from 1.71602\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.5389 - mse: 5.5389 - mae: 1.8508 - val_loss: 4.5371 - val_mse: 4.5371 - val_mae: 1.7238\n",
      "\n",
      "Epoch 00633: val_mae did not improve from 1.71602\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.2475 - mse: 6.2475 - mae: 2.0240 - val_loss: 4.5376 - val_mse: 4.5376 - val_mae: 1.7241\n",
      "\n",
      "Epoch 00634: val_mae did not improve from 1.71602\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8675 - mse: 5.8675 - mae: 1.9733 - val_loss: 4.5320 - val_mse: 4.5320 - val_mae: 1.7201\n",
      "\n",
      "Epoch 00635: val_mae did not improve from 1.71602\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.1896 - mse: 6.1896 - mae: 1.9428 - val_loss: 4.5339 - val_mse: 4.5339 - val_mae: 1.7217\n",
      "\n",
      "Epoch 00636: val_mae did not improve from 1.71602\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.6431 - mse: 5.6431 - mae: 1.8369 - val_loss: 4.5374 - val_mse: 4.5374 - val_mae: 1.7241\n",
      "\n",
      "Epoch 00637: val_mae did not improve from 1.71602\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.3187 - mse: 6.3187 - mae: 1.9756 - val_loss: 4.5389 - val_mse: 4.5389 - val_mae: 1.7251\n",
      "\n",
      "Epoch 00638: val_mae did not improve from 1.71602\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 6.6938 - mse: 6.6938 - mae: 2.0428 - val_loss: 4.5398 - val_mse: 4.5398 - val_mae: 1.7258\n",
      "\n",
      "Epoch 00639: val_mae did not improve from 1.71602\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 5.8180 - mse: 5.8180 - mae: 1.9289 - val_loss: 4.5304 - val_mse: 4.5304 - val_mae: 1.7191\n",
      "\n",
      "Epoch 00640: val_mae did not improve from 1.71602\n",
      "Epoch 00640: early stopping\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def show_info(model, X, y, log, weights = None):\n",
    "    '''\n",
    "    Show metrics about the evaluation model and plots about loss, rmse and rmspe\n",
    "    '''\n",
    "    if (log != None):\n",
    "        # summarize history for loss\n",
    "        plt.figure(figsize=(14,10))\n",
    "        plt.plot(log.history['loss'])\n",
    "        plt.plot(log.history['val_loss'])\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "        print('\\n')\n",
    "\n",
    "        # summarize history for MAE\n",
    "        plt.figure(figsize=(14,10))\n",
    "        plt.plot(log.history['mae'])\n",
    "        plt.plot(log.history['val_mae'])\n",
    "        plt.title('Model MAE')\n",
    "        plt.ylabel('MAE')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "        print('\\n')\n",
    "\n",
    "        # summarize history for MSE\n",
    "        plt.figure(figsize=(14,10))\n",
    "        plt.plot(log.history['mse'])\n",
    "        plt.plot(log.history['val_mse'])\n",
    "        plt.title('Model MSE')\n",
    "        plt.ylabel('MSE')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "        print('\\n')\n",
    "    if (weights != None):\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    predictions = model.predict(X, verbose=1)\n",
    "\n",
    "    mse = mean_squared_error(y, predictions)\n",
    "    mae= mean_absolute_error(y, predictions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "show_info(model, x_test, y_test, log, weights='/home/m-marouni/Documents/CE-901/Heathrow/best_weights')"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"603.474375pt\" version=\"1.1\" viewBox=\"0 0 829.003125 603.474375\" width=\"829.003125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-08-13T20:23:45.579130</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 603.474375 \nL 829.003125 603.474375 \nL 829.003125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 40.603125 565.918125 \nL 821.803125 565.918125 \nL 821.803125 22.318125 \nL 40.603125 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m48d3f6f217\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"76.112216\" xlink:href=\"#m48d3f6f217\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(72.930966 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"183.878804\" xlink:href=\"#m48d3f6f217\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 100 -->\n      <g transform=\"translate(174.335054 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"291.645393\" xlink:href=\"#m48d3f6f217\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 200 -->\n      <g transform=\"translate(282.101643 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"399.411981\" xlink:href=\"#m48d3f6f217\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 300 -->\n      <g transform=\"translate(389.868231 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"507.17857\" xlink:href=\"#m48d3f6f217\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 400 -->\n      <g transform=\"translate(497.63482 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"614.945158\" xlink:href=\"#m48d3f6f217\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 500 -->\n      <g transform=\"translate(605.401408 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"722.711747\" xlink:href=\"#m48d3f6f217\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 600 -->\n      <g transform=\"translate(713.167997 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- epoch -->\n     <g transform=\"translate(415.975 594.194687)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n       <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n       <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m80da27e630\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m80da27e630\" y=\"522.911538\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 5 -->\n      <g transform=\"translate(27.240625 526.710756)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m80da27e630\" y=\"458.026506\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 10 -->\n      <g transform=\"translate(20.878125 461.825725)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m80da27e630\" y=\"393.141475\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 15 -->\n      <g transform=\"translate(20.878125 396.940693)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m80da27e630\" y=\"328.256443\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 20 -->\n      <g transform=\"translate(20.878125 332.055662)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m80da27e630\" y=\"263.371411\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 25 -->\n      <g transform=\"translate(20.878125 267.17063)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m80da27e630\" y=\"198.48638\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 30 -->\n      <g transform=\"translate(20.878125 202.285599)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m80da27e630\" y=\"133.601348\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 35 -->\n      <g transform=\"translate(20.878125 137.400567)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#m80da27e630\" y=\"68.716317\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 40 -->\n      <g transform=\"translate(20.878125 72.515536)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_17\">\n     <!-- loss -->\n     <g transform=\"translate(14.798438 303.775937)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-108\"/>\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"88.964844\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"141.064453\" xlink:href=\"#DejaVuSans-115\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#pf52b4f76f4)\" d=\"M 76.112216 47.027216 \nL 78.267548 158.239116 \nL 80.422879 251.733669 \nL 81.500545 294.118685 \nL 83.655877 366.636044 \nL 84.733543 394.76662 \nL 86.888875 442.835797 \nL 87.966541 461.489216 \nL 90.121872 481.918098 \nL 91.199538 490.527108 \nL 93.35487 498.694115 \nL 94.432536 500.872275 \nL 95.510202 500.697516 \nL 96.587868 502.999242 \nL 97.665534 503.038523 \nL 98.743199 503.631901 \nL 99.820865 504.811677 \nL 100.898531 504.898945 \nL 101.976197 505.505361 \nL 103.053863 504.129137 \nL 104.131529 505.296884 \nL 105.209195 504.899032 \nL 106.286861 506.34435 \nL 107.364527 505.664069 \nL 108.442192 504.1378 \nL 109.519858 505.068234 \nL 110.597524 505.054868 \nL 111.67519 504.78601 \nL 112.752856 506.42996 \nL 113.830522 506.62332 \nL 114.908188 503.725431 \nL 115.985854 505.657368 \nL 117.06352 502.424755 \nL 118.141185 504.86076 \nL 119.218851 506.517235 \nL 121.374183 506.369727 \nL 122.451849 506.959634 \nL 123.529515 504.711024 \nL 124.607181 507.248152 \nL 125.684847 505.450041 \nL 126.762513 507.87599 \nL 127.840178 504.631794 \nL 128.917844 508.331662 \nL 129.99551 504.227859 \nL 132.150842 508.298526 \nL 133.228508 507.672265 \nL 134.306174 507.718087 \nL 135.38384 507.569038 \nL 136.461505 507.110229 \nL 137.539171 508.586159 \nL 138.616837 507.489425 \nL 139.694503 508.090395 \nL 140.772169 508.440848 \nL 141.849835 509.844299 \nL 142.927501 507.843572 \nL 144.005167 504.321711 \nL 145.082833 504.129286 \nL 146.160498 509.179655 \nL 147.238164 508.606728 \nL 148.31583 504.130109 \nL 149.393496 507.196928 \nL 150.471162 505.854187 \nL 151.548828 507.69125 \nL 152.626494 507.239841 \nL 153.70416 508.419104 \nL 154.781826 506.781589 \nL 155.859491 509.694174 \nL 156.937157 506.41954 \nL 158.014823 510.141375 \nL 159.092489 508.852623 \nL 160.170155 506.544777 \nL 161.247821 507.862606 \nL 162.325487 509.592104 \nL 163.403153 508.082543 \nL 164.480818 509.914959 \nL 165.558484 508.932831 \nL 167.713816 509.949327 \nL 168.791482 513.539297 \nL 169.869148 509.305789 \nL 170.946814 509.228465 \nL 172.02448 510.77094 \nL 173.102146 507.850719 \nL 174.179811 507.275601 \nL 175.257477 509.039715 \nL 176.335143 511.315724 \nL 177.412809 510.299414 \nL 178.490475 511.29333 \nL 179.568141 510.422294 \nL 180.645807 511.2546 \nL 181.723473 510.409312 \nL 182.801139 510.638444 \nL 183.878804 508.415756 \nL 184.95647 511.764868 \nL 186.034136 508.44052 \nL 187.111802 508.84909 \nL 188.189468 510.291073 \nL 189.267134 510.721709 \nL 190.3448 507.879573 \nL 191.422466 510.182506 \nL 192.500131 511.653294 \nL 194.655463 511.320545 \nL 195.733129 509.821484 \nL 196.810795 512.192695 \nL 197.888461 512.926823 \nL 198.966127 513.860871 \nL 200.043793 508.273057 \nL 201.121459 509.512416 \nL 202.199124 513.12285 \nL 203.27679 508.555943 \nL 204.354456 512.443454 \nL 205.432122 510.912185 \nL 206.509788 511.180079 \nL 207.587454 511.302878 \nL 208.66512 513.609512 \nL 209.742786 509.69142 \nL 210.820452 511.858677 \nL 211.898117 509.93278 \nL 212.975783 514.041335 \nL 214.053449 512.601481 \nL 215.131115 512.40757 \nL 216.208781 511.771947 \nL 217.286447 513.353573 \nL 218.364113 512.236171 \nL 219.441779 511.998586 \nL 220.519444 511.970722 \nL 221.59711 515.559164 \nL 222.674776 514.873295 \nL 223.752442 514.447566 \nL 224.830108 512.061585 \nL 225.907774 516.496386 \nL 226.98544 513.429319 \nL 228.063106 515.191775 \nL 229.140772 514.047802 \nL 230.218437 514.654342 \nL 231.296103 515.757183 \nL 232.373769 513.396251 \nL 233.451435 514.367841 \nL 234.529101 514.346944 \nL 235.606767 513.230675 \nL 236.684433 516.359305 \nL 237.762099 517.654164 \nL 238.839765 514.495826 \nL 239.91743 516.134801 \nL 240.995096 515.223073 \nL 242.072762 513.458403 \nL 243.150428 517.792774 \nL 244.228094 513.880375 \nL 245.30576 514.899538 \nL 246.383426 514.628971 \nL 247.461092 515.559374 \nL 248.538758 516.760059 \nL 249.616423 513.73572 \nL 250.694089 517.670636 \nL 251.771755 515.278894 \nL 252.849421 515.178644 \nL 253.927087 515.243005 \nL 255.004753 514.547185 \nL 256.082419 517.499138 \nL 257.160085 513.672734 \nL 258.23775 517.792279 \nL 259.315416 517.983021 \nL 260.393082 515.858913 \nL 261.470748 514.224615 \nL 262.548414 514.36729 \nL 263.62608 516.577312 \nL 264.703746 517.866818 \nL 265.781412 515.444137 \nL 266.859078 515.756868 \nL 267.936743 518.960372 \nL 269.014409 516.504177 \nL 270.092075 518.328883 \nL 271.169741 516.296108 \nL 272.247407 519.361108 \nL 273.325073 518.023175 \nL 274.402739 517.418794 \nL 275.480405 517.746339 \nL 276.558071 520.331695 \nL 277.635736 518.18919 \nL 278.713402 518.917688 \nL 279.791068 516.952547 \nL 280.868734 517.256881 \nL 281.9464 517.826207 \nL 283.024066 520.644049 \nL 284.101732 518.807252 \nL 285.179398 517.803194 \nL 286.257063 519.263073 \nL 287.334729 517.310252 \nL 288.412395 516.973252 \nL 289.490061 518.154934 \nL 290.567727 519.769418 \nL 292.723059 516.60491 \nL 293.800725 518.349408 \nL 294.878391 519.258456 \nL 295.956056 519.455406 \nL 297.033722 517.438138 \nL 299.189054 520.615758 \nL 300.26672 520.292037 \nL 301.344386 519.051421 \nL 302.422052 521.388982 \nL 303.499718 520.227355 \nL 304.577384 520.806185 \nL 305.655049 519.02808 \nL 306.732715 520.99772 \nL 307.810381 518.001028 \nL 308.888047 520.064946 \nL 309.965713 519.069471 \nL 311.043379 521.624401 \nL 312.121045 520.914393 \nL 313.198711 520.753192 \nL 314.276376 517.507529 \nL 315.354042 521.684238 \nL 316.431708 519.565284 \nL 317.509374 518.08264 \nL 318.58704 520.920173 \nL 319.664706 518.407946 \nL 320.742372 520.324666 \nL 321.820038 519.488214 \nL 322.897704 519.927222 \nL 323.975369 521.018276 \nL 325.053035 519.741065 \nL 326.130701 522.072351 \nL 327.208367 516.742535 \nL 328.286033 520.779552 \nL 329.363699 521.533278 \nL 330.441365 521.034742 \nL 331.519031 523.277485 \nL 332.596697 520.86351 \nL 334.752028 522.237735 \nL 335.829694 519.289285 \nL 336.90736 522.123209 \nL 337.985026 521.467513 \nL 339.062692 521.950529 \nL 340.140358 522.202241 \nL 341.218024 518.829392 \nL 343.373355 522.56955 \nL 344.451021 521.321292 \nL 345.528687 520.295793 \nL 346.606353 520.258703 \nL 347.684019 521.202905 \nL 348.761685 521.562404 \nL 349.839351 521.540493 \nL 350.917017 522.717126 \nL 351.994682 522.45857 \nL 353.072348 522.4269 \nL 354.150014 520.845788 \nL 355.22768 521.867951 \nL 356.305346 524.34383 \nL 357.383012 520.942499 \nL 358.460678 522.965595 \nL 359.538344 521.440997 \nL 360.61601 519.368212 \nL 361.693675 522.186833 \nL 362.771341 520.962052 \nL 363.849007 521.739787 \nL 364.926673 519.423569 \nL 366.004339 520.599539 \nL 367.082005 520.786594 \nL 369.237337 522.429783 \nL 370.315003 520.261741 \nL 371.392668 519.626526 \nL 372.470334 521.618881 \nL 373.548 520.037639 \nL 374.625666 521.683223 \nL 375.703332 525.351446 \nL 376.780998 523.571931 \nL 377.858664 522.404005 \nL 378.93633 522.345485 \nL 380.013995 519.248401 \nL 381.091661 521.011729 \nL 382.169327 523.194152 \nL 383.246993 522.068502 \nL 384.324659 524.267973 \nL 385.402325 522.346457 \nL 386.479991 525.032657 \nL 387.557657 521.578678 \nL 388.635323 521.582769 \nL 389.712988 523.453785 \nL 390.790654 523.250419 \nL 392.945986 522.261336 \nL 394.023652 517.78554 \nL 395.101318 522.708234 \nL 396.178984 520.724801 \nL 397.25665 523.651662 \nL 398.334316 522.048113 \nL 399.411981 522.438601 \nL 400.489647 522.426925 \nL 401.567313 520.809211 \nL 402.644979 523.154723 \nL 403.722645 521.938698 \nL 404.800311 521.286801 \nL 405.877977 522.825099 \nL 406.955643 522.072153 \nL 408.033308 521.980689 \nL 409.110974 524.165662 \nL 410.18864 523.207221 \nL 411.266306 520.630528 \nL 412.343972 521.118495 \nL 413.421638 525.116912 \nL 414.499304 520.795307 \nL 417.732301 523.950582 \nL 418.809967 520.526138 \nL 419.887633 522.615786 \nL 420.965299 520.701813 \nL 422.042965 520.816048 \nL 423.120631 522.544644 \nL 424.198297 522.948449 \nL 425.275963 520.567201 \nL 426.353629 522.822172 \nL 427.431294 524.01316 \nL 429.586626 523.038415 \nL 430.664292 521.865451 \nL 431.741958 524.404206 \nL 432.819624 522.846571 \nL 433.89729 523.385285 \nL 434.974956 522.694224 \nL 436.052621 520.063208 \nL 437.130287 524.374448 \nL 438.207953 523.353831 \nL 439.285619 521.871676 \nL 440.363285 522.668278 \nL 441.440951 525.038443 \nL 442.518617 520.62069 \nL 443.596283 523.493914 \nL 444.673949 522.148654 \nL 445.751614 522.973126 \nL 446.82928 521.735363 \nL 447.906946 520.891714 \nL 448.984612 524.411446 \nL 450.062278 525.366687 \nL 451.139944 522.049418 \nL 452.21761 523.232134 \nL 453.295276 523.257436 \nL 454.372942 524.290286 \nL 455.450607 523.673165 \nL 456.528273 521.46961 \nL 457.605939 520.73943 \nL 458.683605 524.994886 \nL 459.761271 522.893605 \nL 460.838937 522.430049 \nL 461.916603 522.090122 \nL 462.994269 523.4168 \nL 464.071934 523.359308 \nL 465.1496 522.255488 \nL 466.227266 522.577359 \nL 467.304932 523.302237 \nL 468.382598 522.120981 \nL 469.460264 523.885986 \nL 470.53793 523.001819 \nL 471.615596 523.640066 \nL 472.693262 522.366054 \nL 473.770927 523.80792 \nL 474.848593 522.588466 \nL 475.926259 521.177695 \nL 478.081591 523.642566 \nL 479.159257 523.395872 \nL 480.236923 525.59496 \nL 481.314589 522.883698 \nL 482.392255 523.202648 \nL 483.46992 520.529975 \nL 484.547586 521.416462 \nL 485.625252 523.644911 \nL 486.702918 523.883913 \nL 487.780584 523.197122 \nL 488.85825 521.98671 \nL 489.935916 521.73613 \nL 491.013582 521.868075 \nL 492.091247 522.175181 \nL 493.168913 524.988265 \nL 494.246579 524.34956 \nL 495.324245 520.898843 \nL 496.401911 521.69813 \nL 497.479577 524.654643 \nL 498.557243 523.728584 \nL 499.634909 522.486192 \nL 500.712575 523.718832 \nL 503.945572 521.865284 \nL 505.023238 520.620801 \nL 506.100904 523.512725 \nL 507.17857 523.685949 \nL 508.256236 523.991175 \nL 509.333902 522.789153 \nL 510.411568 521.38642 \nL 511.489233 524.739065 \nL 512.566899 520.700594 \nL 513.644565 522.303606 \nL 514.722231 522.887448 \nL 515.799897 524.206904 \nL 516.877563 521.938586 \nL 517.955229 523.509253 \nL 519.032895 524.310044 \nL 520.110561 523.282237 \nL 521.188226 522.94572 \nL 522.265892 523.178707 \nL 523.343558 523.52692 \nL 524.421224 523.12103 \nL 525.49889 524.405474 \nL 526.576556 523.625376 \nL 527.654222 525.076164 \nL 528.731888 523.637919 \nL 529.809553 521.620991 \nL 530.887219 522.79247 \nL 531.964885 523.685349 \nL 533.042551 522.48011 \nL 534.120217 524.493003 \nL 535.197883 522.242982 \nL 536.275549 520.858355 \nL 537.353215 523.425048 \nL 538.430881 522.44641 \nL 539.508546 520.051636 \nL 540.586212 526.049741 \nL 541.663878 523.086272 \nL 542.741544 524.026205 \nL 543.81921 524.030388 \nL 544.896876 525.365629 \nL 545.974542 524.663127 \nL 547.052208 522.728499 \nL 548.129874 525.393295 \nL 549.207539 523.282268 \nL 550.285205 524.189467 \nL 551.362871 525.526639 \nL 552.440537 521.705122 \nL 553.518203 523.377525 \nL 554.595869 521.366235 \nL 555.673535 524.440678 \nL 557.828866 524.093511 \nL 558.906532 524.995988 \nL 559.984198 523.164896 \nL 561.061864 522.500784 \nL 562.13953 523.429405 \nL 563.217196 522.480939 \nL 564.294862 523.991998 \nL 565.372528 522.720145 \nL 566.450194 523.584288 \nL 567.527859 522.471385 \nL 568.605525 520.050089 \nL 569.683191 520.972423 \nL 570.760857 522.387452 \nL 571.838523 523.410872 \nL 572.916189 523.595464 \nL 573.993855 522.497696 \nL 575.071521 522.493723 \nL 576.149187 522.092529 \nL 577.226852 523.907106 \nL 578.304518 521.18655 \nL 579.382184 523.941832 \nL 580.45985 524.660392 \nL 581.537516 523.59378 \nL 582.615182 521.092122 \nL 583.692848 524.301889 \nL 584.770514 519.800549 \nL 585.848179 523.477008 \nL 586.925845 524.269761 \nL 588.003511 524.884568 \nL 589.081177 524.333391 \nL 590.158843 521.921539 \nL 591.236509 522.998113 \nL 592.314175 522.801857 \nL 593.391841 521.152015 \nL 594.469507 524.557425 \nL 595.547172 522.809889 \nL 596.624838 525.406804 \nL 597.702504 525.104926 \nL 598.78017 523.340577 \nL 599.857836 523.992975 \nL 600.935502 521.476231 \nL 602.013168 522.186586 \nL 603.090834 522.434103 \nL 604.1685 524.263047 \nL 605.246165 519.664792 \nL 606.323831 524.057918 \nL 607.401497 523.345447 \nL 608.479163 524.644297 \nL 609.556829 523.73351 \nL 610.634495 524.537846 \nL 611.712161 523.860585 \nL 612.789827 523.84251 \nL 613.867492 521.77879 \nL 614.945158 524.24548 \nL 616.022824 525.5498 \nL 617.10049 523.834515 \nL 618.178156 523.223588 \nL 619.255822 523.423105 \nL 620.333488 523.485677 \nL 621.411154 521.625428 \nL 622.48882 524.555624 \nL 623.566485 524.30023 \nL 624.644151 526.783696 \nL 625.721817 522.47701 \nL 626.799483 525.036197 \nL 627.877149 524.194838 \nL 628.954815 523.058111 \nL 630.032481 523.050896 \nL 631.110147 521.041976 \nL 632.187813 525.477562 \nL 633.265478 522.971115 \nL 634.343144 525.353581 \nL 636.498476 521.999284 \nL 637.576142 522.762434 \nL 638.653808 524.143237 \nL 639.731474 521.827971 \nL 640.80914 523.327391 \nL 641.886806 522.465197 \nL 642.964471 522.502095 \nL 644.042137 520.628647 \nL 645.119803 520.909845 \nL 646.197469 524.563254 \nL 647.275135 521.744744 \nL 648.352801 522.072901 \nL 649.430467 524.511177 \nL 650.508133 522.483853 \nL 651.585798 522.547292 \nL 652.663464 523.248346 \nL 653.74113 522.62482 \nL 654.818796 523.57125 \nL 655.896462 523.46764 \nL 656.974128 525.086993 \nL 658.051794 525.169231 \nL 659.12946 524.107291 \nL 660.207126 525.160295 \nL 661.284791 524.156114 \nL 662.362457 522.746722 \nL 663.440123 521.9709 \nL 664.517789 521.603572 \nL 665.595455 522.765416 \nL 666.673121 524.190822 \nL 667.750787 522.897776 \nL 668.828453 525.345685 \nL 669.906119 523.603267 \nL 670.983784 524.456494 \nL 672.06145 520.603085 \nL 673.139116 521.677462 \nL 674.216782 524.270739 \nL 675.294448 520.629377 \nL 676.372114 521.821857 \nL 677.44978 523.911184 \nL 678.527446 525.185146 \nL 679.605111 523.694142 \nL 681.760443 522.57593 \nL 682.838109 522.912819 \nL 683.915775 519.73617 \nL 684.993441 525.023326 \nL 686.071107 522.850017 \nL 687.148773 524.380791 \nL 688.226439 522.919774 \nL 689.304104 522.458631 \nL 690.38177 525.195325 \nL 691.459436 524.195952 \nL 692.537102 524.518812 \nL 693.614768 522.083118 \nL 694.692434 524.405085 \nL 695.7701 525.898557 \nL 696.847766 522.958739 \nL 697.925432 523.967426 \nL 699.003097 522.682999 \nL 700.080763 524.273653 \nL 701.158429 523.177135 \nL 702.236095 525.126082 \nL 703.313761 525.163915 \nL 704.391427 522.040638 \nL 705.469093 522.03612 \nL 706.546759 524.861499 \nL 707.624424 523.307094 \nL 708.70209 524.335545 \nL 709.779756 522.25758 \nL 710.857422 525.273732 \nL 711.935088 524.62983 \nL 713.012754 521.973393 \nL 714.09042 521.403338 \nL 715.168086 523.591522 \nL 716.245752 523.077887 \nL 717.323417 523.374827 \nL 718.401083 522.531544 \nL 719.478749 521.850427 \nL 720.556415 523.877441 \nL 721.634081 520.431624 \nL 722.711747 520.621748 \nL 723.789413 525.148532 \nL 724.867079 524.208816 \nL 727.02241 523.135274 \nL 728.100076 522.954717 \nL 729.177742 522.247085 \nL 730.255408 523.856829 \nL 731.333074 523.193849 \nL 732.41074 523.644231 \nL 733.488406 522.821955 \nL 734.566072 523.467813 \nL 735.643737 523.506333 \nL 736.721403 524.80712 \nL 737.799069 523.259107 \nL 738.876735 522.010174 \nL 739.954401 524.188736 \nL 741.032067 524.081506 \nL 742.109733 522.858371 \nL 743.187399 524.16133 \nL 745.34273 522.305852 \nL 746.420396 523.59685 \nL 747.498062 521.671194 \nL 748.575728 526.328636 \nL 749.653394 523.127849 \nL 750.73106 523.185594 \nL 751.808726 522.000193 \nL 752.886392 523.111296 \nL 753.964058 523.858333 \nL 756.119389 523.67332 \nL 757.197055 522.200255 \nL 758.274721 523.848221 \nL 759.352387 523.082819 \nL 760.430053 523.742773 \nL 761.507719 521.764762 \nL 762.585385 524.385624 \nL 763.663051 523.084471 \nL 764.740716 522.113711 \nL 765.818382 521.459116 \nL 766.896048 520.548836 \nL 767.973714 520.842143 \nL 769.05138 522.939816 \nL 770.129046 524.054131 \nL 771.206712 523.880745 \nL 772.284378 521.007125 \nL 773.362043 523.305819 \nL 775.517375 525.551248 \nL 776.595041 522.629498 \nL 777.672707 521.697511 \nL 778.750373 522.597761 \nL 779.828039 522.508061 \nL 780.905705 521.35014 \nL 781.983371 524.314023 \nL 783.061036 524.388786 \nL 784.138702 520.821593 \nL 785.216368 522.694775 \nL 786.294034 522.828452 \nL 786.294034 522.828452 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#pf52b4f76f4)\" d=\"M 76.112216 132.343518 \nL 78.267548 232.099452 \nL 80.422879 316.294948 \nL 82.578211 385.264056 \nL 83.655877 413.82494 \nL 84.733543 438.448599 \nL 85.811209 458.04976 \nL 86.888875 474.413353 \nL 87.966541 486.929879 \nL 89.044207 495.996702 \nL 90.121872 502.345965 \nL 91.199538 506.575481 \nL 92.277204 509.379951 \nL 93.35487 510.974844 \nL 94.432536 511.746564 \nL 95.510202 512.171959 \nL 96.587868 512.269549 \nL 98.743199 512.189588 \nL 99.820865 511.980202 \nL 107.364527 511.74102 \nL 108.442192 511.897667 \nL 109.519858 512.198883 \nL 112.752856 512.289975 \nL 115.985854 512.465501 \nL 117.06352 512.3915 \nL 119.218851 512.685581 \nL 120.296517 513.043546 \nL 122.451849 512.879263 \nL 134.306174 514.107033 \nL 135.38384 514.026014 \nL 137.539171 514.242641 \nL 142.927501 515.005772 \nL 144.005167 514.888189 \nL 145.082833 515.159938 \nL 146.160498 515.253419 \nL 147.238164 515.53518 \nL 148.31583 515.678832 \nL 149.393496 515.653975 \nL 150.471162 515.379095 \nL 151.548828 515.554845 \nL 153.70416 515.503033 \nL 154.781826 516.025999 \nL 155.859491 515.935921 \nL 156.937157 515.961156 \nL 158.014823 516.371471 \nL 159.092489 516.524077 \nL 160.170155 516.541149 \nL 161.247821 516.416816 \nL 163.403153 516.591111 \nL 164.480818 516.918996 \nL 166.63615 517.274071 \nL 167.713816 517.668161 \nL 168.791482 517.708556 \nL 169.869148 517.883055 \nL 170.946814 517.639146 \nL 172.02448 517.617816 \nL 174.179811 517.931748 \nL 175.257477 518.247784 \nL 176.335143 518.318951 \nL 177.412809 518.543671 \nL 178.490475 518.407147 \nL 180.645807 518.721308 \nL 182.801139 519.089217 \nL 183.878804 518.838637 \nL 184.95647 519.160069 \nL 186.034136 519.235289 \nL 187.111802 519.54544 \nL 189.267134 519.453221 \nL 191.422466 520.070441 \nL 192.500131 520.366966 \nL 193.577797 519.990407 \nL 194.655463 520.346819 \nL 195.733129 520.234984 \nL 196.810795 520.701782 \nL 197.888461 520.807899 \nL 198.966127 521.101912 \nL 200.043793 521.26221 \nL 201.121459 521.197961 \nL 203.27679 521.534979 \nL 205.432122 521.439067 \nL 207.587454 522.025972 \nL 209.742786 522.080983 \nL 210.820452 522.115307 \nL 211.898117 522.556716 \nL 214.053449 522.598447 \nL 215.131115 522.858946 \nL 216.208781 522.962829 \nL 217.286447 522.672727 \nL 218.364113 523.217307 \nL 219.441779 523.204047 \nL 220.519444 523.522087 \nL 221.59711 523.565167 \nL 222.674776 523.797338 \nL 223.752442 523.574567 \nL 224.830108 523.818062 \nL 225.907774 524.191199 \nL 226.98544 524.208915 \nL 228.063106 524.591582 \nL 229.140772 524.720322 \nL 230.218437 524.649563 \nL 231.296103 524.722543 \nL 233.451435 525.266455 \nL 237.762099 525.593202 \nL 238.839765 525.461115 \nL 239.91743 525.621091 \nL 240.995096 525.984922 \nL 242.072762 526.186939 \nL 244.228094 526.110939 \nL 251.771755 527.214208 \nL 252.849421 527.150305 \nL 253.927087 527.532224 \nL 258.23775 528.110782 \nL 259.315416 528.334005 \nL 260.393082 528.387202 \nL 261.470748 528.151876 \nL 262.548414 528.564276 \nL 263.62608 528.567196 \nL 264.703746 528.867502 \nL 267.936743 528.972258 \nL 270.092075 529.390617 \nL 271.169741 529.261196 \nL 275.480405 529.858374 \nL 276.558071 529.558278 \nL 277.635736 530.09219 \nL 281.9464 530.841486 \nL 285.179398 530.828509 \nL 286.257063 530.917461 \nL 287.334729 531.14965 \nL 288.412395 531.044889 \nL 289.490061 531.348505 \nL 290.567727 531.322281 \nL 291.645393 531.587749 \nL 295.956056 531.991752 \nL 298.111388 532.371566 \nL 301.344386 532.758398 \nL 303.499718 532.68499 \nL 305.655049 533.141683 \nL 307.810381 533.135947 \nL 308.888047 533.024348 \nL 309.965713 533.364449 \nL 313.198711 533.344759 \nL 316.431708 533.958705 \nL 317.509374 534.022756 \nL 319.664706 533.807466 \nL 320.742372 534.200566 \nL 322.897704 534.378531 \nL 323.975369 534.351174 \nL 327.208367 534.809823 \nL 328.286033 534.615745 \nL 329.363699 534.807502 \nL 330.441365 534.710383 \nL 331.519031 534.948568 \nL 334.752028 535.201493 \nL 336.90736 535.52415 \nL 337.985026 535.354904 \nL 339.062692 535.30691 \nL 341.218024 535.801925 \nL 343.373355 535.911315 \nL 344.451021 535.716489 \nL 346.606353 535.824883 \nL 347.684019 535.6462 \nL 348.761685 535.83982 \nL 349.839351 535.896078 \nL 350.917017 536.207952 \nL 353.072348 536.326166 \nL 354.150014 536.493874 \nL 355.22768 536.4187 \nL 358.460678 536.578225 \nL 359.538344 536.786089 \nL 360.61601 536.641004 \nL 361.693675 536.909591 \nL 363.849007 537.003978 \nL 370.315003 537.091902 \nL 371.392668 537.393208 \nL 372.470334 537.47474 \nL 373.548 537.382264 \nL 374.625666 537.518337 \nL 376.780998 537.42743 \nL 378.93633 537.681917 \nL 380.013995 537.543673 \nL 381.091661 537.593647 \nL 383.246993 537.929214 \nL 385.402325 537.947908 \nL 386.479991 537.636832 \nL 388.635323 538.150736 \nL 389.712988 538.135625 \nL 391.86832 538.317899 \nL 396.178984 538.173213 \nL 397.25665 538.023713 \nL 398.334316 538.075101 \nL 401.567313 538.658591 \nL 402.644979 538.494994 \nL 404.800311 538.696724 \nL 406.955643 538.708756 \nL 408.033308 538.817936 \nL 411.266306 538.824288 \nL 414.499304 538.938832 \nL 415.57697 538.512522 \nL 416.654636 538.943693 \nL 419.887633 538.979576 \nL 420.965299 539.125392 \nL 422.042965 539.058599 \nL 425.275963 539.146836 \nL 426.353629 539.053442 \nL 427.431294 539.314225 \nL 429.586626 539.170195 \nL 431.741958 539.409603 \nL 437.130287 539.297651 \nL 439.285619 539.393864 \nL 440.363285 539.367482 \nL 442.518617 539.618043 \nL 443.596283 539.449818 \nL 444.673949 539.588168 \nL 448.984612 539.6684 \nL 451.139944 539.743101 \nL 453.295276 539.659019 \nL 454.372942 539.806443 \nL 456.528273 539.613043 \nL 457.605939 539.904528 \nL 458.683605 539.681556 \nL 459.761271 539.703609 \nL 460.838937 539.926427 \nL 461.916603 539.730592 \nL 462.994269 539.912486 \nL 465.1496 539.913637 \nL 466.227266 540.029564 \nL 467.304932 540.023157 \nL 468.382598 539.763821 \nL 469.460264 540.005407 \nL 470.53793 539.898173 \nL 472.693262 540.118079 \nL 474.848593 539.965324 \nL 477.003925 540.09554 \nL 479.159257 540.062645 \nL 480.236923 539.941572 \nL 481.314589 540.005369 \nL 482.392255 539.9176 \nL 484.547586 540.343836 \nL 487.780584 540.092047 \nL 488.85825 540.22216 \nL 489.935916 540.158295 \nL 492.091247 540.32552 \nL 493.168913 540.005236 \nL 494.246579 540.279711 \nL 496.401911 540.437534 \nL 497.479577 540.193058 \nL 498.557243 540.283393 \nL 499.634909 540.236101 \nL 500.712575 540.326835 \nL 501.79024 540.290685 \nL 503.945572 540.491047 \nL 505.023238 540.345532 \nL 506.100904 540.468275 \nL 509.333902 540.371428 \nL 510.411568 540.568461 \nL 513.644565 540.561666 \nL 516.877563 540.401084 \nL 517.955229 540.281682 \nL 519.032895 540.555194 \nL 521.188226 540.382217 \nL 522.265892 540.53508 \nL 524.421224 540.301563 \nL 525.49889 540.531989 \nL 526.576556 540.445618 \nL 534.120217 540.606009 \nL 535.197883 540.470314 \nL 537.353215 540.592962 \nL 538.430881 540.374853 \nL 542.741544 540.636107 \nL 544.896876 540.597368 \nL 548.129874 540.620427 \nL 549.207539 540.439585 \nL 550.285205 540.566474 \nL 552.440537 540.640504 \nL 553.518203 540.653538 \nL 554.595869 540.849265 \nL 555.673535 540.75326 \nL 558.906532 540.77277 \nL 559.984198 540.579528 \nL 561.061864 540.775855 \nL 562.13953 540.707469 \nL 565.372528 540.824709 \nL 568.605525 540.685737 \nL 571.838523 540.773358 \nL 572.916189 540.609555 \nL 576.149187 540.813573 \nL 578.304518 540.905343 \nL 580.45985 540.884602 \nL 581.537516 540.720359 \nL 583.692848 540.842471 \nL 584.770514 540.750704 \nL 590.158843 540.89815 \nL 591.236509 540.766282 \nL 593.391841 540.894654 \nL 596.624838 540.729832 \nL 599.857836 540.941141 \nL 603.090834 540.791897 \nL 604.1685 540.948532 \nL 614.945158 540.830216 \nL 616.022824 540.70281 \nL 617.10049 540.865617 \nL 619.255822 540.742805 \nL 620.333488 540.916182 \nL 621.411154 540.86097 \nL 623.566485 540.932938 \nL 624.644151 540.756713 \nL 628.954815 541.039213 \nL 630.032481 540.807933 \nL 632.187813 541.016732 \nL 633.265478 540.777006 \nL 636.498476 541.03425 \nL 642.964471 540.969441 \nL 644.042137 541.047632 \nL 645.119803 540.927397 \nL 646.197469 541.025469 \nL 647.275135 540.888017 \nL 649.430467 540.869772 \nL 651.585798 541.074153 \nL 653.74113 541.120562 \nL 656.974128 540.974363 \nL 658.051794 541.00844 \nL 660.207126 540.778559 \nL 662.362457 541.113369 \nL 664.517789 541.048733 \nL 669.906119 540.997392 \nL 670.983784 540.808487 \nL 672.06145 541.093533 \nL 673.139116 541.080635 \nL 674.216782 540.943777 \nL 678.527446 541.208842 \nL 679.605111 541.035339 \nL 682.838109 540.974432 \nL 683.915775 541.151545 \nL 684.993441 541.153683 \nL 686.071107 540.955732 \nL 687.148773 541.12038 \nL 692.537102 540.753486 \nL 693.614768 541.086696 \nL 696.847766 540.983156 \nL 699.003097 541.02857 \nL 701.158429 540.95006 \nL 703.313761 541.086263 \nL 704.391427 541.151852 \nL 706.546759 540.890644 \nL 707.624424 541.063271 \nL 708.70209 540.827945 \nL 709.779756 541.007831 \nL 710.857422 540.867773 \nL 711.935088 541.107954 \nL 713.012754 541.147146 \nL 714.09042 541.045803 \nL 715.168086 541.146666 \nL 716.245752 541.017552 \nL 717.323417 541.123328 \nL 731.333074 540.984561 \nL 735.643737 541.064286 \nL 736.721403 540.8907 \nL 738.876735 541.067309 \nL 741.032067 540.868473 \nL 742.109733 541.104539 \nL 743.187399 540.968893 \nL 749.653394 541.12955 \nL 750.73106 540.866072 \nL 751.808726 541.083818 \nL 757.197055 541.021707 \nL 758.274721 540.916321 \nL 759.352387 541.075474 \nL 761.507719 541.054178 \nL 762.585385 540.911556 \nL 769.05138 541.102552 \nL 770.129046 540.979447 \nL 771.206712 541.021243 \nL 772.284378 540.892383 \nL 773.362043 541.105767 \nL 776.595041 541.209034 \nL 777.672707 541.108332 \nL 778.750373 541.160369 \nL 779.828039 540.875818 \nL 786.294034 541.019353 \nL 786.294034 541.019353 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 40.603125 565.918125 \nL 40.603125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 821.803125 565.918125 \nL 821.803125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 40.603125 565.918125 \nL 821.803125 565.918125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 40.603125 22.318125 \nL 821.803125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_18\">\n    <!-- Model Loss -->\n    <g transform=\"translate(398.119687 16.318125)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 9.8125 72.90625 \nL 24.515625 72.90625 \nL 43.109375 23.296875 \nL 61.8125 72.90625 \nL 76.515625 72.90625 \nL 76.515625 0 \nL 66.890625 0 \nL 66.890625 64.015625 \nL 48.09375 14.015625 \nL 38.1875 14.015625 \nL 19.390625 64.015625 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-77\"/>\n      <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n      <path id=\"DejaVuSans-32\"/>\n      <path d=\"M 9.8125 72.90625 \nL 19.671875 72.90625 \nL 19.671875 8.296875 \nL 55.171875 8.296875 \nL 55.171875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-76\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-77\"/>\n     <use x=\"86.279297\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"147.460938\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"210.9375\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"272.460938\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"300.244141\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"332.03125\" xlink:href=\"#DejaVuSans-76\"/>\n     <use x=\"385.994141\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"447.175781\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"499.275391\" xlink:href=\"#DejaVuSans-115\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 47.603125 59.674375 \nL 102.878125 59.674375 \nQ 104.878125 59.674375 104.878125 57.674375 \nL 104.878125 29.318125 \nQ 104.878125 27.318125 102.878125 27.318125 \nL 47.603125 27.318125 \nQ 45.603125 27.318125 45.603125 29.318125 \nL 45.603125 57.674375 \nQ 45.603125 59.674375 47.603125 59.674375 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_18\">\n     <path d=\"M 49.603125 35.416562 \nL 69.603125 35.416562 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_19\"/>\n    <g id=\"text_19\">\n     <!-- train -->\n     <g transform=\"translate(77.603125 38.916562)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n       <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n       <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n       <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_20\">\n     <path d=\"M 49.603125 50.094687 \nL 69.603125 50.094687 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_21\"/>\n    <g id=\"text_20\">\n     <!-- test -->\n     <g transform=\"translate(77.603125 53.594687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"100.732422\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"152.832031\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pf52b4f76f4\">\n   <rect height=\"543.6\" width=\"781.2\" x=\"40.603125\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"603.474375pt\" version=\"1.1\" viewBox=\"0 0 822.640625 603.474375\" width=\"822.640625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-08-13T20:23:45.846864</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 603.474375 \nL 822.640625 603.474375 \nL 822.640625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 34.240625 565.918125 \nL 815.440625 565.918125 \nL 815.440625 22.318125 \nL 34.240625 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mad3516a54c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.749716\" xlink:href=\"#mad3516a54c\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(66.568466 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"177.516304\" xlink:href=\"#mad3516a54c\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 100 -->\n      <g transform=\"translate(167.972554 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"285.282893\" xlink:href=\"#mad3516a54c\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 200 -->\n      <g transform=\"translate(275.739143 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"393.049481\" xlink:href=\"#mad3516a54c\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 300 -->\n      <g transform=\"translate(383.505731 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"500.81607\" xlink:href=\"#mad3516a54c\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 400 -->\n      <g transform=\"translate(491.27232 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"608.582658\" xlink:href=\"#mad3516a54c\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 500 -->\n      <g transform=\"translate(599.038908 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"716.349247\" xlink:href=\"#mad3516a54c\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 600 -->\n      <g transform=\"translate(706.805497 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- epoch -->\n     <g transform=\"translate(409.6125 594.194687)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n       <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n       <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m4b2fc01da2\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#m4b2fc01da2\" y=\"485.299906\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 2 -->\n      <g transform=\"translate(20.878125 489.099125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#m4b2fc01da2\" y=\"374.153067\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 3 -->\n      <g transform=\"translate(20.878125 377.952286)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#m4b2fc01da2\" y=\"263.006229\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 4 -->\n      <g transform=\"translate(20.878125 266.805447)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#m4b2fc01da2\" y=\"151.85939\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 5 -->\n      <g transform=\"translate(20.878125 155.658608)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.240625\" xlink:href=\"#m4b2fc01da2\" y=\"40.712551\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 6 -->\n      <g transform=\"translate(20.878125 44.51177)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_14\">\n     <!-- MAE -->\n     <g transform=\"translate(14.798438 305.011875)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 24.515625 72.90625 \nL 43.109375 23.296875 \nL 61.8125 72.90625 \nL 76.515625 72.90625 \nL 76.515625 0 \nL 66.890625 0 \nL 66.890625 64.015625 \nL 48.09375 14.015625 \nL 38.1875 14.015625 \nL 19.390625 64.015625 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-77\"/>\n       <path d=\"M 34.1875 63.1875 \nL 20.796875 26.90625 \nL 47.609375 26.90625 \nz\nM 28.609375 72.90625 \nL 39.796875 72.90625 \nL 67.578125 0 \nL 57.328125 0 \nL 50.6875 18.703125 \nL 17.828125 18.703125 \nL 11.1875 0 \nL 0.78125 0 \nz\n\" id=\"DejaVuSans-65\"/>\n       <path d=\"M 9.8125 72.90625 \nL 55.90625 72.90625 \nL 55.90625 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.015625 \nL 54.390625 43.015625 \nL 54.390625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 8.296875 \nL 56.78125 8.296875 \nL 56.78125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-69\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-77\"/>\n      <use x=\"86.279297\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"154.6875\" xlink:href=\"#DejaVuSans-69\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_13\">\n    <path clip-path=\"url(#p9437348bb8)\" d=\"M 69.749716 47.027216 \nL 75.138045 259.023729 \nL 78.371043 374.134332 \nL 80.526375 431.445163 \nL 81.604041 453.126288 \nL 82.681707 461.252484 \nL 83.759372 475.236944 \nL 84.837038 480.664725 \nL 85.914704 481.311179 \nL 86.99237 486.02566 \nL 88.070036 488.186904 \nL 89.147702 485.50647 \nL 90.225368 485.914151 \nL 91.303034 485.952535 \nL 92.380699 488.02384 \nL 93.458365 486.077984 \nL 94.536031 486.460093 \nL 95.613697 486.224711 \nL 96.691363 484.630052 \nL 97.769029 485.543304 \nL 98.846695 485.879688 \nL 99.924361 487.985349 \nL 101.002027 486.755164 \nL 102.079692 482.5146 \nL 103.157358 484.06996 \nL 104.235024 485.162374 \nL 105.31269 485.644068 \nL 106.390356 487.422593 \nL 107.468022 487.515752 \nL 108.545688 481.818565 \nL 109.623354 486.045257 \nL 110.70102 483.338654 \nL 111.778685 486.044356 \nL 112.856351 487.749014 \nL 113.934017 486.538372 \nL 115.011683 486.635095 \nL 116.089349 488.04447 \nL 117.167015 483.22097 \nL 118.244681 488.29697 \nL 119.322347 484.445192 \nL 120.400013 489.945528 \nL 121.477678 484.762523 \nL 122.555344 489.107973 \nL 123.63301 484.777363 \nL 124.710676 485.502786 \nL 125.788342 487.194433 \nL 126.866008 490.53375 \nL 127.943674 487.254401 \nL 129.02134 489.586023 \nL 130.099005 486.924774 \nL 131.176671 490.006067 \nL 132.254337 487.503019 \nL 133.332003 489.368542 \nL 134.409669 489.41754 \nL 135.487335 492.448934 \nL 136.565001 489.921334 \nL 137.642667 483.58592 \nL 138.720333 485.593057 \nL 139.797998 491.753839 \nL 140.875664 490.657874 \nL 141.95333 485.175756 \nL 143.030996 489.613901 \nL 144.108662 489.768923 \nL 145.186328 488.447712 \nL 146.263994 489.617558 \nL 147.34166 488.585284 \nL 148.419326 488.604907 \nL 149.496991 492.637411 \nL 150.574657 486.790568 \nL 151.652323 494.08036 \nL 152.729989 488.901714 \nL 153.807655 486.511634 \nL 154.885321 488.003634 \nL 155.962987 492.270049 \nL 157.040653 490.44242 \nL 158.118318 493.250887 \nL 159.195984 490.741387 \nL 160.27365 491.460318 \nL 161.351316 490.960299 \nL 162.428982 496.012675 \nL 163.506648 491.623422 \nL 164.584314 489.185139 \nL 165.66198 493.649585 \nL 166.739646 488.264508 \nL 167.817311 489.679381 \nL 168.894977 489.643169 \nL 169.972643 493.692978 \nL 171.050309 495.003907 \nL 172.127975 493.552901 \nL 173.205641 494.693505 \nL 174.283307 493.70212 \nL 175.360973 494.406595 \nL 176.438639 495.837381 \nL 177.516304 490.536877 \nL 178.59397 491.956176 \nL 179.671636 490.552486 \nL 180.749302 491.754833 \nL 181.826968 492.24498 \nL 182.904634 493.273173 \nL 183.9823 488.748587 \nL 185.059966 493.456112 \nL 186.137631 495.751722 \nL 188.292963 493.860322 \nL 189.370629 489.003856 \nL 190.448295 493.216133 \nL 191.525961 496.878188 \nL 192.603627 498.118906 \nL 193.681293 489.507452 \nL 194.758959 491.657341 \nL 195.836624 496.832516 \nL 196.91429 494.032741 \nL 197.991956 497.208967 \nL 199.069622 495.563297 \nL 200.147288 493.536724 \nL 201.224954 494.346229 \nL 202.30262 498.712932 \nL 203.380286 491.222313 \nL 204.457952 495.013274 \nL 205.535617 492.170371 \nL 206.613283 498.611969 \nL 207.690949 495.468151 \nL 208.768615 495.380822 \nL 209.846281 496.74369 \nL 210.923947 497.794301 \nL 212.001613 496.825387 \nL 213.079279 494.409629 \nL 214.156944 495.384068 \nL 215.23461 500.36153 \nL 216.312276 497.346579 \nL 217.389942 499.297907 \nL 218.467608 492.946832 \nL 219.545274 501.863096 \nL 220.62294 498.757649 \nL 221.700606 499.832826 \nL 222.778272 498.012723 \nL 223.855937 501.131008 \nL 224.933603 501.55068 \nL 226.011269 496.711837 \nL 227.088935 498.700729 \nL 228.166601 499.092099 \nL 229.244267 497.306711 \nL 230.321933 501.587183 \nL 231.399599 503.753926 \nL 232.477265 497.926904 \nL 233.55493 501.371902 \nL 234.632596 498.619852 \nL 235.710262 499.32813 \nL 236.787928 505.29862 \nL 237.865594 496.532012 \nL 238.94326 497.041159 \nL 240.020926 500.785031 \nL 241.098592 499.429769 \nL 242.176258 500.839885 \nL 243.253923 498.291563 \nL 244.331589 505.390891 \nL 245.409255 504.608825 \nL 246.486921 501.628708 \nL 247.564587 500.990389 \nL 248.642253 499.218237 \nL 249.719919 504.501622 \nL 250.797585 498.896467 \nL 251.87525 505.170336 \nL 252.952916 504.159832 \nL 254.030582 499.501172 \nL 255.108248 500.16978 \nL 256.185914 497.795891 \nL 257.26358 506.352371 \nL 258.341246 505.337905 \nL 259.418912 500.168998 \nL 260.496578 498.415157 \nL 261.574243 507.834672 \nL 262.651909 503.425598 \nL 263.729575 505.783653 \nL 264.807241 503.019069 \nL 265.884907 506.831747 \nL 266.962573 504.748809 \nL 268.040239 501.792886 \nL 269.117905 505.297679 \nL 270.195571 507.830393 \nL 271.273236 504.523378 \nL 272.350902 507.123546 \nL 273.428568 502.516825 \nL 274.506234 503.663536 \nL 275.5839 507.423811 \nL 276.661566 509.052668 \nL 277.739232 506.584984 \nL 278.816898 505.800785 \nL 279.894563 506.861638 \nL 280.972229 504.481323 \nL 282.049895 503.000864 \nL 283.127561 505.34514 \nL 284.205227 508.016644 \nL 286.360559 502.243774 \nL 287.438225 507.813711 \nL 288.515891 506.173089 \nL 290.671222 508.235291 \nL 291.748888 507.190258 \nL 292.826554 507.816043 \nL 293.90422 511.771341 \nL 294.981886 509.525604 \nL 296.059552 510.444062 \nL 297.137218 511.09746 \nL 298.214884 510.647591 \nL 299.292549 507.5736 \nL 300.370215 509.262504 \nL 301.447881 507.09221 \nL 302.525547 512.627883 \nL 303.603213 506.326614 \nL 304.680879 510.866238 \nL 305.758545 511.506015 \nL 306.836211 506.315352 \nL 307.913876 508.027628 \nL 308.991542 511.25268 \nL 310.069208 508.62017 \nL 311.146874 507.621524 \nL 312.22454 510.421604 \nL 313.302206 503.502791 \nL 314.379872 510.151296 \nL 315.457538 507.553712 \nL 316.535204 509.822146 \nL 317.612869 512.494936 \nL 318.690535 510.448063 \nL 319.768201 512.504489 \nL 320.845867 503.836445 \nL 321.923533 511.602791 \nL 323.001199 510.492304 \nL 324.078865 510.220486 \nL 325.156531 514.737798 \nL 326.234197 511.683283 \nL 327.311862 511.250481 \nL 328.389528 514.574866 \nL 329.467194 509.041988 \nL 330.54486 514.927759 \nL 331.622526 514.34599 \nL 332.700192 511.233919 \nL 333.777858 510.962908 \nL 334.855524 507.295991 \nL 335.933189 512.054051 \nL 337.010855 514.09088 \nL 338.088521 511.802213 \nL 339.166187 510.020918 \nL 340.243853 510.530437 \nL 341.321519 511.895425 \nL 342.399185 511.873974 \nL 343.476851 513.778689 \nL 344.554517 514.693862 \nL 345.632182 512.374191 \nL 346.709848 514.104673 \nL 347.787514 514.065056 \nL 348.86518 514.334688 \nL 349.942846 515.244839 \nL 351.020512 510.778393 \nL 352.098178 515.435065 \nL 353.175844 513.138767 \nL 354.25351 510.080065 \nL 355.331175 517.802687 \nL 356.408841 515.841951 \nL 357.486507 515.883383 \nL 358.564173 508.647067 \nL 361.797171 515.133832 \nL 362.874837 514.11775 \nL 363.952503 511.808414 \nL 365.030168 511.453745 \nL 366.107834 515.338051 \nL 367.1855 511.232249 \nL 368.263166 515.195921 \nL 369.340832 517.836394 \nL 370.418498 515.67099 \nL 371.496164 513.896493 \nL 372.57383 514.694074 \nL 373.651495 508.898494 \nL 374.729161 514.489167 \nL 375.806827 514.141825 \nL 376.884493 513.625536 \nL 377.962159 517.451238 \nL 379.039825 515.053473 \nL 380.117491 519.259429 \nL 381.195157 512.858151 \nL 382.272823 514.364275 \nL 383.350488 516.262935 \nL 384.428154 514.915305 \nL 385.50582 516.213037 \nL 386.583486 516.038803 \nL 387.661152 508.945384 \nL 388.738818 516.888058 \nL 389.816484 514.153471 \nL 390.89415 516.950318 \nL 391.971816 515.233351 \nL 393.049481 516.568699 \nL 394.127147 516.543618 \nL 395.204813 512.807338 \nL 396.282479 517.164884 \nL 397.360145 514.136419 \nL 398.437811 515.960762 \nL 399.515477 516.639267 \nL 400.593143 515.412355 \nL 401.670808 516.006897 \nL 402.748474 518.723371 \nL 403.82614 515.810867 \nL 404.903806 513.64015 \nL 405.981472 514.66715 \nL 407.059138 518.705696 \nL 408.136804 516.891688 \nL 409.21447 515.426744 \nL 410.292136 516.070735 \nL 411.369801 518.772197 \nL 412.447467 512.264059 \nL 413.525133 516.454553 \nL 414.602799 513.730818 \nL 415.680465 514.68729 \nL 416.758131 517.010538 \nL 417.835797 516.171896 \nL 418.913463 515.003972 \nL 419.991129 518.384496 \nL 421.068794 520.376554 \nL 422.14646 515.957277 \nL 423.224126 518.521671 \nL 424.301792 516.644607 \nL 425.379458 521.873417 \nL 426.457124 516.191175 \nL 427.53479 516.280438 \nL 428.612456 516.880916 \nL 429.690121 511.814363 \nL 430.767787 518.927563 \nL 431.845453 517.447475 \nL 432.923119 514.376955 \nL 434.000785 516.613576 \nL 435.078451 519.595747 \nL 436.156117 512.749463 \nL 437.233783 517.879376 \nL 438.311449 515.574863 \nL 439.389114 516.186193 \nL 440.46678 519.0104 \nL 441.544446 512.588386 \nL 442.622112 519.293534 \nL 443.699778 521.014237 \nL 444.777444 517.296759 \nL 445.85511 517.919854 \nL 446.932776 518.97513 \nL 448.010442 519.638557 \nL 449.088107 519.591945 \nL 450.165773 517.611507 \nL 451.243439 516.052768 \nL 452.321105 520.339627 \nL 453.398771 517.910765 \nL 454.476437 515.110738 \nL 455.554103 516.908303 \nL 456.631769 516.837974 \nL 457.709434 517.562827 \nL 458.7871 516.714526 \nL 459.864766 517.308419 \nL 460.942432 518.218994 \nL 462.020098 517.071434 \nL 463.097764 518.260465 \nL 464.17543 515.937442 \nL 465.253096 521.230659 \nL 466.330762 520.102788 \nL 467.408427 519.632211 \nL 468.486093 518.235105 \nL 469.563759 514.88593 \nL 470.641425 517.822747 \nL 471.719091 517.510226 \nL 472.796757 518.275597 \nL 473.874423 523.346323 \nL 474.952089 519.354801 \nL 476.029755 520.044158 \nL 477.10742 512.937795 \nL 478.185086 517.362557 \nL 479.262752 520.308795 \nL 480.340418 517.463679 \nL 481.418084 517.882159 \nL 482.49575 515.828225 \nL 483.573416 515.369598 \nL 484.651082 516.19927 \nL 485.728747 516.795257 \nL 486.806413 521.228896 \nL 487.884079 521.140627 \nL 488.961745 515.126956 \nL 490.039411 517.445938 \nL 491.117077 520.79881 \nL 493.272409 517.708866 \nL 494.350075 520.168136 \nL 496.505406 518.021188 \nL 497.583072 516.249765 \nL 498.660738 515.483453 \nL 499.738404 520.26421 \nL 500.81607 519.321372 \nL 501.893736 519.726376 \nL 502.971402 518.384218 \nL 504.049068 516.835046 \nL 505.126733 519.3296 \nL 506.204399 514.912999 \nL 507.282065 516.576517 \nL 508.359731 517.886319 \nL 509.437397 521.707636 \nL 510.515063 516.451519 \nL 511.592729 520.863177 \nL 513.748061 520.048981 \nL 514.825726 517.038575 \nL 515.903392 518.928756 \nL 516.981058 518.757794 \nL 518.058724 518.892014 \nL 519.13639 520.352705 \nL 520.214056 519.341366 \nL 521.291722 521.783053 \nL 522.369388 519.690894 \nL 523.447053 518.147935 \nL 524.524719 518.034385 \nL 525.602385 518.971261 \nL 526.680051 516.686847 \nL 527.757717 521.539974 \nL 528.835383 518.782028 \nL 529.913049 515.032658 \nL 530.990715 519.156479 \nL 532.068381 515.648267 \nL 533.146046 514.726668 \nL 534.223712 522.70819 \nL 535.301378 518.823367 \nL 536.379044 521.078247 \nL 537.45671 520.056878 \nL 538.534376 521.322917 \nL 539.612042 520.442339 \nL 540.689708 518.356168 \nL 541.767374 521.678062 \nL 542.845039 518.79382 \nL 543.922705 520.722001 \nL 545.000371 523.528189 \nL 546.078037 516.105303 \nL 547.155703 518.185512 \nL 548.233369 518.945119 \nL 549.311035 521.868541 \nL 550.388701 523.84454 \nL 551.466366 523.152175 \nL 552.544032 520.0924 \nL 553.621698 519.217441 \nL 554.699364 519.402169 \nL 555.77703 518.22913 \nL 556.854696 519.517879 \nL 557.932362 522.904339 \nL 559.010028 519.245398 \nL 560.087694 518.009489 \nL 561.165359 516.506783 \nL 562.243025 513.618076 \nL 563.320691 516.066773 \nL 564.398357 517.285179 \nL 565.476023 521.045083 \nL 566.553689 519.786 \nL 567.631355 519.872388 \nL 568.709021 519.341286 \nL 569.786687 516.117824 \nL 570.864352 520.701676 \nL 571.942018 517.14028 \nL 573.019684 521.964853 \nL 574.09735 519.579039 \nL 575.175016 522.201679 \nL 576.252682 516.707901 \nL 577.330348 522.570697 \nL 578.408014 517.173934 \nL 579.485679 520.453138 \nL 580.563345 520.076845 \nL 581.641011 521.473049 \nL 582.718677 522.599158 \nL 583.796343 515.460558 \nL 584.874009 518.06062 \nL 585.951675 520.2711 \nL 587.029341 518.028913 \nL 588.107007 520.653116 \nL 589.184672 520.905788 \nL 591.340004 523.253416 \nL 592.41767 520.275896 \nL 593.495336 520.316665 \nL 594.573002 516.330363 \nL 595.650668 519.595827 \nL 596.728334 518.091783 \nL 597.806 520.814749 \nL 598.883665 515.47084 \nL 599.961331 522.004443 \nL 601.038997 520.421537 \nL 602.116663 521.416367 \nL 603.194329 521.48398 \nL 604.271995 523.352736 \nL 605.349661 521.067581 \nL 606.427327 520.004316 \nL 607.504992 518.369736 \nL 608.582658 519.502204 \nL 609.660324 524.247173 \nL 610.73799 521.588812 \nL 611.815656 521.499536 \nL 612.893322 519.205026 \nL 613.970988 521.25423 \nL 615.048654 516.282903 \nL 616.12632 522.76833 \nL 617.203985 519.970039 \nL 618.281651 524.140486 \nL 619.359317 519.713537 \nL 620.436983 520.946531 \nL 621.514649 523.944761 \nL 622.592315 521.367224 \nL 623.669981 520.086478 \nL 624.747647 515.536055 \nL 625.825313 523.248501 \nL 626.902978 518.835146 \nL 627.980644 523.123834 \nL 629.05831 519.232651 \nL 630.135976 518.96135 \nL 631.213642 520.380304 \nL 632.291308 522.471205 \nL 633.368974 517.918344 \nL 634.44664 520.896553 \nL 635.524306 519.57582 \nL 636.601971 519.354761 \nL 637.679637 516.433314 \nL 638.757303 519.199832 \nL 639.834969 521.419123 \nL 640.912635 518.21792 \nL 641.990301 517.054938 \nL 643.067967 520.692812 \nL 644.145633 518.716945 \nL 645.223298 518.431095 \nL 646.300964 519.944997 \nL 647.37863 520.884138 \nL 648.456296 520.141451 \nL 649.533962 520.318772 \nL 650.611628 521.895968 \nL 651.689294 522.020714 \nL 652.76696 521.541431 \nL 653.844626 522.352103 \nL 654.922291 523.600069 \nL 655.999957 519.209027 \nL 657.077623 515.752648 \nL 659.232955 519.655583 \nL 660.310621 521.075875 \nL 661.388287 519.21336 \nL 662.465953 522.693429 \nL 663.543619 520.38249 \nL 664.621284 520.146565 \nL 665.69895 516.398586 \nL 666.776616 519.152292 \nL 667.854282 521.026162 \nL 668.931948 515.770827 \nL 670.009614 516.601188 \nL 671.08728 522.517764 \nL 672.164946 521.888654 \nL 673.242611 519.936067 \nL 674.320277 519.708569 \nL 675.397943 518.9556 \nL 676.475609 520.277698 \nL 677.553275 515.401716 \nL 678.630941 522.894309 \nL 679.708607 519.307844 \nL 680.786273 521.31229 \nL 681.863939 519.113126 \nL 682.941604 519.516262 \nL 684.01927 525.294856 \nL 685.096936 522.014089 \nL 686.174602 523.923601 \nL 687.252268 516.753758 \nL 688.329934 523.162603 \nL 689.4076 524.628567 \nL 690.485266 518.532496 \nL 691.562932 518.892849 \nL 692.640597 518.128763 \nL 693.718263 522.511378 \nL 694.795929 518.444915 \nL 695.873595 523.99197 \nL 696.951261 523.07583 \nL 698.028927 517.957735 \nL 699.106593 518.202962 \nL 700.184259 520.927385 \nL 701.261924 519.662526 \nL 702.33959 521.290415 \nL 703.417256 519.571619 \nL 704.494922 525.105358 \nL 705.572588 522.240368 \nL 706.650254 518.646642 \nL 707.72792 518.34317 \nL 708.805586 521.077955 \nL 709.883252 518.900441 \nL 710.960917 520.594062 \nL 712.038583 519.497209 \nL 713.116249 517.561303 \nL 714.193915 521.22039 \nL 715.271581 515.474139 \nL 716.349247 516.055458 \nL 717.426913 522.350752 \nL 718.504579 522.037925 \nL 719.582245 521.053576 \nL 720.65991 519.357358 \nL 721.737576 520.378502 \nL 722.815242 518.89522 \nL 723.892908 521.847818 \nL 724.970574 521.50934 \nL 726.04824 521.29696 \nL 727.125906 520.655077 \nL 728.203572 521.151796 \nL 729.281237 519.626897 \nL 730.358903 519.923917 \nL 731.436569 521.290892 \nL 732.514235 518.830813 \nL 733.591901 523.304693 \nL 734.669567 521.717745 \nL 735.747233 518.484863 \nL 736.824899 522.687984 \nL 737.902565 519.887334 \nL 738.98023 520.345258 \nL 741.135562 518.738953 \nL 742.213228 527.426235 \nL 743.290894 520.949353 \nL 744.36856 520.116859 \nL 745.446226 519.975591 \nL 746.523892 520.434668 \nL 747.601558 520.68999 \nL 748.679223 519.004186 \nL 749.756889 519.917464 \nL 750.834555 520.159523 \nL 751.912221 521.490565 \nL 752.989887 520.174244 \nL 754.067553 519.386348 \nL 755.145219 517.786695 \nL 756.222885 522.838421 \nL 757.300551 519.870255 \nL 758.378216 519.349872 \nL 759.455882 517.67329 \nL 760.533548 513.269383 \nL 761.611214 517.981002 \nL 762.68888 520.144684 \nL 763.766546 519.75481 \nL 764.844212 521.491784 \nL 765.921878 516.03443 \nL 766.999543 518.965365 \nL 768.077209 522.98283 \nL 769.154875 523.771521 \nL 770.232541 520.844045 \nL 771.310207 518.629537 \nL 772.387873 519.446847 \nL 773.465539 518.808143 \nL 774.543205 517.279879 \nL 775.620871 521.812269 \nL 776.698536 520.490475 \nL 777.776202 516.776985 \nL 778.853868 520.981431 \nL 779.931534 518.145497 \nL 779.931534 518.145497 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#p9437348bb8)\" d=\"M 69.749716 106.890423 \nL 75.138045 317.186332 \nL 76.215711 357.176048 \nL 77.293377 392.911831 \nL 78.371043 422.586151 \nL 79.448709 445.130311 \nL 80.526375 462.195918 \nL 81.604041 474.316352 \nL 82.681707 482.55994 \nL 83.759372 487.914715 \nL 84.837038 490.86502 \nL 85.914704 491.334273 \nL 86.99237 491.363926 \nL 88.070036 490.938384 \nL 89.147702 490.090004 \nL 90.225368 489.448822 \nL 91.303034 488.631274 \nL 92.380699 488.233278 \nL 93.458365 487.326864 \nL 94.536031 487.067447 \nL 96.691363 486.886138 \nL 97.769029 486.467884 \nL 98.846695 486.19951 \nL 101.002027 485.90844 \nL 102.079692 486.235775 \nL 103.157358 486.950479 \nL 105.31269 486.723762 \nL 107.468022 486.978899 \nL 108.545688 486.914294 \nL 109.623354 487.037569 \nL 110.70102 486.70671 \nL 112.856351 487.286876 \nL 113.934017 488.163717 \nL 116.089349 487.473353 \nL 118.244681 487.763376 \nL 119.322347 488.246727 \nL 121.477678 488.494404 \nL 122.555344 488.494219 \nL 123.63301 488.909956 \nL 125.788342 489.277212 \nL 126.866008 489.13544 \nL 127.943674 489.488426 \nL 129.02134 489.14331 \nL 130.099005 489.219257 \nL 133.332003 490.094681 \nL 134.409669 490.060019 \nL 135.487335 490.724441 \nL 136.565001 490.953913 \nL 137.642667 490.482606 \nL 138.720333 491.088464 \nL 139.797998 491.213939 \nL 140.875664 491.906489 \nL 141.95333 492.172889 \nL 143.030996 491.935149 \nL 144.108662 491.054372 \nL 145.186328 491.394069 \nL 146.263994 491.330497 \nL 147.34166 491.04266 \nL 148.419326 492.288771 \nL 149.496991 491.920958 \nL 150.574657 491.87212 \nL 151.652323 492.827876 \nL 152.729989 493.123001 \nL 153.807655 493.030769 \nL 154.885321 492.577933 \nL 155.962987 492.779104 \nL 157.040653 492.78867 \nL 158.118318 493.511496 \nL 159.195984 493.727851 \nL 160.27365 494.200708 \nL 161.351316 495.213809 \nL 162.428982 495.15074 \nL 163.506648 495.51479 \nL 164.584314 494.625176 \nL 165.66198 494.445881 \nL 167.817311 495.013513 \nL 168.894977 495.751748 \nL 169.972643 495.808444 \nL 171.050309 496.307734 \nL 172.127975 495.771676 \nL 173.205641 496.182378 \nL 175.360973 496.607708 \nL 176.438639 497.098703 \nL 177.516304 496.294139 \nL 178.59397 496.995527 \nL 179.671636 497.067222 \nL 180.749302 497.773181 \nL 182.904634 497.266683 \nL 183.9823 497.791651 \nL 185.059966 498.629233 \nL 186.137631 499.320167 \nL 187.215297 498.167612 \nL 188.292963 498.973766 \nL 189.370629 498.55889 \nL 190.448295 499.651543 \nL 191.525961 499.812408 \nL 192.603627 500.50305 \nL 193.681293 500.814737 \nL 194.758959 500.470747 \nL 196.91429 501.126556 \nL 199.069622 500.590737 \nL 200.147288 501.393353 \nL 201.224954 501.930113 \nL 202.30262 501.986027 \nL 203.380286 501.790951 \nL 204.457952 501.729274 \nL 205.535617 502.838608 \nL 207.690949 502.629898 \nL 208.768615 503.226706 \nL 209.846281 503.356593 \nL 210.923947 502.373065 \nL 212.001613 503.764897 \nL 213.079279 503.566376 \nL 214.156944 504.334264 \nL 215.23461 504.297934 \nL 216.312276 504.843134 \nL 217.389942 504.014707 \nL 218.467608 504.556158 \nL 219.545274 505.516114 \nL 220.62294 505.382703 \nL 221.700606 506.419137 \nL 222.778272 506.634008 \nL 223.855937 506.205034 \nL 224.933603 506.250163 \nL 226.011269 507.027697 \nL 227.088935 507.617403 \nL 228.166601 507.69669 \nL 229.244267 507.455438 \nL 230.321933 507.870182 \nL 231.399599 507.935834 \nL 232.477265 507.351507 \nL 233.55493 507.668587 \nL 234.632596 508.625576 \nL 235.710262 509.076027 \nL 236.787928 508.857327 \nL 237.865594 508.490442 \nL 240.020926 509.240006 \nL 241.098592 509.843041 \nL 242.176258 509.981262 \nL 243.253923 510.675071 \nL 244.331589 510.814021 \nL 245.409255 510.768654 \nL 246.486921 510.406526 \nL 247.564587 511.409107 \nL 248.642253 511.654717 \nL 249.719919 512.148415 \nL 250.797585 512.064505 \nL 252.952916 513.104741 \nL 254.030582 513.102436 \nL 255.108248 512.255937 \nL 256.185914 513.327894 \nL 257.26358 513.179072 \nL 258.341246 513.94708 \nL 259.418912 513.866297 \nL 260.496578 513.953692 \nL 261.574243 513.841652 \nL 262.651909 514.449338 \nL 263.729575 514.834998 \nL 264.807241 514.324393 \nL 266.962573 514.948336 \nL 268.040239 515.678423 \nL 269.117905 515.530702 \nL 270.195571 514.595946 \nL 271.273236 515.955859 \nL 272.350902 516.39632 \nL 273.428568 517.014208 \nL 275.5839 517.757187 \nL 276.661566 517.428687 \nL 278.816898 517.249564 \nL 279.894563 517.387083 \nL 280.972229 517.960995 \nL 282.049895 517.507218 \nL 283.127561 518.28715 \nL 284.205227 518.07848 \nL 285.282893 518.752759 \nL 286.360559 518.863819 \nL 288.515891 518.826786 \nL 290.671222 520.079588 \nL 292.826554 520.832902 \nL 293.90422 520.89124 \nL 294.981886 521.353404 \nL 296.059552 520.897163 \nL 297.137218 520.760253 \nL 298.214884 521.303771 \nL 299.292549 522.092713 \nL 301.447881 521.735884 \nL 302.525547 521.233004 \nL 303.603213 522.274778 \nL 304.680879 522.156471 \nL 305.758545 522.346445 \nL 306.836211 521.77138 \nL 307.913876 522.344312 \nL 308.991542 522.63892 \nL 310.069208 523.54079 \nL 311.146874 523.648007 \nL 313.302206 522.592241 \nL 314.379872 523.866124 \nL 316.535204 524.218633 \nL 317.612869 523.962383 \nL 318.690535 524.494638 \nL 319.768201 524.749258 \nL 320.845867 525.345271 \nL 321.923533 524.427012 \nL 323.001199 525.013856 \nL 324.078865 524.527948 \nL 325.156531 525.270198 \nL 326.234197 525.400509 \nL 327.311862 525.282295 \nL 328.389528 525.821215 \nL 329.467194 526.51619 \nL 330.54486 526.89402 \nL 331.622526 526.047176 \nL 332.700192 525.782738 \nL 333.777858 526.558417 \nL 334.855524 527.545178 \nL 335.933189 527.583205 \nL 337.010855 527.763441 \nL 338.088521 526.782709 \nL 339.166187 526.765974 \nL 340.243853 526.97842 \nL 341.321519 526.287751 \nL 342.399185 526.836012 \nL 343.476851 526.956585 \nL 344.554517 528.000916 \nL 345.632182 527.902828 \nL 346.709848 528.240458 \nL 347.787514 528.800325 \nL 348.86518 528.388868 \nL 351.020512 528.557855 \nL 352.098178 528.695984 \nL 353.175844 529.42044 \nL 354.25351 528.769215 \nL 355.331175 529.76904 \nL 356.408841 530.08604 \nL 357.486507 529.921081 \nL 358.564173 529.881756 \nL 359.641839 530.096613 \nL 360.719505 530.03952 \nL 361.797171 529.587439 \nL 362.874837 529.532917 \nL 363.952503 529.712371 \nL 365.030168 530.80448 \nL 366.107834 531.09082 \nL 367.1855 530.588483 \nL 368.263166 531.066878 \nL 369.340832 530.653354 \nL 370.418498 530.520128 \nL 371.496164 531.013283 \nL 372.57383 531.328057 \nL 373.651495 530.756132 \nL 374.729161 530.874426 \nL 375.806827 531.50726 \nL 376.884493 532.010842 \nL 377.962159 531.825147 \nL 379.039825 531.899107 \nL 380.117491 530.8331 \nL 381.195157 531.785862 \nL 382.272823 532.523779 \nL 383.350488 532.367419 \nL 384.428154 532.874871 \nL 385.50582 533.093889 \nL 386.583486 532.850849 \nL 387.661152 532.331194 \nL 388.738818 532.473987 \nL 389.816484 532.261183 \nL 390.89415 531.788101 \nL 391.971816 531.916292 \nL 395.204813 533.994884 \nL 396.282479 533.146504 \nL 398.437811 533.904468 \nL 400.593143 533.844394 \nL 401.670808 534.336847 \nL 402.748474 534.079047 \nL 403.82614 534.252313 \nL 404.903806 534.120081 \nL 407.059138 534.468695 \nL 408.136804 534.476512 \nL 409.21447 532.985122 \nL 410.292136 534.363479 \nL 411.369801 534.360179 \nL 412.447467 533.978097 \nL 413.525133 534.407097 \nL 414.602799 535.000897 \nL 415.680465 534.642783 \nL 416.758131 534.879675 \nL 417.835797 534.757632 \nL 418.913463 534.868678 \nL 419.991129 534.473094 \nL 421.068794 535.570437 \nL 422.14646 535.297082 \nL 423.224126 534.83933 \nL 425.379458 535.838731 \nL 427.53479 535.354426 \nL 428.612456 535.380952 \nL 429.690121 535.14671 \nL 430.767787 535.103463 \nL 431.845453 535.450341 \nL 434.000785 535.2804 \nL 435.078451 535.676196 \nL 436.156117 536.297649 \nL 437.233783 535.519492 \nL 438.311449 536.074377 \nL 439.389114 536.04544 \nL 440.46678 536.428529 \nL 441.544446 535.717416 \nL 442.622112 536.271176 \nL 443.699778 536.685985 \nL 444.777444 536.560086 \nL 445.85511 536.186391 \nL 446.932776 536.118671 \nL 448.010442 536.765801 \nL 449.088107 536.256468 \nL 450.165773 535.913486 \nL 451.243439 537.226164 \nL 452.321105 536.130914 \nL 453.398771 536.203085 \nL 454.476437 537.205732 \nL 455.554103 536.265823 \nL 456.631769 537.029087 \nL 457.709434 536.866976 \nL 458.7871 536.963938 \nL 459.864766 537.56276 \nL 460.942432 537.475391 \nL 462.020098 536.292945 \nL 463.097764 537.283243 \nL 464.17543 536.772095 \nL 465.253096 537.425095 \nL 466.330762 537.822494 \nL 467.408427 537.095958 \nL 468.486093 536.979467 \nL 469.563759 537.430872 \nL 471.719091 537.590505 \nL 472.796757 537.299077 \nL 473.874423 536.794302 \nL 474.952089 537.016592 \nL 476.029755 536.677995 \nL 477.10742 537.533809 \nL 478.185086 538.823499 \nL 479.262752 538.069628 \nL 481.418084 537.259778 \nL 482.49575 537.804104 \nL 483.573416 537.493013 \nL 485.728747 538.268494 \nL 486.806413 536.869679 \nL 487.884079 537.971329 \nL 488.961745 538.152744 \nL 490.039411 538.726921 \nL 491.117077 537.548092 \nL 492.194743 537.915309 \nL 493.272409 537.685664 \nL 494.350075 538.060446 \nL 495.42774 537.873797 \nL 497.583072 538.747882 \nL 498.660738 538.04619 \nL 499.738404 538.577782 \nL 500.81607 538.450982 \nL 501.893736 538.651345 \nL 502.971402 538.111802 \nL 504.049068 539.08848 \nL 505.126733 539.20888 \nL 506.204399 539.498692 \nL 507.282065 538.972942 \nL 508.359731 538.773772 \nL 509.437397 538.281611 \nL 510.515063 538.180357 \nL 511.592729 537.678457 \nL 512.670395 538.904905 \nL 513.748061 538.284314 \nL 514.825726 538.083236 \nL 515.903392 538.752334 \nL 516.981058 538.374836 \nL 518.058724 537.74187 \nL 519.13639 538.702661 \nL 520.214056 538.319969 \nL 521.291722 538.440489 \nL 522.369388 538.920884 \nL 524.524719 538.811481 \nL 525.602385 538.677407 \nL 526.680051 538.984271 \nL 527.757717 538.961773 \nL 528.835383 538.360937 \nL 529.913049 538.539835 \nL 530.990715 538.87777 \nL 532.068381 537.949082 \nL 533.146046 538.307382 \nL 534.223712 538.370212 \nL 535.301378 538.969339 \nL 536.379044 539.010903 \nL 537.45671 538.790785 \nL 539.612042 538.963297 \nL 540.689708 539.023291 \nL 541.767374 538.890874 \nL 542.845039 538.141985 \nL 543.922705 538.638228 \nL 545.000371 538.572562 \nL 546.078037 538.919559 \nL 547.155703 538.956009 \nL 548.233369 539.996326 \nL 549.311035 539.430588 \nL 550.388701 539.625664 \nL 551.466366 539.237328 \nL 552.544032 539.499911 \nL 553.621698 538.615889 \nL 554.699364 539.476366 \nL 555.77703 539.152715 \nL 559.010028 539.703374 \nL 560.087694 539.309472 \nL 561.165359 539.063054 \nL 562.243025 539.012374 \nL 563.320691 539.227761 \nL 564.398357 539.225959 \nL 565.476023 539.39064 \nL 566.553689 538.685489 \nL 568.709021 539.443547 \nL 569.786687 539.502455 \nL 570.864352 539.924578 \nL 573.019684 540.013895 \nL 574.09735 539.834122 \nL 575.175016 539.082187 \nL 576.252682 539.42615 \nL 577.330348 539.622736 \nL 578.408014 539.200811 \nL 579.485679 539.306359 \nL 580.563345 539.088758 \nL 581.641011 539.859376 \nL 582.718677 539.985845 \nL 583.796343 539.859694 \nL 584.874009 539.232664 \nL 585.951675 539.696418 \nL 587.029341 539.864901 \nL 588.107007 539.540694 \nL 589.184672 539.59776 \nL 590.262338 539.115695 \nL 591.340004 539.476843 \nL 592.41767 540.011218 \nL 593.495336 540.047337 \nL 594.573002 539.792293 \nL 595.650668 539.724295 \nL 596.728334 539.33678 \nL 597.806 540.079653 \nL 598.883665 540.03736 \nL 599.961331 540.198172 \nL 601.038997 540.034551 \nL 602.116663 540.169115 \nL 603.194329 539.465978 \nL 604.271995 540.03528 \nL 605.349661 540.037598 \nL 606.427327 539.616363 \nL 607.504992 539.593096 \nL 608.582658 539.446488 \nL 609.660324 538.93363 \nL 610.73799 539.57778 \nL 611.815656 539.40707 \nL 612.893322 539.075257 \nL 613.970988 539.778487 \nL 615.048654 539.539859 \nL 616.12632 539.928686 \nL 617.203985 539.863417 \nL 618.281651 539.127275 \nL 620.436983 539.645883 \nL 621.514649 540.114685 \nL 622.592315 540.327264 \nL 623.669981 539.287451 \nL 625.825313 540.194131 \nL 626.902978 539.167078 \nL 627.980644 539.603312 \nL 629.05831 540.20799 \nL 630.135976 540.270383 \nL 631.213642 540.175488 \nL 632.291308 539.68179 \nL 633.368974 540.087974 \nL 634.44664 539.757128 \nL 635.524306 540.100429 \nL 636.601971 539.948534 \nL 637.679637 540.3237 \nL 638.757303 539.754134 \nL 639.834969 540.183425 \nL 640.912635 539.585862 \nL 641.990301 539.603338 \nL 643.067967 539.502667 \nL 644.145633 540.174693 \nL 646.300964 540.63752 \nL 647.37863 540.67931 \nL 648.456296 540.326456 \nL 650.611628 539.981327 \nL 651.689294 540.146246 \nL 652.76696 539.792478 \nL 653.844626 539.181984 \nL 654.922291 539.786277 \nL 655.999957 540.652439 \nL 657.077623 540.296869 \nL 659.232955 540.343363 \nL 660.310621 539.88842 \nL 661.388287 540.263864 \nL 662.465953 540.31579 \nL 663.543619 540.034935 \nL 664.621284 539.262356 \nL 665.69895 540.480564 \nL 666.776616 540.413931 \nL 667.854282 539.78694 \nL 668.931948 539.975537 \nL 670.009614 539.97653 \nL 671.08728 540.900911 \nL 672.164946 541.209034 \nL 673.242611 540.171302 \nL 674.320277 540.029105 \nL 675.397943 540.238067 \nL 676.475609 539.904624 \nL 677.553275 540.730785 \nL 678.630941 540.732216 \nL 679.708607 539.801289 \nL 680.786273 540.551701 \nL 681.863939 540.216351 \nL 682.941604 540.210932 \nL 685.096936 539.76415 \nL 686.174602 539.083074 \nL 687.252268 540.441583 \nL 688.329934 540.128598 \nL 689.4076 539.957597 \nL 690.485266 539.963135 \nL 691.562932 540.194913 \nL 692.640597 540.160397 \nL 693.718263 539.819349 \nL 695.873595 539.910825 \nL 696.951261 540.448433 \nL 698.028927 540.789031 \nL 700.184259 539.595707 \nL 701.261924 540.354161 \nL 702.33959 539.352892 \nL 703.417256 540.07809 \nL 704.494922 539.491683 \nL 705.572588 540.540452 \nL 706.650254 540.759404 \nL 707.72792 540.266382 \nL 708.805586 540.766904 \nL 709.883252 540.132586 \nL 710.960917 540.614532 \nL 715.271581 540.309086 \nL 716.349247 539.97441 \nL 717.426913 540.479331 \nL 718.504579 540.498517 \nL 719.582245 540.316413 \nL 720.65991 539.703679 \nL 722.815242 539.798997 \nL 723.892908 540.228222 \nL 724.970574 540.007455 \nL 726.04824 540.137753 \nL 727.125906 539.901232 \nL 728.203572 540.021911 \nL 729.281237 540.375639 \nL 730.358903 539.612494 \nL 732.514235 540.395023 \nL 734.669567 539.542111 \nL 735.747233 540.55622 \nL 736.824899 539.935748 \nL 737.902565 540.040142 \nL 738.98023 539.973655 \nL 740.057896 540.552125 \nL 741.135562 539.978995 \nL 743.290894 540.703795 \nL 744.36856 539.546802 \nL 745.446226 540.478285 \nL 746.523892 540.464942 \nL 747.601558 540.760663 \nL 748.679223 540.686663 \nL 750.834555 540.197125 \nL 751.912221 539.72358 \nL 752.989887 540.425352 \nL 755.145219 540.32366 \nL 756.222885 539.695861 \nL 757.300551 539.797646 \nL 758.378216 540.237391 \nL 759.455882 539.761461 \nL 760.533548 540.508203 \nL 761.611214 540.585939 \nL 762.68888 540.544825 \nL 763.766546 539.968024 \nL 764.844212 540.166836 \nL 765.921878 539.621676 \nL 766.999543 540.549065 \nL 769.154875 541.131656 \nL 770.232541 541.191014 \nL 771.310207 540.575604 \nL 772.387873 540.82132 \nL 773.465539 539.578614 \nL 774.543205 539.715789 \nL 775.620871 539.701333 \nL 776.698536 540.493853 \nL 777.776202 540.521121 \nL 779.931534 540.151506 \nL 779.931534 540.151506 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 34.240625 565.918125 \nL 34.240625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 815.440625 565.918125 \nL 815.440625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 34.240625 565.918125 \nL 815.440625 565.918125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 34.240625 22.318125 \nL 815.440625 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_15\">\n    <!-- Model MAE -->\n    <g transform=\"translate(391.845313 16.318125)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path id=\"DejaVuSans-32\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-77\"/>\n     <use x=\"86.279297\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"147.460938\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"210.9375\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"272.460938\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"300.244141\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"332.03125\" xlink:href=\"#DejaVuSans-77\"/>\n     <use x=\"418.310547\" xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"486.71875\" xlink:href=\"#DejaVuSans-69\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 41.240625 59.674375 \nL 96.515625 59.674375 \nQ 98.515625 59.674375 98.515625 57.674375 \nL 98.515625 29.318125 \nQ 98.515625 27.318125 96.515625 27.318125 \nL 41.240625 27.318125 \nQ 39.240625 27.318125 39.240625 29.318125 \nL 39.240625 57.674375 \nQ 39.240625 59.674375 41.240625 59.674375 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_15\">\n     <path d=\"M 43.240625 35.416562 \nL 63.240625 35.416562 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_16\"/>\n    <g id=\"text_16\">\n     <!-- train -->\n     <g transform=\"translate(71.240625 38.916562)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n       <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n       <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n       <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 43.240625 50.094687 \nL 63.240625 50.094687 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_18\"/>\n    <g id=\"text_17\">\n     <!-- test -->\n     <g transform=\"translate(71.240625 53.594687)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"100.732422\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"152.832031\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p9437348bb8\">\n   <rect height=\"543.6\" width=\"781.2\" x=\"34.240625\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzYAAAJcCAYAAAArVzHJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAACIM0lEQVR4nOzddXid5f3H8fdzNO7WNHV3d4oUdxsyYAw2YGNsY8pgg43ZbzDGBBgMGS7DHVqshXqbuqWWprFGGvdjz++P5+TUkqYpTXMCn9d15erJc+S5zzlpez753vf3NkzTREREREREpCezdfcAREREREREviwFGxERERER6fEUbEREREREpMdTsBERERERkR5PwUZERERERHo8BRsREREREenxFGxEROS4Mgyjv2EYpmEYjiO47XWGYSw6HuMSEZGeTcFGRETaZRhGnmEYHsMwUg46viYYTvp309D2D0hrDjqeEhxzXhv3WWAYRpVhGO6Djj8dvE/9fl/ruvgpiIjIMaRgIyIiHdkFfLP1G8MwxgBR3TecQ0QZhjF6v++vwhrzAYIhbDZgAhe08Th/NU0zZr+vcV0yWhER6RIKNiIi0pHngGv3+/7bwLP738AwjHjDMJ41DKPcMIzdhmHcaRiGLXid3TCMvxmGsdcwjFzg3Dbu+1/DMPYYhlFkGMafDMOwd3J8397v+2sPHt9+x5cBTx90exER+QpQsBERkY4sA+IMwxgRDBxXAs8fdJsHgXhgIHASVoi4PnjdjcB5wARgMvCNg+77NOADBgdvcwZwQyfG9zxwZTBAjQRigOVt3O5a4IXg15mGYaR34hwiIhLmFGxERORItFZtTge2AEWtV+wXdu4wTbPONM084H7gW8GbXA780zTNAtM0K4G/7HffdOAc4CemaTaYplkG/CP4eEeqENgKnBYc43MH38AwjBOAfsArpmmuAnZiTVnb3y8Mw6je7+uZToxBRES6WYcdaURERLDCwhfAAA6d5pUCOIHd+x3bDfQOXs4ECg66rlW/4H33GIbResx20O2PxLPAdcBMrHU0Qw+6/tvAR6Zp7g1+/2Lw2D/2u83fTNO8s5PnFRGRMKFgIyIiHTJNc7dhGLuwqivfPejqvYAXK6RsDh7ry76qzh6gz36377vf5QKgBUgxTdP3JYb4OvAQsMo0zXzDMELBxjCMSKyqkd0wjJLgYTeQYBjGONM01f1MROQrQFPRRETkSH0XmGOaZsP+B03T9AOvAH82DCPWMIx+wM/Ytw7nFeDHhmFkGYaRCNy+3333AB8B9xuGEWcYhs0wjEGGYZzUmYEFxzSHttfmXAT4gZHA+ODXCGAhBzZFEBGRHkzBRkREjohpmjtN08xu5+ofAQ1ALrAIa6rXk8HrHgfmAeuA1cAbB933WsCFVe2pAl4Deh3F+LJN09zZxlXfBp4yTTPfNM2S1i+sCs/V+20UettB+9jsbeOxREQkTBmmaXb3GERERERERL4UVWxERERERKTHU7AREREREZEeT8FGRERERER6PAUbERERERHp8cJqH5uUlBSzf//+3T0MEREREREJU6tWrdprmmbqwcfDKtj079+f7Oz2OomKiIiIiMjXnWEYu9s6rqloIiIiIiLS4ynYiIiIiIhIj6dgIyIiIiIiPV5YrbFpi9frpbCwkObm5u4eSpeKiIggKysLp9PZ3UMREREREelxwj7YFBYWEhsbS//+/TEMo7uH0yVM06SiooLCwkIGDBjQ3cMREREREelxwn4qWnNzM8nJyV/ZUANgGAbJyclf+aqUiIiIiEhXCftgA3ylQ02rr8NzFBERERHpKj0i2IiIiIiIiByOgk0Hqqurefjhhzt9v3POOYfq6upjPyARERERETmEgk0H2gs2Pp/vsPf74IMPSEhI6KJRiYiIiIjI/sK+K1p3u/3229m5cyfjx4/H6XQSERFBYmIiOTk5bNu2jYsuuoiCggKam5u59dZbuemmmwDo378/2dnZ1NfXc/bZZ3PCCSewZMkSevfuzdtvv01kZGQ3PzMRERERka+OHhVsfv/uJjYX1x7TxxyZGcfvzh/V7vX33HMPGzduZO3atSxYsIBzzz2XjRs3htoyP/nkkyQlJdHU1MSUKVO49NJLSU5OPuAxtm/fzksvvcTjjz/O5Zdfzuuvv84111xzTJ+HiIiIiMjXWY8KNuFg6tSpB+w188ADD/Dmm28CUFBQwPbt2w8JNgMGDGD8+PEATJo0iby8vOM1XBERERGRr4UeFWwOV1k5XqKjo0OXFyxYwCeffMLSpUuJiori5JNPbnMvGrfbHbpst9tpamo6LmMVEREREfm66NLmAYZhJBiG8ZphGDmGYWwxDGNGV56vK8TGxlJXV9fmdTU1NSQmJhIVFUVOTg7Lli07zqMTERERERHo+orNv4C5pml+wzAMFxDVxec75pKTk5k1axajR48mMjKS9PT00HVnnXUW//nPfxgxYgTDhg1j+vTp3ThSEREREZGvL8M0za55YMOIB9YCA80jPMnkyZPN7OzsA45t2bKFESNGHPsBhqGv03MVERERETkahmGsMk1z8sHHu3Iq2gCgHHjKMIw1hmE8YRhG9ME3MgzjJsMwsg3DyC4vL+/C4YiIiIiIyFdVVwYbBzAReMQ0zQlAA3D7wTcyTfMx0zQnm6Y5OTU1tQuHIyIiIiIiX1VdGWwKgULTNJcHv38NK+iIiIiIiIgcU10WbEzTLAEKDMMYFjx0KrC5q84nIiIiIiJfX13dFe1HwAvBjmi5wPVdfD4REREREfka6tJgY5rmWuCQjgXhrri6CY8vQP+UQ3odiIiIiIhIGOrSDTp7Kp/fpMUXAKC6upqHH374qB7nn//8J42NjcdyaCIiIiIi0gYFmzYYBrRuvaNgIyIiIiIS/rp6jU2PZBgQCF6+/fbb2blzJ+PHj+f0008nLS2NV155hZaWFi6++GJ+//vf09DQwOWXX05hYSF+v5+77rqL0tJSiouLOeWUU0hJSWH+/Pnd+pxERERERL7Kelaw+fB2KNlwbB8zYwycfc8BhwzDCFVs7rnnHjZu3MjatWv56KOPeO2111ixYgWmaXLBBRfwxRdfUF5eTmZmJu+//z4ANTU1xMfH8/e//5358+eTkpJybMcsIiIiIiIH0FS0NhhAMNcc4KOPPuKjjz5iwoQJTJw4kZycHLZv386YMWP4+OOP+dWvfsXChQuJj48/7mMWEREREfk661kVm4MqK13FMKCNXINpmtxxxx1873vfO+S61atX88EHH3DnnXdy6qmn8tvf/rbrByoiIiIiIoAqNm2yBaeimaZJbGwsdXV1AJx55pk8+eST1NfXA1BUVERZWRnFxcVERUVxzTXX8Mtf/pLVq1cDHHBfERERERHpOj2rYnOcGME/TSA5OZlZs2YxevRozj77bK666ipmzJgBQExMDM8//zw7duzgl7/8JTabDafTySOPPALATTfdxFlnnUVmZqaaB4iIiIiIdCHDbGsxSTeZPHmymZ2dfcCxLVu2MGLEiOM6jvK6FvbUNDEqMw677fgVtbrjuYqIiIiI9CSGYawyTXPywcc1Fa0NRrBkE0aZT0REREREDkPBpg2hqWgKNiIiIiIiPUKPCDbHe7qcESzZmG32Rusa4TQlUERERESkpwn7YBMREUFFRcVx/eBvC5ZsAsfplKZpUlFRQURExPE5oYiIiIjIV0zYd0XLysqisLCQ8vLy43bOJo+figYPVLtx2o9P9ouIiCArK+u4nEtERERE5Ksm7ION0+lkwIABx/Wcn24p5caXsnn7llmM6JNwXM8tIiIiIiKdF/ZT0bpDa5XG6w9080hERERERORIKNi0weWwXhaPT8FGRERERKQnULBpQ2vFxqOKjYiIiIhIj6Bg0wa3KjYiIiIiIj2Kgk0b9q2x0d4yIiIiIiI9gYJNG0JrbPz+bh6JiIiIiIgcCQWbNjjt1g6dXp8qNiIiIiIiPYGCTRtaKzYtah4gIiIiItIjKNi0wdW6xkbNA0REREREegQFmzbsW2OjYCMiIiIi0hMo2LTBqYqNiIiIiEiPomDTBofNwDBUsRERERER6SkUbNpgGAZOu03BRkRERESkh1CwaYfbbsOjqWgiIiIiIj2Cgk07nA4bXlVsRERERER6BAWbdrhUsRERERER6TEUbNrhctjw+s3uHoaIiIiIiBwBBZt2OO2GKjYiIiIiIj2Egk07XA67uqKJiIiIiPQQCjbtcKliIyIiIiLSYyjYtMOlrmgiIiIiIj2Ggk07nOqKJiIiIiLSYyjYtEMVGxERERGRnkPBph1Ou40WVWxERERERHoEBZt2qGIjIiIiItJzKNi0w2W3qd2ziIiIiEgPoWDTDpfdhtdndvcwRERERETkCCjYtMPpMFSxERERERHpIRRs2uGy2/GqeYCIiIiISI+gYNMOp8OgRRUbEREREZEeQcGmHW671RXNNLXORkREREQk3CnYtMNpt2Ga4Aso2IiIiIiIhDsFm3a4HNZLo71sRERERETCn4JNO5x266XxqIGAiIiIiEjYU7BpR2vFRi2fRURERETCn4JNO1yq2IiIiIiI9BgKNu3Yt8ZGzQNERERERMKdgk07tMZGRERERKTnULBph7qiiYiIiIj0HAo27XDaDQBaVLEREREREQl7CjbtUMVGRERERKTnULBph7qiiYiIiIj0HAo27VDFRkRERESk51CwaYe6oomIiIiI9BwKNm157TsMfO0MADyq2IiIiIiIhD0FmzYZ2HzNgCo2IiIiIiI9gYJNW+wubAEvAF6/2c2DERERERGRjijYtMXhwvC3AODx+bt5MCIiIiIi0hEFm7bYXRiq2IiIiIiI9BgKNm2xu8DvAdQ8QERERESkJ1CwaYvDvS/YqHmAiIiIiEjYU7Bpi92FEfDhspuq2IiIiIiI9AAKNm2xuwCItgfwqmIjIiIiIhL2FGzaEgo2flVsRERERER6AAWbtjjcQLBio2AjIiIiIhL2FGzaYncCEGn306KpaCIiIiIiYU/Bpi12q2ITY/drHxsRERERkR5AwaYtwYpNhC2Ax+fv5sGIiIiIiEhHFGzaElxjE2X3qWIjIiIiItIDKNi0JTgVLcLm1wadIiIiIiI9gIJNW4JT0aIUbEREREREegQFm7Y4Wis2Pu1jIyIiIiLSAyjYtCW4QWekKjYiIiIiIj2Cgk1bgsHGbfi0QaeIiIiISA+gYNOWYLCJsPk1FU1EREREpAdQsGmLY7+KjaaiiYiIiIiEPQWbtoSmoqliIyIiIiLSEyjYtCW4j43b8Kl5gIiIiIhID6Bg05bgVDSXoXbPIiIiIiI9gYJNW4JT0Vx48frNbh6MiIiIiIh0RMGmLa1rbPDhD5j4Awo3IiIiIiLhTMGmLTY7GHac+AC0l42IiIiISJhTsGmPw40TLwAtaiAgIiIiIhLWFGzaY3eqYiMiIiIi0kMo2LTH7sZpWhUbtXwWEREREQlvCjbtcbhxqGIjIiIiItIjKNi0x+7EoYqNiIiIiEiPoGDTHrsbh2lVbLRJp4iIiIhIeFOwaY/dicP0AKrYiIiIiIiEOwWb9jjc2APWVDSvXxt0ioiIiIiEMwWb9thd2LXGRkRERESkR1CwaY/dhT1gTUVTVzQRERERkfCmYNMeuwtbsGLTooqNiIiIiEhYU7Bpj8OFzd+6xkbBRkREREQknCnYtMfuDlVstMZGRERERCS8Kdi0x+7C8LcAqtiIiIiIiIQ7BZv2OFzYgu2etUGniIiIiEh4c3TlgxuGkQfUAX7AZ5rm5K483zFld4FfG3SKiIiIiPQEXRpsgk4xTXPvcTjPsWV3YbQGG1VsRERERETCmqaitWe/io3XZ3bzYERERERE5HC6OtiYwEeGYawyDOOmtm5gGMZNhmFkG4aRXV5e3sXD6QSHGyPgw2Ez8fj93T0aERERERE5jK4ONieYpjkROBu4xTCMEw++gWmaj5mmOdk0zcmpqaldPJxOsDsBiLL78fpVsRERERERCWddGmxM0ywK/lkGvAlM7crzHVN2NwAx9oCaB4iIiIiIhLkuCzaGYUQbhhHbehk4A9jYVec75hxWsImy+9U8QEREREQkzHVlV7R04E3DMFrP86JpmnO78HzHVnAqWrTdr4qNiIiIiEiY67JgY5pmLjCuqx6/ywWnokXaA3hVsRERERERCWtq99ye1oqNTRUbEREREZFwp2DTnuAam0ibXxUbEREREZEwp2DTHrsLgEi7nxZVbEREREREwpqCTXtag40qNiIiIiIiYU/Bpj37BRutsRERERERCW8KNu0JrrGJsHnx+s1uHoyIiIiIiByOgk17ghUbtyo2IiIiIiJhT8GmPcFgE2H4tMZGRERERCTMKdi0x7Ev2KgrmoiIiIhIeFOwaU/rVDRDXdFERERERMKdgk177FbzALfhw6NgIyIiIiIS1hRs2mN3AuDCh1dT0UREREREwpqCTXuC7Z5dqtiIiIiIiIQ9BZv2BNfYuPDh9ZuYpvayEREREREJVwo27bHZwbDjMnwAqtqIiIiIiIQxBZvDcbhxYgUbr18VGxERERGRcKVgczh2J07TC4BHDQRERERERMKWgs3h2N04sYKN9rIREREREQlfCjaHY3fhMINrbFSxEREREREJWwo2h+NwhSo2ah4gIiIiIhK+FGwOx+7CoTU2IiIiIiJhT8HmcOwu7KbW2IiIiIiIhDsFm8Oxu7AHVLEREREREQl3CjaH43Dvm4qmio2IiIiISNhSsDkcuwubKjYiIiIiImFPweZw7C7spgcAr9/s5sGIiIiIiEh7FGwOx+HC5lfFRkREREQk3CnYHM5+U9HUFU1EREREJHwp2ByO3Y0RaAFUsRERERERCWcKNodjd2IE1BVNRERERCTcKdgcjsON4beaB6hiIyIiIiISvhRsDsfuwvBrjY2IiIiISLhTsDkcuwv8WmMjIiIiIhLuFGwOx+HGCPiwGQFVbEREREREwpiCzeHYnQBE2QO0KNiIiIiIiIQtBZvDsbsBiLUH8PrMbh6MiIiIiIi0R8HmcOwuACLtfjx+fzcPRkRERERE2qNgczgOK9hE2/2q2IiIiIiIhDEFm8M5oGKjNTYiIiIiIuFKweZwgsEm2qZgIyIiIiISzhRsDsdhNQ+IsAe0j42IiIiISBhTsDmcUMXGp31sRERERETCmILN4QSDTYTNr4qNiIiIiEgYU7A5nNbmATa/KjYiIiIiImFMweZwWtfY2Hyq2IiIiIiIhDEFm8OxO4HgVDS/9rEREREREQlXCjaHYw9WbAwfHp+/mwcjIiIiIiLtUbA5nP0qNl5VbEREREREwpaCzeEE19i40RobEREREZFwpmBzOMGpaC7tYyMiIiIiEtYUbA4nOBVNFRsRERERkfCmYHM4waloLsOHRxUbEREREZGwpWBzOMENOl1YwcY01UBARERERCQcKdgcjs0Ohh0XXkwT/AEFGxERERGRcKRg0xG7Cyc+AE1HExEREREJUwo2HXHsCzZenyo2IiIiIiLhSMGmI/tVbFr8/m4ejIiIiIiItEXBpiN2N07TC6CWzyIiIiIiYUrBpiMOFw6sYOP1ayqaiIiIiEg4UrDpiN2FI6CKjYiIiIhIOFOw6YjdhcNsrdgo2IiIiIiIhCMFm47YXdiDwaZFFRsRERERkbCkYNMRhxt7QBUbEREREZFwpmDTEbszVLHRGhsRERERkfCkYNMRuxtbwAOoYiMiIiIiEq4UbDpid2JTxUZEREREJKwp2HTE4cbmtyo2HlVsRERERETCkoJNR+xubNrHRkREREQkrCnYdMTuxPC3rrExu3kwIiIiIiLSFgWbjjjcGMHmAR6fv5sHIyIiIiIibVGw6YjdheFv3cdGFRsRERERkXCkYNMRuwv8LYCaB4iIiIiIhCsFm47YXRgBHwYBNQ8QEREREQlTCjYdcbgAiLL7VbEREREREQlTCjYdsbcGmwBeVWxERERERMKSgk1H7G4AYlSxEREREREJWwo2HQlORYu0B/Aq2IiIiIiIhCUFm44Ep6JF2/y0aCqaiIiIiEhYUrDpSOsaG4df+9iIiIiIiIQpBZuOtAYbWwCPz9/NgxERERERkbYo2HTEYTUPiLR5VbEREREREQlTCjYdsTsBiLBpg04RERERkXClYNMRe2vFxqd2zyIiIiIiYUrBpiPBqWgRNr8qNiIiIiIiYUrBpiPBqWiRhl/72IiIiIiIhCkFm44Ep6K5VbEREREREQlbCjYdaW0eYPhUsRERERERCVMKNh1xtFZsfKrYiIiIiIiEKQWbjgQ36HTjw6N9bEREREREwpKCTUdag43hw+Pzd/NgRERERESkLQo2HQkGG5fhw6uKjYiIiIhIWFKw6UhwjY0LrzboFBEREREJUwo2HbHZwbDjNPz4Ayb+gKo2IiIiIiLhRsHmSNhduPACqOWziIiIiEgYUrA5Eg4XTtMHoOloIiIiIiJhSMHmSNhdOIMVG+1lIyIiIiISfhRsjoTdjdPUVDQRERERkXClYHMk7E4cBKeiqWIjIiIiIhJ2FGyOhMONQxUbEREREZGwpWBzJOzOULBpUcVGRERERCTsKNgcCbsbu6nmASIiIiIi4UrB5kg49gUbr18bdIqIiIiIhJsuDzaGYdgNw1hjGMZ7XX2uLmN3Yg+oYiMiIiIiEq6OR8XmVmDLcThP17G7sQc8ALT4/N08GBEREREROViXBhvDMLKAc4EnuvI8Xc7uxKY1NiIiIiIiYaurKzb/BG4D2k0DhmHcZBhGtmEY2eXl5V08nKPkcGPzWxUbj9o9i4iIiIiEnS4LNoZhnAeUmaa56nC3M03zMdM0J5umOTk1NbWrhvPl2F3YAmr3LCIiIiISrrqyYjMLuMAwjDzgf8AcwzCe78LzdR27CyO4xkZT0UREREREwk+XBRvTNO8wTTPLNM3+wJXAZ6ZpXtNV5+tSdheGXxUbEREREZFwpX1sjoTDjeFXxUZEREREJFw5jsdJTNNcACw4HufqEnYXKNiIiIiIiIQtVWyOhN2FEfDisJl4/NrHRkREREQk3CjYHAmHC4Boe0AVGxERERGRMKRgcyTsVrCJcQTUPEBEREREJAwp2BwJuxuAaLtfFRsRERERkTCkYHMk7E4AohyaiiYiIiIiEo4UbI6EY1/FpsWvYCMiIiIiEm4UbI5EcI1NpE1T0UREREREwpGCzZEIBptoTUUTEREREQlLCjZHIjgVLcrmp8WnfWxERERERMKNgs2RCDYP0FQ0EREREZHwpGBzJILtniNtPjxqHiAiIiIiEnYUbI5EcI1NhKGKjYiIiIhIOFKwORKOYLCx+RRsRERERETCkILNkWit2Nj8tCjYiIiIiIiEHQWbIxGaiqaKjYiIiIhIOFKwORLBds9udUUTEREREQlLCjZHIlixcRteWtQVTUREREQk7Bw22BiGEXeY6/oe++GEqWCwcWFVbEzT7OYBiYiIiIjI/jqq2CxovWAYxqcHXffWsR5M2ApVbHwAeP0KNiIiIiIi4aSjYGPsdznpMNd9tQXX2LjwAtDi83fnaERERERE5CAdBRuzncttff/VZbODYcOFFWjUQEBEREREJLw4Org+zTCMn2FVZ1ovE/w+tUtHFm7sbpzBio1HDQRERERERMJKR8HmcSC2jcsAT3TJiMKV3YUTa42NKjYiIiIiIuHlsMHGNM3ft3edYRhTjv1wwpjDta9io2AjIiIiIhJWOqrYHMAwjJHAN4Nf1cDkLhhTeLK7cZitzQMUbEREREREwkmHwcYwjP7sCzNeoB8w2TTNvC4dWbixOxVsRERERETCVEcbdC4F3scKQJeapjkJqPvahRoAhxu7qTU2IiIiIiLhqKN2z6VYDQPS2dcF7evT5nl/dicO0wOoK5qIiIiISLg5bLAxTfMiYAywCrjbMIxdQKJhGFOPw9jCi92NPaDmASIiIiIi4ajDNTamadYATwFPGYaRDlwO/MMwjL6mafbp6gGGDbsLu691jY2/mwcjIiIiIiL762gq2gFM0yw1TfNB0zRnASd00ZjCk8OFLRCciqaKjYiIiIhIWDlsxcYwjHc6uP8Fx3As4c3uwqapaCIiIiIiYamjqWgzgALgJWA5YHT5iMLV/sFGzQNERERERMJKR8EmAzgdaw+bq7BaP79kmuamrh5Y2HG4NRVNRERERCRMddQVzW+a5lzTNL8NTAd2AAsMw/jhcRldOLG7MPxWsNEGnSIiIiIi4aXDrmiGYbiBc7GqNv2BB4A3u3ZYYcjuAn9rVzQFGxERERGRcNJR84BngdHAB8DvTdPceFxGFY7sLgx/Cy67TVPRRERERETCTEcVm2uABuBW4MeGEeodYACmaZpxXTi28OJwg8+Dy6FgIyIiIiISbg4bbEzT7NQ+N19pdif4g8HGrw06RURERETCiYLLkbK7IeAlwq6uaCIiIiIi4UbB5kjZnQBEOUw1DxARERERCTMKNkfK4QYg2u5XxUZEREREJMwo2BwpuxVsohRsRERERETCjoLNkWqdimb34/Er2IiIiIiIhBMFmyO131Q0rbEREREREQkvCjZHyu4CINIe0FQ0EREREZEwo2BzpFqDjaGKjYiIiIhIuFGwOVKhio0fj08bdIqIiIiIhBMFmyPlCAYbm0/NA0REREREwoyCzZEKtnuOtPm0xkZEREREJMwo2BypYFe0CEPBRkREREQk3CjYHKngGpsIw6fmASIiIiIiYUbB5kgFg41bFRsRERERkbCjYHOkHPuCjS9gEgiY3TwgERERERFppWBzpILNA9yG1epZndFERERERMKHgs2RCjYPcBk+AK2zEREREREJIwo2Ryq4xsaFF4AWbdIpIiIiIhI2FGyOVLBi4w4GGzUQEBEREREJHwo2RypYsXEq2IiIiIiIhB0FmyNlGGB34TStNTZqHiAiIiIiEj4UbDrD7lbFRkREREQkDCnYdIbDhcP0AAo2IiIiIiLhRMGmM+xuHGZrVzQFGxERERGRcKFg0xl2ZyjYqGIjIiIiIhI+FGw6w+HGEVDFRkREREQk3CjYdIbdja21YqOuaCIiIiIiYUPBpjMcLuwBNQ8QEREREQk3CjadYXeHgk2Lz9/NgxERERERkVYKNp3hcGELqHmAiIiIiEi4UbDpDLsbQ1PRRERERETCjoJNZzhc2PwtgIKNiIiIiEg4UbDpDLsbw+/BZqgrmoiIiIhIOFGw6QyHG3weXA6bKjYiIiIiImFEwaYz7E7wt+Cy27RBp4iIiIhIGFGw6Qx7a8XGrmAjIiIiIhJGFGw6w+ECvwe3pqKJiIiIiIQVBZvOsLvB32IFGzUPEBEREREJGwo2neFwgxkgwm7i8fm7ezQiIiIiIhKkYNMZdhcA0Q6/1tiIiIiIiIQRBZvOcLgBiLb5tcZGRERERCSMKNh0Rqhi41OwEREREREJIwo2nRGs2ETa/GoeICIiIiISRhRsOsNuBZsoTUUTEREREQkrCjadYXcCwYqNgo2IiIiISNhQsOmM0FQ0n7qiiYiIiIiEEQWbzgg2D4iwq92ziIiIiEg4UbDpjNaKjeHTBp0iIiIiImFEwaYzgs0DIgyfuqKJiIiIiIQRBZvOcLQGGy8eXwDTNLt5QCIiIiIiAgo2nRMMNm58BEzwBRRsRERERETCgYJNZ7RWbGxeALV8FhEREREJEwo2neGIAMCFD1CwEREREREJFwo2nRGaihas2KiBgIiIiIhIWFCw6YxgVzQXHkAVGxERERGRcKFg0xnBio3TtCo2LdrLRkREREQkLCjYdIbNDjbnfsFGFRsRERERkXCgYNNZDremoomIiIiIhBkFm85yuHGaCjYiIiIiIuFEwaazHBHYTXVFExEREREJJwo2neVw4wi0AKrYiIiIiIiECwWbzrK7cQSsqWhqHiAiIiIiEh4UbDrL4cYe0BobEREREZFw0mXBxjCMCMMwVhiGsc4wjE2GYfy+q851XDkisCnYiIiIiIiEFUcXPnYLMMc0zXrDMJzAIsMwPjRNc1kXnrPrOVzYW5oBaFHzABERERGRsNBlFRvTUh/81hn8MrvqfMeNIwIj2Dygxevv5sGIiIiIiAh08RobwzDshmGsBcqAj03TXN7GbW4yDCPbMIzs8vLyrhzOseFwY/MHg42moomIiIiIhIUuDTamafpN0xwPZAFTDcMY3cZtHjNNc7JpmpNTU1O7cjjHhiMCw+/BMFSxEREREREJF8elK5ppmtXAfOCs43G+LmV3Y/haiHTaaVKwEREREREJC13ZFS3VMIyE4OVI4HQgp6vOd9w43OBrJtJpp9mrqWgiIiIiIuGgK7ui9QKeMQzDjhWgXjFN870uPN/x4YgAn4cIVWxERERERMJGlwUb0zTXAxO66vG7TbBiExFtU7AREREREQkTx2WNzVeKww0BL9FONQ8QEREREQkXCjad5XADEOMIqGIjIiIiIhImFGw6yxEBQKwzQJNHwUZEREREJBwo2HSW3QVAjM2vrmgiIiIiImFCwaazWis2Dj/NmoomIiIiIhIWFGw6K7jGJtrh0xobEREREZEwoWDTWcGKTbTNp4qNiIiIiEiYULDprNaKjd2vio2IiIiISJhQsOmsYLCJsvlo9gYwTbObByQiIiIiIgo2nRWcihZp8wHQ4lNnNBERERGR7qZg01nBds+RhhdAe9mIiIiIiIQBBZvOClZsIgyrYtPsU7AREREREeluCjadFVxjE2lTxUZEREREJFwo2HRWsGLjxgOgzmgiIiIiImFAwaaznJHAvmDT7FXzABERERGR7qZg01mtwcZsDTaq2IiIiIiIdDcFm86yuwAjFGy0xkZEREREpPsp2HSWYYAzCqfZDKgrmoiIiIhIOFCwORrOCJyBFkAVGxERERGRcKBgczQckTiCwabZp+YBIiIiIiLdTcHmaDgjsQeCU9FUsRERERER6XYKNkfDGYHdZwUb7WMjIiIiItL9FGyOhiMSm78Zp91Qu2cRERERkTCgYHM0nBHgbSbCaVfFRkREREQkDCjYHA1nFHgbiXTaVbEREREREQkDCjZHwxEBPqti0+xVVzQRERERke6mYHM0nJHgbSbSadc+NiIiIiIiYUDB5mg4I8HXRITLTrNPwUZEREREpLsp2BwNRyR4m4hw2FSxEREREREJAwo2R8MZAd4mIl1qHiAiIiIiEg4UbI6GMxJMP1F2U80DRERERETCgILN0XBEAhDn8GkfGxERERGRMKBgczScEQDE2r0KNiIiIiIiYcDR3QPokYIVmxi7V1PRRERERETCgILN0XAGg43NS7O3m8ciIiIiIiKainZU9gs2Xr+Jz6+qjYiIiIhId1KwORoOa41NlM0q1zT7FGxERERERLqTgs3RcEYBEBkMNtqkU0RERESkeynYHI1gV7RIPADapFNEREREpJsp2ByNYFe0SEPBRkREREQkHCjYHI1g84CIYMVGe9mIiIiIiHQvBZujEQw27tBUNDUPEBERERHpTgo2R6M12JgtgCo2IiIiIiLdTcHmaDgiAQN3oAlQVzQRERERke6mYHM0bDZwReP0NwLQ4lOwERERERHpTgo2R8sVjVMVGxERERGRsKBgc7Rc0Th9VsVGa2xERERERLqXgs3RcsVg9zUA6oomIiIiItLdFGyOlisGm9cKNqrYiIiIiIh0LwWbo+WKxvA0EOG00aJgIyIiIiLSrRRsjpYrGjwNRDrtqtiIiIiIiHQzBZuj5Y4BTz2RTjuN6oomIiIiItKtFGyOlssKNtFuB40eX3ePRkRERETka03B5mgFp6JFuezUt6hiIyIiIiLSnRRsjpYrGgI+EtwBGlpUsRERERER6U4KNkfLFQNAssOrYCMiIiIi0s0c3T2AHisYbBIcHho8RjcPRkRERETk600Vm6PligaCwUZrbEREREREupWCzdEKVmzi7R7qNRVNRERERKRbKdgcrWDFJt7WjMcXwOsPdPOARERERES+vhRsjpbbqtjE2DwANGo6moiIiIhIt1GwOVrBik2M0QxAvTbpFBERERHpNgo2Ryu4xiY6GGzU8llEREREpPso2BytYMUmymwCUAMBEREREZFupGBztJxRgEFEMNhojY2IiIiISPdRsDlahgHuOCICjYAqNiIiIiIi3UnB5suIiMftqwe0xkZEREREpDsp2HwZEfE4vbUANKgrmoiIiIhIt1Gw+TIi4nF4gsFGa2xERERERLqNgs2XERGPzVODzdBUNBERERGR7qRg82VExGM01xLtcqh5gIiIiIhIN1Kw+TIiE6C5hmi3g0atsRERERER6TYKNl9GRDy01BLr0hobEREREZHupGDzZUTEA5AV7ae8rqWbByMiIiIi8vWlYPNlBIPNkDg/+ZWN3TwYEREREZGvLwWbLyMYbAbE+CipbabZq+loIiIiIiLdQcHmywgGmz6RHgAKq5q6czQiIiIiIl9bCjZfRkQCAL3cVrAp0HQ0EREREZFuoWDzZQQrNqlOK9BonY2IiIiISPdQsPkygsEm1mwgwmlTsBERERER6SYKNl+GKwYMG0ZLLX2TohRsRERERES6iYLNl2GzgTsOmmvITIikpKa5u0ckIiIiIvK1pGDzZUUlQWMFSVEuqho93T0aEREREZGvJQWbLys6FerLSIx2UdWgYCMiIiIi0h0UbL6s6FRo2EtilJMGj58WnzbpFBERERE53hRsvqyYNGiwKjYA1Y3ebh6QiIiIiMjXj4LNlxWdCo2VJEdYL2WlpqOJiIiIiBx3CjZfVnQqYJLqaADQOhsRERERkW6gYPNlxaQBkGzWAFCpzmgiIiIiIsedgs2XFW0FmwSzClDFRkRERESkOyjYfFnRqQDE+CoBqFLzABERERGR407B5suKsYKNo6mC2AiHmgeIiIiIiHQDBZsvyx0Hdre1SWeUiyqtsREREREROe4UbL4swwhu0llOYrRLFRsRERERkW6gYHMsxGZAbTFJUU5t0CkiIiIi0g0UbI6FxH5QvZteCZHsrmjANM3uHpGIiIiIyNeKgs2xkNgfqgsYkxFNbbOPgsqm7h6RiIiIiMjXioLNsZDQD0w/ExIaAdhQVNPNAxIRERER+XpRsDkWEvsDMNBRjtNuKNiIiIiIiBxnCjbHQmI/AFx1BQxNj2Wjgo2IiIiIyHGlYHMsxGWBYYeqPCb2TWRpbgUPfba9u0clIiIiIvK1oWBzLNgdEJ8FVbv5+RlDOWVYGn/7aBvldS1H9XBef4ClOyva7K525WNLuW9ezpcdsYiIiIjIV0qXBRvDMPoYhjHfMIzNhmFsMgzj1q46V1hIGggVO0iIcnHzyYMAWLW76qge6s01RXzz8WW8tKLggOMNLT6W76rk/fV7yM6rZNH2vYfct77Fx18+3EJ9i++ozt2Wsrpm9tYfXUgTERERETkeurJi4wN+bprmSGA6cIthGCO78HzdK2MMlG0Gn4fRveNw2W2s2l3Z4d1qmrxUNXgOOLZ4hxVY/vT+ZrbsqQ0dzympxTQhr6KRm55bxQ9fWk2z13/AfT/eXMKjn+fy6ZZS5m8to6HFh9cfIBAwCQTMo9pj5+x/LmTynz7BH9D+PCIiIiISnros2Jimucc0zdXBy3XAFqB3V52v22VOAL8HyjbjdtgZkxXPqt1VBAImn28rp6bRe8hdmr1+Ln1kCafcv4BPNpfiDwaPpTsrmD4wibgIJ1c/sZw3VhfiD5hsLt4XciobPFQ3epm3qeSAx1y9uxqAV7ILuP6plby4PJ/T//45D83fwU3PZXPCvfNZk3/klaRAwKQiGLxeX10IwNaSOu6dm6ONSEVEREQkbDiOx0kMw+gPTACWt3HdTcBNAH379j0ew+kameOtP/eshczxTO6XyFOL83h++W5++/Ym7DaD1Bg3918+jrfWFOFy2CitbWZHWR1nxOWz9cXnSIgoZGxUJe97qqgzTsLxzTu55c187n/lE4pKx1HUaCchyokBxNJEjNvGs0t3c9qIdFbsqqRvchSrg6Fl8Y4KAN7fsIe8ikbeWVfMjrJ6AK5/eiWf/OwkUmLcHT6twqp9m40+vTiPyyf34aUV+Ty9JI9LJvRmSHpsm/czTRPDMACoafRSXt/M4LS2bysiIiIi8mUZXf1bd8MwYoDPgT+bpvnG4W47efJkMzs7u0vH02VME+7tB6MuhvP/xZr8Ki5+eAlOu0HvhEjOG5vJm2uKqG1q4RLfh5xhX0WWUU6Gox63v4GA4WCzP4sKdxaVzSYXRqzB5msBc99Us1qisRsGNncU7pYqDNPHhkB/Fjpn8feGM8kyyplg7KDSlsQOXxrFpBwyzDvPHcG9c3M4b2wmP5wzmI83lzJ9YDK/eHUdz313KrnlDUzpn4TLYRXzPtlcyg3PZjNtQBKr86vY/Iez+OZjy8jeXcWfLhrNNdP7tflyfPOxZYzMjOOu80ZyzRPLWZFXydu3zGJEr7iuef1FRERE5GvBMIxVpmlOPvh4l1ZsDMNwAq8DL3QUano8w4Be46FwFQAT+iZy4tBUvthWzjXT+3HD7IFMc+7AO/+vzHGuJZA2ElJPwBaTBumjMEZewF1PbmRNfjXXzujHxSfGwqqnwBVNrT2RZz5bS1xLCWP7JDEh3QHRKQSc0TgXv8Ut3uf5TtwHRHr2W9PjgNXmUJb7h1FsJtOEm63048qpZ1Jc3cyzS/OoafLyWU4Z/ZOjyKto5BevrmPxjgp+cPIgbjtrOABbS+sAOG9cJst3VbKjrJ7NwXU/K3ZVcsWUPszPKePEoansLK+nutHL6Mx4VuRV0ujxsam4hkU79mIY8NOX1/LhrbNDlZzDWbJzLyU1zVwyMeuo3xLTNGnxBYhw2o/6MURERESkZ+iyYGNYn17/C2wxTfPvXXWesDLkdPjoTti7HVKGcMfZw7EZcNnYZPjgNmaveBSvM5Lymb8n9dRbrTAUZAD3fWMcn2wp5cbZA8FmwGl3AxAH3DTNT0W9h/S4COs6rAVSGVN+Sv6yp+lb+ilV6TN4qbw/l42K5u0PPuBiYwGjGz7AZezXYODfD3Nr3BDG25thJ0xwpDOidjc1zhhW7BpOb0bzxCIbMREOLp2YxfbSOjLjI5jcLxGAuRtLaPT4iXTaWb6rgt++vZGXVhQwLD02FIJOHpaKP2CSu7eBZ5fsJtpl5wenDOa+eVvZtbeBgakx7b6Ezy3bTa+4CH7y8lrqW3z4/CYzByeTlRjV6bfjjdVF3P3uJhb9ag7xkU7AaqX9vedWccPsAcwcZFW0CiobCZgm/ZKjO30OEREREQkPXTYVzTCME4CFwAYgEDz8a9M0P2jvPj16KhpAXQn8fQTM/jnMudM6tnspvHET1OTDtJut4+72P9gfS2V1zUz788fcMiWeXlEBxntWM8q3BbNsE8Wle3GaLaQYNewI9KaXq5FYn1XxKTB6UemPpLjXaTzceBpTo4r51QWTGPHvQnrFR1BY1cR1M/vz9JI8AKb0T2RlXhXnjulFYXUT6wqqQ2NIinYxpX8ivzprOHPu/5zfnDOCvslRnDEynWZvgEjXvmpKcXUTs/86n+EZsWzZU0trE7YYt4PsO09rt/KyrbSOlBg3Hl8AE5Ne8ZEA/OCFVXywoYSnrp/CKcPSAFhfWM0FDy3mkgm9+fsV4wEYe/c8apt9bP3TWbgdqu6IiIiIhLPjPhXNNM1FWIWIr4/YDBh4Cix/FFrqoLESNr0BCX3hug+g/6zjOpy02Aj+fPE4ThicQt/kKOBkwHpTnp+bw+vZ+XzxkylE+yLAbefxDz7mmtRcsoqX4dudx7jSxzjTfBxbnQmPw2vukSyqG8qzrou5/ezhXJawlfTNT5LUfxz16c3EVm7k3dQr+HFBemgMlQ0exmYlMCAlmrRYN/fMzcEfMLn97OH8bd5WTh6WSnF1M3eeN4LPt5XjD5hsCnZ/+/0Fo6hv8XHfvK2s2l3FrMGHrhkyTZMz/vEFAKmxbnz+AK/dPJOBKdGs2GU1Uli9uyoUbFYH9xZaEtwA1TAMaputPX9eyS7kW+2sGTJNk4cX7OSs0RkMOkzFSURERES6x3Hpiva1cvZfYd4dkP0UOCJg0vVWlSYyoVuGc9W0tjvN/fz0odx88iAiIpyhHtw3Xnpu8NKPKNhWzu1PPcPJrs1cf/ZsIhqKiVv2Dj8y3+J7rgW4nn6QUcWrISoFli8hzu4CdyznFd/BOFccmbZKPvOP56feHzAuKwGjsYKrexXx4jYbtURx79wc3A4bC7aW4wuYvLuumHmbSsmMj6C4phmAGYOS6Z0QyT8+3saiHXvbDDb5lY2hy3XNXqJdDi58aDGnjUgLbSqanbevvfWaYDWppLaZXXsbyEqMwjCs3g9PL97VbrAprW3hvnlbKahsZFBqDMMyYjlxaGon3gkRERER6UoKNsdaymC4+tXuHkWHHHYbcfb2tzGaOSiZ3yZNom7MeURMsxoJRE36Gdu2L2Zo/qtQUwCzfmJNu3NGgc0G9eUYL15BQbFJScoJnFb+JovdPyb2syFQtolb/R5ujQCv4eQhzwVEjb+MGy86i2ufWsl76/dQ1+zjjxeO4u53N+Oy2xiUGoPdZjCxbyKLd+wlEDDZWFzDmN7xVDZ4SIp2sb6wBoDvnzSIE4emkB4Xwd/mbeWttcUAnDA4hVW7q/D6AzjtNlbnVzE8I5ackjqW7KzgxCE2TBP6JUexs7yBmkYv8VHWehzTNFmdX8X4PonkVTQAMHdTCTVNXk4ZltapYHPjs9mcN7YXF47/6m7lJCIiItKdFGykTQ67jU9/fnJrnwIAesVH0mvyaTD5tLbvFJOKcdNnDKxuIj7SyS/+OYkzvZ9yVhQw5QboPxvqimnOmc9Pd74OG16HykmclvxzFu2wHuLUTB+VqWvw2yOxt0yDyERmD0nh759s4wcvrGbuphJmDU5myc4KZg5KJjXGjcth42enDw21qH746ok8+kUu2XlVXDqxN4t27OXzreXYbFBQ2cRvzhnBU4t38cW2cgamWA0DzhnTi0cW7ORfn26ntLaZB785gReW7+autzcxfWASp42wptdVBzda3RZslHCwZq+fjzeXcuaojNB4Khs8fLy5lGiXXcFGREREpIso2Ei77LajWyKVmWAt3j/htItotl0MEw78MB875QYo3wq5C2Dh37m67PtkOQdR5cok84XPudVjbSTKX/8IA07iupPu5r3VTuZuKmFAooPFOyqY1C+RNfnVNHr8jMqMC4UIAMMw+P5Jg+Akqwta74RIfvv2RkrrWhiVGcc3JmWRV9HAm2uKmB2supwz2go2Ty7eBcBlk7P416c76JMUybLcSraX1mO3GfiDHQ0Kq6wmCSvzKhnRKy40Te7hBTt54NPtnDg0lSeunYzLYQuFoOLq5qN6PUVERESkYwo20mUunXSYPWhSh1lfQ8/CfPMWeuflMce/DtLHwfn/Ak8j5M6HZf8h9qmT+NAeQUnqEDLrNlDXbwrRQ05kdf9+XPd5FNfal8L2Zqvd9kGcdhs3nTiQ372ziZOGpvLw1ROJdjuYMzyNF5bn8/qqQmwGDMuIZUBKNLv2WlPOfvLyWqobvbx+8wy+//xqyutaGJQazTen9qWq0cO/5+/kqseX0eDxYzPgue9OY1K/RJ5ftpuMuAi+2FbOgq1lnDEqg+3BYFNU3dTmS2GaJrXNvlBL6o7UNHnZtbeBcVnxR7QnkIiIiMjXgYKNdK/Efri+8x6LvsjF6B/J8D4Z+/b36TcDJl0H2z/CVphNZv4ymHIDsfnLYfE/mWz6WR/pwFbugxcehOTB0G8WjLsSilZBSz1M+jbXTO/HwNRopg9MxhlcVzRzUApuh421BdX0io/A5bAxvk8ChVWNTO6XxNLcCq6c0odJ/ZKYNiCJ99bvYUBKNDfMHkhueT3/nr+TBo+fX5wxlLfXFvODF1Zz0tBUKhs8PH39FG54Jps1BdWU17ewNLcCsBoW+PwBHAetbXprbRG/en0DH/z4BPokRfHMkjyumNK33aDz8PwdPPpFLtMHJvHCDdOPurIGEAiY2L7E/UVERETChYKNhIUbTxzY9hVxmVa4mXTdgce9TVC4EtuG16DvdGgoh4IVsOZ5WP1M8EYGLP4X9vP/xewBJ8L7t8LEb0PAR2TGGH54ymDu/3gb9cF2zz87fSjfmJSFy2Hjoc92cMc5IwCYPjCZ99bvoX9wA8++SVG4HDZ8/gCXT+nDheN7883Hl/HOumKun9Wfk4amMqJXHC+tyA+tyQHwB0yKqpvomxTFk4vzyC2v588Xj2Hh9r14fAHunbuVMb3j+fvH23DabVw/awDXPbWCM0dlcOaoDGwGJES52FFmTdVbllvJ2oJqJvVLxOML8NTiXVw5pW+o+UFHluzcy1WPL+eDH89mZGYcAIt37KVfctRRbYgqIiIi0p0UbKRnckbCgBOtr/2V5UDFdsiaYoWft38Ib94EEfHQXAOrn7Vu12caP7z4Uby+QQxIs/al6ZMURZ8k6wP9M9+ZGnrImYOSARiaHgtYjRVGZcYRF+EkLTYCgDdunsnG4hpOGZaGYRhM6JvAhqKaQ4Z9+j++YFBqDDvL6vH4A9x88iDW5Ffjctj4eHMpH28uBWBZbgUXjMtkwdZySmqaeWZJHkVVTdx32TiKqpuY3C+R1flVfLhhD+V1LdQ2e/nLhznERTr55tR9Lb7fWF1ItNtBfkUj2bsrefRbk/H4AmTnVfKH9zYDsDKvkpGZcWwsquHqJ5Yzc1AyL944/cu+QyIiIiLHlYKNfLWkDbe+Wl37Nix5wKriXPAQlOdYxxfcg/HAeH6WNQWG3Q15eeBpgP4ngCsaGvZC3R5IH83A1BjeumUWI3vFhR72v9+egsO+bwpXWlwEc+IiQt+P75PAs0t3c+aodEpqWzh3TAb/90EOHl+ALXtqiXLZ8fjhuWW72bW3gV+eOYyEKCcrdlVS0+Rl+a7K0EalOSXWGp0ol517PtxCRYOHS4INGZ5YtIsnFu0KNU/ILa8PjWFbaR23vbaewWkxRLnsrC2optnr5+WVBfzunU2h21U0eDBNk7ve3ghAg8f/5d8HERERkeNMwUa+2uwOmP0z6wuAC6w/hp9nNSdYeD88fe6+2zsiID4LKoL9p0d/A878P8b3SbfW7DTUQFwmSdGuw5525qAUMuMj+N5Jg5jYN5Fmr5//+8AKVY9fO5mUGBd3v7uZpxblATC5XyLTBiZz9bR+vLG6kAVby3lzTVHo8WLcDq6Z3o//fL4TgN6JkaTFRZC9u4ohaTFsD05Pyy23mh9s2VPLT19eiy9gsq20DpfDRsCEneX1LN9lrfk5bUQ6C7eXU1jZSEltM2vyqwFoaPG1+7y0JkdERETClYKNfD2lj7S+JnzLCjgYEBEHW+dC9W4Yf7U1lW3h/bD5bWsqW+Ne675DzoTz/g6NFRCTAbHpUJkLRath9KVgGGTER7DkjlNDp4tw2kOXTx9p7Ynzk9OG8PNX1uH1BxiblRC6fkZw6tt764vJiItgSHoMY3rHM77Pvtv0TojipGGpDE2PZfaQFD7dUsZba4vYUVZPs9fPNx9fhs0wuGZ6X55flk+zNwDA1pI6svOquHB8Jv+6cgKXP7o02LramjY3sW8CW0vqME3zkI5r8zaV8PNX1vHpz08ifb/q1LbSOjLiI4iLOLK1PYGAySOf7+S8sb3oF1y3JCIiIvJlKdjI11tEHIy8cN/3A08+8PpxV8Ka56CxEhL6grfRCjv/GGVdb3fD6Etg2zxoqoTaIug7w1rjc1AweOGGaaTHuUPfnzIsjWV3nEpDi49I177g0ys+krNHZ/DhxhJG9Irlqeut9T4FlY2h22QlRhLjdoRC0rlje7FlTy2f5ZTx4cY9VDd6eeGGaQxOi+H5Zfmh+32aU0ZZXQuT+yWGHmfZzgrWFVbjsBmcOiKd1fnVLMutJCHKyYbCGtYUVPOXS8bw/LLd1Lf4+GhzKd+a3g+A+hYfZ/zjC5x2g5W/OY2EqEMrWUt27uXRz3P55xXjSYx2sXxXJffN20p9i49fnTX8kNsfa9l5lYzNSjhgryMRERH56lGwETmc5EFw2t0HHus3y6rQxKRZFZ7tH0FsBqSNhI9/a91m4CmQMRr6TIfl/4GMscw68RcQFXvAQ7kcNlyOQ8PAj08dwocbSxjdOz50rDXM1Lf46J0Yech9BqZG4w+YPPDpDjLiIpg+MBm7zSA9zk1Vo5c+iZG8v34PAJP6JQUfM4qS2iJW5VUxvFdsqPPbd55eSWKUk4Bptam+ampfFu+wKlYfB4NNdl4ldcFpa16/yV/nbeX/Lh5zwJjK61r48Utr2Fvv4dmlu7n1tCG8vroQgI1tNFc41goqG/nGf5byl0vGHNBUodVTi3fx7rpi3vjBrC4fi4iIiHQtBRuRzhp8KhCcZrZ/tae5BrZ/bFVtFv0T8hbBkgfBHQ+7l8DWD2DqjVbYyZp02FOM6BXHa9+fwZD0fUHIMAyGZ8SysbiG5DbW+AxMtbq77drbwM0nDwrtbzNrcApltS047AY7yxsY0zueYRnW42YlRhIwYUVeJVdP60uvBGuKWZPXT1PNviYCv3h1HQHTmka3YGsZi3fs5eonlpMe58ZmWOf4bEsZ5kXWFDbTNIMhazu1TT7GZsXzzNI8rpnelw82WOFqc3Ftm1PejqWtwcYLOXtq27x+xa5KVudX09DiI9qtfw5FRER6Mv1PLnKsRMTDmG9Yl2fdagWdTW/CkDOgpgheugLm/RpsTjjjjxDwQ/EaSOwHJ/wU3AdWcyb3TzrkFOeN7UXf5Kg2w8CQtBgGpEQzqV8it546JHT83kvHYppWW+eUGDd3nTcyFHr67LdfzcnD0uidsK8SFOt24HbaAIOtpXWcNiKdm08exMebS7nttfUAlNa2MCozjvPHZnLb6+vJKakjIcrJrf9bS1FVExUNLVw0IZNLJmZx5WPL+NFLa2j0+Dl/XCbvrivmzrc2MmtwCueM6dXpl3vR9r3ERDgY3yeBnJJacvbUcVGwW1yr3L1WU4XW5goHK6xqAmB3RWNoLx8RERHpmRRsRLpKRPy+jUXjMuEnG6GhDN74Hsy93Toe3xc2vQEbX4c5d1nreCpzod9MiE6D9S9b7aeHngXuGK6bNaDd00W7Hcz/xcmHHHfarbUlswanMGtwygHXDc+IpXdCJNfP6s/pI9PxB0wcNgOn3cbrP5gZ3Pgzj9dXF/Kz04cyolcsozLj2FRcS1yEg9pmH1P6J3HSsFQA5m8tY0FOOZuKa3A5bDR7A9wweyBD0mIYnBbDkp0V9EuO4tsz+vHuumJeWJ7PC8vz+eNFo4l22cktb+DGEwcSH3loI4JNxTUMTY/ld+9s4pzRvfjV6+tJi3Pz5g9m8eBnO3h//R7S4yKYMSgZ07Q2Q91ZZnWJ21FWz/Zgk4PY/ZocFFZZ65byKxs6FWy2ltSxqbiGSyZmHfF9REREpGsp2IgcL64ocPWH6z+02kkbNkgZbE1Te/cn8Pp3D7y9zQkBr3U5eQhc/QokDoDSjVBXAv1ngzPi4LN0SmK0i8W3zwl9b7cZZCZE0jcpKrQh6S/OHMp5Y3uFPvh/e2Z/bnttPbedNZz1hdV8Y1IW6XERTOibwGNf5FLd6OWu80Zy2og0tpXWhx7nqql9+cN7m7l0YtYBIeK0EWnc9dbG0PefbCnlw1tnH1CV2lxcy7kPLGJ8nwTWFlRTUtNMUXUTpbXNNHn8rC+sBuA3b21g3k9O5M43N/JydgGxEdY/cWV1LZz74CLOHJXBg9+cAFiND6oardc3r2JfY4Yjcd+8rXyWU8qZozK6ZApbZYOHCKeNKJf+iRYRETlS+l9T5Hiz2SB16L7v+82Em5dAwXJoqbWqO7mfW9WdwaeDrwXeuAEenAxRydZxAHccjLwATvwlJPY/ZsP7xxXjSYjaV9XoFR9Jr/h9U9QumdAbp93g3DGZXBPsjgZw9/mjuPjhxUS77Fw2OYu4COcB7Zwvn9KHPTVNXDO9H1EuB09fP4URveJIinbx27c3YpowOC2GP72/hZySOpq8fib2tbq3vb3W2tNnbUE1AF9sKwfAFzD5LKeMgsomRveOY2NRLbe9tp431xThtBvUNfvIiIugpLYZjy/A++uL+fnpQ+mfEk1RcBoaWFPR2nPHGxs4dXgapwU70DV7/SzesZeACesKqpl5UBXsWLjq8WVkxEfwdLAjXmf87u2NOO027jxvZKfu99e5OdhtBj8/Y1inzykiIhIOFGxEwoHdAf3368zVa9yB139/Max8HOrLoe80iOsNm96CDa/DmuetKW2zfwbDzwW/B/KXQe+JkDSw00OZFGwF3R6H3cbFEw6dgjWuTwJ/v3w8dpvR5p42MW4Hvzl334ftk4elhS7/5ZKxgNXF7E/vb+HbT66grK6Fa2f049fnjODddcVMHZCE22HD6w+wLLcydN//LsoF4KenDeXmF1bz5poiRmXGMW1AMk8u3sUZo9J5duluRmXGsb2snscW5nLdzP58tKkEALfDxqbiGp5YmEtJTTO/PGsYbofVfruywcNLK/KpafKEgs2y3AqavFZjhVW7q5g5OIXc8np+9fp6Th+ZznUzBxxRa2l/wMRuM6ht9nL76+u5/awR9E2OwuMLsK20jpySOlbtrurw/difaZq8t34PLkfng80764pxOWwKNiIi0mMp2Ij0BAl94PQ/HHhsyOkw5zew9gXY8Sm89xPrq1VEPJx1r3W76GNfVWjLwYv3O6tPUhT9k6PIq2ikd0Ikzy7dzSvZBTR7A9xxzgjOH5fJp1tKWZZbSYTTRr+kaFbnVwMwbWAypwxLZd6mUq6Z3o8p/ZN4dVUBF0/oTaPHz5VT+vC/lQW8taaIz7aUUVLbDFgd6NYWVLO+0Go/PXtoKolRTj7YUMLAFKvitGWP1V3ts5xS/vTeFiKcNjLiIliVX4Vpmtz51kbW5FezMq+KXXsbQkGtPXM3lvCLV9fxxW2n8OHGPXywoYRpA5L59sz+5Fc2EjCt2/3r0+08+519VZutJXUUVjUyY1AyD362g5tPHnRAiCyva6GiwQNARX0LyTFujkSz109RdRNOmy0UuERERHoaBRuRniwu05qKNvsXkDsf9u4Am92amvbhbfDW961NRDPHQ3QqzPwR9J0OFTth7Ysw4xaIOrT7Wnc6cWgqu5ft5pnvTKW4uok31xRx0tBUzhtrdU5r3dtnaHosvzlnBDc9t4pBqdHEuB1cN3MANU1eLhiXSbTbwfrfnYFhGEwITmmz2QxeW1VIo2dfK+vTR6aztqCaf14xnp+/uo6nF+/i823lBEyrygSQV9FAfYuPX7+xEYfd4N5Lx7Ist4L31+/h/Q17WLKzgj9eOIo9Nc08vGAnr68u4o8XjuKKKX1Zk1+Fy2FjVOa+PYk+2VJKfYuPFbsqeGdtMbBvOtyuvVbDg9ZNWlfnVzGxbyLPLdsdWot04+wBPL5wF30So7hq2r79eTbt19Z6U3EtJw5NPaLXfHdFI6YJHn+A0tpmMhMO3SfpWHhxeT6T+iWG2o0fjdteW0ezN8ADwbVS+2v2+olw2g84tqemiWi3o80qooiIfLVoK26RrwLDgEFzYNpNMOW71l47P1gON34G46+yGhHkL4Unz4SHZ8JjJ8PCv8FT58AbN1lT11oFAt32NAB+ctpQXr5pBoPTYjhxaCr/uGI8F03oHWomkBbrJisxkrFZ8UwbmMyqO0/jpZumAzBjUDL/u2lGaEH/wW2xJ/RJYHyfBE4ZlsrIXnH0TYrixtkDWXz7HC6a0JvRmXHM31qOw2ZjSv9E6oMbkJomvLBsNyW1zfzyzGFcOL43Z43uRW2zj1++up5+yVFcNa0fPz9jGH+4cBQjMmL50/tbKKhs5LqnVnLNE8upDFZSwNo/B+DddXtYkWdd3l1hBZpdwRbVvz1/JEnRLv71yXZafH4e/HQ7o4JNF55ZuhuAhdvLD3h+Ww4KNvUtPkpqmkPH8isamfCHj/h4c+kB98st39cOu631RjvL6xn127msC65xao/PH6CstrnN6xpafPz6zQ08vGAHzV4/gdayVCeYpsknW8pYsrPikOs2Fdcw5u55B7wGAN98bBl/fm9Lp8/VFXaU1XH2vxa2+xrJ0cktr8c0O//zJPJV9vbaItbkV3X3MI47VWxEvqrsDug9yfoC8DTAqmdg+zyrecGgOfD5X2HbXFj/itWlzRkJ3iboNRZOvsNar1O5CwadAumjrQBlmlC2BdJGWN8fY0nRLqYOaL+KZBgGb9w8MxReHHbbEf9DZhgGL39vOrbguAOmicthC+3fM6V/EusKazhleCqnjkhnZV5VqCnBXz7MIdJp5/TgWpsTh6QwdUASK3ZV8r0T922Ieu2M/swclMyZ/1zIJY8soabJi91mcMFDixiQEs2Y3vHkV1rh4f0Ne7DbDEZkxpIXCjYNJEe76BUfyY2zB3Lv3Bx+/cZGyupauP/ycfw52FwBYPGOvfgDJl5/gGueWE727iriI53ERjh4ccVuHlmwAxNY+ZvTiHDaWZlXSVWjlxufzSb7ztNICU5Vyw1WiQCeXZpHdl4lP9pvL6S5G0to8PiZt6mE/60s4MopfRjXJ+GQ1/cP723mpRX5PHDlBM4+aG+iHcG9hJbsrOCKx5bR7PHz1PVTOlUdKqxqCgXE2mYvDS0+Vu+u5tyxvViTX43Xb7JkZwUjelkBsKbJS15FY9hsvrpo+1627KllwbZyLp/cp7uH0yXaqpp1pTX5VVz88BLuvXQMV0zp2/EdRL4GWnx+bnttPdMHJvPMdzrfhKYnU8VG5OvCFQ0zfgDXvg2XPQ0Tr4WfboSfboJTfm1tKjrxWus29WXw4uXw8jXw8V3wnxPggQmw4TV462Z4ZAYs+Eu3PZW0uIij/rDqdthx2m047bZQk4BW0wcmA3DR+N6cMTKdKJedi8bvWzd02eSsUAtmwzD4w4Wj+ObUPlw66cC1RYPTYrnnkjFUNXiYPjCJv146loGpMZTVtvDwgp0AzB5irXs6b2wvZg1KoaCyCZ8/wM7yBgYE1/ZcO6MfiVFOXl9dyCnDUjlhcAonBaeXTR+YRG2zj3WF1Tz2RS7Zu63fzM0YmMyMgcmU1rYwOC2GumYfTy3O44ZnstlQVBMcO9z11kYueGgRj32xk53l9aTEuLHbDD7cWML9H29jfk4ZD3y6HY8vwPwcqxPfc0t389KKfH7x6rpgE4cKVgYrTkXVTby0Ih+7zeDH/1tDRX0LPn+Ad9YVU9XgCW2SWl7XwrqCaraV1XHTc9mYpskrKwu45YXV+Duo4qzdr2K0q7yB+z/axi0vrmZdQXUoOK0rqGZrSR1NHj87yqwAuLO8vlMVoj+8u/mQqtaRuuGZldz/0dY2r2sNkK0Vu1ZNHj9vry064PkBbCyq4ddvbsDnP3wVdVtpHfntdPYrqm7i5Pvmh96nY23B1jJ+9NIa/AGTO95Yz/C75oZe9+PhlexCAB5fuOuYVm2Kq5tCbeQ7q7LBw+rj8Jvy8rqWdt/346Vpv2m9HTFNs8O/49l5laHpuOFk0fa9B1Tdw926ghpafAFW51cdVXW8JwuPX2OJSPdxx8JJtx14bM5dVkMCTMicYF1e/K99e+2kj4bP74XaIjjhZ5A86LgPuyucOiKNF26YxsxByRiGwRe3nUJCpNW2OmCanBGs1rQanhHXbqOAyyb3YVK/RBKiXCRFu7h0UhamafLfRbtYvquS754wgFW7q7j55EGs3l2Nxx9g8G8+tO47yeo6F+128KeLxrAyr5I7zhmOYRicPy6TuZtKuPuCUVzw0GIe/yKXz3LKOHdML247axgxbgcJUS7+eNFoAMb9/iPunZsDQKzbwbD0WE4cmsLjC3cBsL6whtgIB6Mz41mau2+K13efWUnAtELB6vwqIp126lp8OGwG28vq+f5zq/h8Wzm+gMmNswfgC/7n+ffLx/ODF1azeGcFW/bU8siCnSREORmblRAq+EW57PzyzGH8/t3N/PrNjby0Ih+A62f1JyXGzS0vrubhqyfisFtNGh76bAf5lY0s3rE3NL4te2qZu9HqbPfQfGt6G8BnOWW8s66YXvERnDrC6rzX7A1QVN1En6SoNt+rkppmbn9jPb89bySNHj9PLt7Fm2sK+fTnJ5MY5cTrN2n2+Q9Yp7OjrJ5bXljNY9dOCrU1z69o5JMtZSzfVcktpww+pHLR+oFt+a59r3Oz18+5Dy4kt7wBmwG3nDKYm08eRJTLwZtrinhxeT7TBiRx4fi2G3M8sTCXP72/haHpMXz005MOuM40rXboeRWN/PLVdcz9yYlEOO2sLagmPc59QBv3zmj0+DBN6+fz2aW7+SynjN4Jkby0ogCAjUW1DE47snVUBZWN3DdvK3+8cDTxUZ1bB9Xs9fPeumLSYt3sKKtn7saSQyqFH27Yw46y+gMqkK1qm73trr3669wcPtpcyrJfn9rh+qz5OWUkx7gYm5UAwAOfbufFFflsvPvMI+qQeLDKBg+vZhdw4+yB2A7TyOOONzZQUNnIvJ+eeMSPnVNSSyBApzYkbs9nOaV8/7nVvH7zTMZkxbd5m03FNXh8ASb0TeTllQXc8eYG/nXlBC4Yl3nIbU3T5MZns5kxKJmHr5502HN7fIGjem2PRk5JLdf8dzkAb98yq81qdbhZHvy3vK7Zx/ay+tC6xoXby/nfigIe+OaEI2oSEwiYmNCjGsoo2IjIoRxuGH7Ovu8nfgvGfAMKVlgd2mIzYd6vYd1LsO5lGHURjL4U/F4oz4GGvWD6IWMMDD4NqvKg70xrD58wZhgGs/bbl6Z1qtbpBwWaIzUwNeaQx79h9kBumG214d5495nYbAYV9ft+E3jzyYP4xqR97bTPHduLc8fu+7A2unc8n//yFOu6Mb14c00RdpvBbWcNO2DfILvN+lA9bWByaN+fuhYfQ9Jj+OGcIWwqruWyyVl8sW0ve2qa+M4JA0LBZsbAZJbmVjBjYDJvB5sb3HzyIP7+8TYunZhFUoyLRz/fydD0WAalxfD0kjyiXA7OGJnBmaMyiItw8OjnO9lUXMu5Y3qxcHs5X2wrZ1h6LDabwYyByVw1rS//+XwnL63IZ9bgZFbuqmLephJSY91sKrb2I1qZV8nvzh/FPz7ZRoTTRrM3wOC0GHbtbeDxhbnUt/iYPjCJjzeXEuN2YBjWxquxEQ5afAGeX5Yfej12lNdT2eBhQ1ENl03OClXrAgGTX762joXb9zKhzx4qGlpw2W3UNvuY+MePGdM7nhafn4LKJm45ZRBjsxJ4cXk+Xn+AraV1fLGtnG/NsF73ecEW4nXNPh7/IpezRmcwJH3fB/zc8gbsNoOCyiaKq5vYXlbPstwKcssbuP+ycSzasZcHP9vBmvxqnr9hGjkl1nqh/3yeywXjMjEMg4YWX6hauaGwhj9/YK0f2lZaT5PHT6TLel5vrSnivnlbyUyIINJpJ6+ikTvf2si9l47lW/9dzklDU3noqomh2y7asZe/Xjr2sB+kwfrwee1/VxDpsvP4tZNZstMKm/9dlEtytIuKBs9h94U62JtrinhnXTHRbnuH3QQP9vD8HdS1+Hj4mon85YMcfvHqOgakRjM8Iy401r99tJX8ykamD0rmww0l3HXeCAzDoKCykTn3L+CJb09h5a5KzhyVccCH8+1l9TR6/Ly5uohvz+zf7hh8/gA//t8aBqRE884PTwCsyqLHF2B3RcMB7/+ReiW7gHs+zGHW4JRQs5SD+QMmy3MraPb58fkDOOwd/9tqmibff24VHl+Ahb+ag91m8FlOKe+sLebeb4w9pILdkbfXFuPxB/jzB5t56cbph6xpBPjFq+spr2th6R1z+HhzKaYJP/nfGqYPSCIt7sANpnP3NlDV6CW3/PAVmz01TZx83wKeun4KMwd1XcfPQMBkY3ENW0v2VSA/2LAnLIPNwT8Dy3dVkhTtorLBQ/buylCweXNNEe9v2MOVU/swe0jbzWVeW1XIwNRoJvZN5A/vbWZtQTVv3TKrzduGIwUbETkyzkgYuN9vhM/7O5z0K6sJwYZXra9W7uB/xiuf2Hes9ySrOjTpOhh6Fhh2K/w4u6YDV0/Q+iGyderZ8IxYfnXW8CO+/zXT+/LmmiIuntD7gFCzv/PG9mJDYTUZ8ZFs2VPL0PRY4iOdvHij1XBh/z2J3vvRCVQ3ekmLc7Mst4JvTe/HzvJ6XHY7qbFuNhfX8t3ZAxiaHsuVU/qQFO1iT00z76/fQ02Tl0sn9cZuM5g5KIW5m0ronRDJ3y4bx71zc3h6SR5D0mN44MoJoed+3zfGsa20jutnDeC7z6xk7qYShgZ/0788OF3rmaV5ADxy9SSavH76JkXxnadXsrO8gcz4CP522Thm/3U+9S0+Zg1OZvGOCr49oz/eQIBHP8+lT1IkBZVN7Cyr598bS8jeXcXTS/J4/rvTyIiP4O11RSzcvheXw8b8rWXkltdz1ugMzhiVzubiWl7JLsAfMJk1OJm/fbTtkNe3tU24aZq8v2EPwzNiqW70cv/H2/jHJ9v49TkjuGH2QJo8Vkvtc8f04v0Ne3jws+2hCsfMQclcOimLSydlkRbrDoW2LXvqSIhysmVPLWsLqmny+rnuyZXcd9lY5gxP4/Y31pMS4+Y354zgJy+vZX1hNdMGJpNf0chv3txAQ/Cc54/LZGBKNP/6dDuZCZHUNftYllsZmrr1wKfbyd3bwPRgy/SkaNcBH1L9AZM/vb+Z1burGJASTfZuq9Pfwu17afYGsNsMvH6Tc8b04pMtpeRXNmKa5iEfdFftrsTnN5k6IImAaf0WuHV6z1trivn2zP6hUHKw+Tll5Fc2hkLG4h17eWj+Di6dmMXsIakMvT6W0+7/nKcX53HPpVZA2lpax87gh+SfvryWwqomrp7el0GpMWTvrsTrN3lnbTGvry5kR1k9//nWpNB72Vpde27Zbkb3juefn2zj4asnEntQ9WZdYQ11zT7WF9Zw/0dbiXDaQw0stpfVtxtsPt1SSt+kqDavb13wva20rt1gs7Wkjrpgc5M9Nc1tViNbfH6+8chSfjRnMGeMymB1fjV5wdC5aMdeYtx2vv/cajz+AJdMzCIjPoJ1BdWcNzYzFJDb4/EF+CynjJQYF8tyK/l0S1lor69WJTXNodfi0y1lbNlTS6/4CPbUNLOxuIY5BwWbNcHW/XkVDW3+/LTaWFRLiy/Ail2VzByUwrbSOgKmyXvr9jAgJZrpg5LZW9fCuD4JZOdVctvr660P6ReOCk0l3l91o4cPN5aQmRAZmuoL8NSSPP743mbG9I4n0mmnX3IUW0uPzTTLouomGlp8DD3o/T+aStTHm0v54Yuree9HJzAkPZbCqkZW5lXyzal9eW99MctyK7l6mrWZ9qYi6/14Y3XRAcGmqLqJ9Fg3C3fs5RevrmP2kBSeuX4q760vZm+9h2eW5IV++ZEY7fqSz75rKdiIyNGLTYdz7oMz/w/yFlqtpbMmWxUfgJ3zrSqPKxqyn4SGcnj1ugMfI2uKtd9O1uGnHnyVZSZE8sS1k5k6sHOttyf2TeTBb07ghMHt/9by8sl9uGRCbx5esDMYbGLave3+H6Ja/8Pdf0pR6wc/IBSkYiOcTO6XyO7KRk4M/kd54tBU5m6yfjse6bJz1bS+PL0kj+EZsQdUBE4cmhpqSX3e2Ex+8eo6iqqaGJsVz8aiGmIjnKHf3o7qHUdarPVBqPU//vsuG0dWYhQzBiazZGcFV03tx7ljMrlwfCZ7app59PNcpvZPpqGljJV5lazOr+LU4Wks31XJpY8s4Y5zhvO3edsY3TuOqf2tDV0Brpnej6kDkjhvbCY/OGUwfr9JXKSD55bt5pMtZVwyoTcvrsinocUXWrf01OI81hZU8/sLRjG+TwKFVU38b2U+93+0jfPGZvKfz621VWeNzmBneT0vrSjAZbdx21nDOHNURug1OWFICo9+kcvcjSVUNnj4yWlDeOizHbySXcjnW8vw+AP8e/4OnlmSx9aSOh67dhLj+1jtzJ9cvIuckjpeXlmAzWYwfWASy3IrmTYgiaum9uW1VYU89oU1jr31Leza20Bds4/cvQ1EOG384tV1gFWpfOLbk9lYVMMlE3vzzJLdPLU4j5G94ngrWMHz+AI89Nl23A4b547txRurizh9ZDpbS+tYW1DFxD9+zJ8vHsM5walhDS0+bnp2FQ67wWWT+vD2uiLm3noiu/Y2EOt24HbauOChxbz+/X3TmgIBk2eX5pFTUsdrqwrxBUwMA04YnML3n1vF4LQYfn/hKADS4yKYPTSF+VvL8PkDNPsCvLAsH5sBAdNqPAHWprot3gAbgx/wPtiwB4D5W8tC1bDS2hYaPX6m9E9kZV4V33sum731Ht5cU8S1M/of8Hdm0fZ90yMf/GzHAddtK60LPf/9rcyr5IZns4l1O3j5ezNCzS7W5Ffx+bby0FqrbaX7uhXWNHqJi3SEPuzvv2bqng9zyCmp5aUbp/O7dzaxvayeB66cQIPH+vl8YtEuBqbG8O/5O4h02olw2vjfinz8AZO4SCf1LV7+74N9TUmy86q49xuHr54t31VBXbOP+66ZyF/nbuUvH27hxKGpPPTZds4dm8mwjFg+32atzYty2XlkwQ6Ka5r58alDeODT7WzZU8ec4emYpsmy3Er+74MtbA6GoGavtTavtQr7xuoirpral5nBf+dauzhuL7XWzl3y8JJQB8tIp51Zg1NYnV/FqjtPY96mEnbtbSC3vIFxfRI4e3QGKTHW1MXMhAiiXA5uenYVK/IqiXU7+OnpQ3lvfTEPXjWRBz7dDsCGohom9E2gX1IUK/P2rZ1asasSf8Bkyc69bCyq4cnrphwSxnaU1ZMRb1VNL3hoEWeOyuDHpw7hZy+vpaCykcW3z8EwDJq9fv7w3mZezS5g3k9OPKTaD3Dv3Bz21rXw+/0CWmltM3e8sZ4WX4DFO/aSGuvm9tc3YLcZ3DB7AKZp8sLyfHadPpSkKBfby+pw2W3M3VjCny/2EeVysLGohgseWsTIzLhQtXX17irWFFSzNzib4N65OSREOomLDP+2+Qo2IvLl2Z1Wl7WDDTrF+gKY+UPw+2DLO1C1C8yA9f2qp+CJOTDifBh7pdWqurWKE/CDp97abPQr7uDfdh6J1jU3HXHYbZw3thfzt5Yxpf+x37fooasmUt/iC02FuGxyFsMyYpjUzzrX0PRYXrpxOqN6tz+v/8LxmTw8fwe5exu4flZ/ThmWxuMLc/n3/J2kxrpDoab1fIVVjaFpg5dP7sPS3ApG944LBa7BaTHcdd5IpvZPor7Fy7xNVjOAW+YM5seGwU9eXssPX1yDYcB93xgbWlszNiueKf0TQ+eK2a9JxbUz+oc+2F40oTd//2grD3y2gwv/vZh1BdWcNiKNb03vh81mMK5PAl5/gIXb9/KTl9ewLNf6IDowNZqLJ/TmLx/mcPqo9NC0xFYT+yZitxk8G6xUTR2QxMzBKaHGDNfO6MezS3fjsBk8dNUE5gy3fm6iXHbmbSpl3qZSDAOevG4KqTFufvjiak4ZnobNZnDi0FReWrHvw/6Ti3extcT6oPPCDdNYsLWchCgXjyzYwcUPL8Y0YX1hNW+uKeKcMRn8+6qJvLaqELvN4GevrGNdYQ0Xjs/k+pkD8AdMpg9M5t11xaHmCH/7aCsfbNjDqSPSKKpqCm0e+9gXuXj8AR77Ipe8igZOHJbK3eeP4uT75vPcsjz++o1xAPzq9fW8uqqQCKeNiX0TiXDZ+b8PtnDJxCxafAGeun7qAe/PyUPT+GBDCbPu/YzS2hbAqlhuK60LhYR7P8yhosFDYnA9T1NwbVaLL8DVTyzn4gm9GZJmfaj80Zwh3PX2RnZXNOK0Gzy/bDdXTukbCtaPf5HLa6sLGNM7HofdoKy2haJqK0BFOu2sya/m/fV7OGt0RmiNQnldC794dR2Z8ZG0+Pz8dW4OT10/FdM0+e3bm0JBGaz1EEt37uXuC0Zx1ePLuWhCJv938RgAPt9WTrTLToPHz/vBcHb7GxuYv7WMxCgXP3hhVShUrdhVyXkPLqTZG+B7J1o/b48vzMVhs3HVtL4UVDbyaU4ZQ9JiOGFICk8tzqNfShSFVU14fAGundEvtH6o1aLte3HZbZw0NA3DMPjec6u45onlrMirpLC6iQvH9+bJRXn0io/gmun9uG+e1VBj1qBkXl9VyJY9tRRUNnLFo0sprmnGaTcOaCzw81fW4bAbJEZZVeF5m0rIvvN04iOdoWrattI6CqoaqW/xMTYrnl7xEczbVMoX28vx+Kx1desKaxiXlYDHF+AfH2/jrrc2cvnkLF7JLuS6mf25+eRBrMir5MShqXyxrZw/vLcZgLP+8QWNXj8DU6LJ3dvAyF5x9E6M5K21xdQ1e6lt9nHdUyus1vXBYa8rrGF8nwRM06S4ppnNxbXc+Gw2TrvBmaMy2FRci2nClVP6sCKvEtOEe+bm8N66PbidttAvcbbsqSPSZecP724mp8Sq2o3OjOORYOOZz7eVc+H4TM4e04ubns2mocVPrNvBpzllPPDZDiobPPz54tFkJUbx/ZMH8dKKAk69f0FonFdM6cNzy3azfFclpwxL46HPrMCbt7eRsVnxzBqcwn3ztvLw/B0YBkS7HNS3+LjhhAE9Yq2Ngo2IHD92B4y+5MBjM26BRf+A1c/ClnetYzEZ0Guctemo3wPDz4Oz7oH4LKjeDWuetyo9Q8+0bm+a1leYr+HpTgNTY3jzB10zTzoj/sApJU67LRRqWs0YlHzYx3Dabdx13kh+9fp6Zg1OISFq32Lskb0ODETjg/sRtbpwfCaT+yeSlXjgdJzvnjAAgF+fM4IFW8uJdjsYl5VgdX+7dTZrC6pJi3UzMDWGumYvg1KjufXUIe1OgTnYmOD41hVUc+e5I7h6Wr8DKlKtY1yWW8mw9FhOHZHG8Iw4UmPdvL66kO/MGnDIY0a7HYzuHR/aM2h4Rhxnj87gi23l/HjOEL530kDqmn2cM6bXAWu/fnb6UNYUVHPzSYPw+ANMDG5KuyC4HgvgpGCwmdQvkbyKRp5flk9ClJM7zhnOpH5J+wXRGG5/fQMRThuvZBfidtj43fmjMAyDy4Jtqv82byvFNc1cMaUPY7Li+VdwimHf4JQow7DWFOWWN/DhxhICpsnsISksy63A4w/QNykqFHDOH5tJaqybc8b04oMNJfz+gtFUNXp4bbX14fN354/EMAyW7qzgi23lvLyygFmDU0Jt2kPPb5hV/atp8vKT04Ywolccp49I5+53N1FQ2cSY3vGhfaOqGr247DY8/gBD02Pw+AJsLanj7nc3cfoI63Udkh7Dr88ZwRMLrTVOd729iQl/+IgHr5pAZkIkf/5gC1EuOzecMJALx1troG56Npste2qZ3D+Jz3LK+HxbOaeNSOfC8ZmcOiKNqx5fRlltC899dyqvry7k/fV7KK9r4e21RWwoqsFpt6b19U2KYlOxVcH4/bubafL6eWlFAWN6W4H5s5wyfjxnMI9+kUuLz+qa91lOGeOy4vnNuSO5/NGlPPpFLikxbvbWt5AY5eLlm2bQNzmKsrpmnl6SR4svwPnjerGttJ5Pc8q4/ezhnDg0lYLKJv46dysuh40Ih40FW8v56Kcn0tDiI2Ca9EuOZtmuSsb1iSfSZeeMkelcMC6Td9ZZ1byPN5fy3vo9xEU4uO2s4VwwLpMXl+dTXNPE6N7xjOgVR05JHffMzaGq0cs9l4zhlOFp/OyVtUzpn8Q/P9mOL2DiC5jsqWkOhfmcPbVMG5gcCgC79jaEKm9/uHA0DpvBvE2leIKvx7qCGjYU1nDFlD4MSo3mrrc34XLYQp301uRX8Vmw4+MdZw+nsLKR3L0NzB6SwuIde/nXlRMor2vhD+9tZmRmHBnBqXMbCmt4aP4OTBNOGJJKY7By++SiXUzpn8jba4vJ3l2FzbCmFydGuXhvvRU+t5TU8vLKAlob+D36eS5xEQ7cTjcPfnMCP3ppDTkltdz97iYaW3zMGpzCgq1lvLuumIGp0fzmnBG8tKKAxxfu4pklu0mPd/PSjdP567ytoU6Or35/RugXWL3iI7njnOEs3VnBR8Hrr5/Vn5ezC1i0fS/9kqKYu6mEH88ZzA/nDMHlsFFS08x987byaU4ZUwckkRDp5KPNpXxjUs9oUa9gIyLdKyIOTvsdnPIb2LUAitZA4UooWW+tx3FGWWt1Hp4ONjs0B3+jadhg2DnWNLc966CmCKbeaAWnDOu3mpim9ThpI62qkoS1U4anseI3p4W+HxcMDqM66OBkGMYhoWZ//ZKj+ccV4/H6A6HfOEY47aH23mBNqfv05yd3arxT+ycxtX8St8wZfMDc/H3njSIhykl1o5dvTMrixuBvy9NiIw7pYLa/q6b2ocnjY2LfRKuj3sQs4iKcnDkqHYfdxj+uGH/IfQ6u/LRl1uBkXA6r+vHzM4ZR3ejhlOFphywanz0klcW3z2Hh9nK+9d8VXDO9H+kHrYeYNTiFtQXVTB9wYGDtm2y9D+eNzSQjzs2U/kk8sWgXWYmR/PmiMfzwxdWsL6rhH1eM59JHlgDQP7jG7JKJWby6qpB31xVT1ejBNK0PYa1Bc0r/RBKjnFQ1epkz7NDXOz0ugrvOG8mIjNjQtCWAn58xjGum9+ODDdaGuMMzYskpqeP0kem8v2EP47ISuOfSsTR7/Vz6yJLQB8CMuAh6jYrkzFEZmKZJZkIkf/94Gzc/v5rpA5Nx2AwW3nYKycEmIwB/u2wcJbXNvLxy3/qp+VvL+GRLKaMy49heVs9/vz2Zyf2T2LW3gZdWFHDJI4spqGxiQEo0vzprOM8syWNSv0Qemm9NbVtbUI3LbmNQWgxPLt5FSU0zJw1N5dbThjJ3U8kBU9ZOHJrK1AFJnDu2F++v38PpI9M5aWgKwzLiQu9NWmwE3zlhAJ9tKWNCn0TGZSUwPCOWCcEw/Oi3JvHyygKm9E/EFzC54KFFnHzffOpafNgMg1tPHcLGohpuPsnqhmkYBn+5ZAxJ0S5SYlz87aNt2Ax47fszQ+/tP68cz9r8aqLdDkb2iuWTLaXsKKvnx6cO4cqp1v5DL9wwHX/A5OH5O/H4A3xjUhaVDR5uOWUwzy7dzdvrirn/422syKskxm1VET7cuAfDsMK422EnNsI6bgBvrS2iyetnXJ94zh7di4Bp/dz+6vX15JbXU1jVxKdbSumdEMnwjFjuPG8Em4pqueWUwZTVtZARH0FZbTMfby7lpKGpoTBy1RPLMQy499KxXD65D6Zp8qOX1vDOumLeWVdMepybH54ymM17avn1OSNIjXHz/edX0T8lmpdW5PPI5zsZmh5DbZOPktpmfnv+qFDDmN+8uYG5G0sor2vhsW9N4oxRGTR7/WwsqiErMYqM+AjmDE/j129u4P31e/jvt6cwJD2W8X0S+HhzKWN6xx9Slb9+1gBrHePTK1lXWMOAlGim9E9k8Y69RDht2Axr+m1rJTIjPoJ+yVFUNni455IxNLT4OXFoaujnJ9wZ4bRb7+TJk83s7OzuHoaIhJvKXFhwjxViUodD/9nWPjqlm8DXbE1VS+hnbTaKCSfeBilDYckDVrAZcxlc8niXbCgqXeu99cVMG5BMaqy74xuHoW8/uYLPt5Xz4a2zQ2spulNOSS29EyIPWQTfFtM0+XRLGTMHJx+y6LrF58fnNw/ZT2pTcQ3nPrCIf105vs0W1RX11vqVrMRIzv7XQnJK6nj95hlM6pdEIGBy4b8XU9ngwe20ERfhPKQb022vreOV7EK++OUpnf6gVVLTzJtrijhvbC9+/eYG7jh7BBc/vJg/XTQ6VIkqqWlm+l8+ZWSvOD64dfYhj7G3voXL/7OU3L0NnDo8jf9eN6XNc+0sr+fddcX8aM4QWnx+fvzSWj7ZUsr4Pgm8+YOZGIZBbnk9c+7/HIAfnDyIH84ZHHqd520q4XvPrWJgajS55Q1M7Z/EOWMyuPtda6rUmz+YyYS+idz4bDYfby7lrFEZzN1UEvpt/Y6yes5/0HofzthvDVer1s9+R1KdXLC1jHmbSkmPc5Ozp465we5/z3136iGdtRpafEz+0yfMGZHGv4Nd9w62eMdern5iOeeO6cXfLht3SKOC0/9uvSYf/+yk0Fin/PmT0HoPgPPHZfJusELULzkq1Cny1v+tYU9NMzWN3tBC/89+ftIha1aeWZLH797ZFJre+bvzR3X4OrT+fPoDJj8+dTBnjd63fqqouomF28qZNTiFrMTINl/XJo+fsb+fh9dv8sS1k5m7qYR5G0tY/ptTQ+/7Of9aGFprtOyOUw+phrcyTZMWXyDUUn7Jzr1c9fhyfnveSL5zwqGV4Nbxe/zWfR5ZsJN75+aQFO1ibFY8T19/4Cae6wqqcdptx6QteFcxDGOVaZqTDzmuYCMiXxkNe2HuHbDhFev7pIHQe7L1fWwmpA6zGhjEZcKUG6DfTKsCVLAcBpwMFdsha6qmtMkx8/LKfF7NLuSV783osJXyV8Wq3VVM6JPQ4fN9ftlu/vz+FpbdcWpoD5vWD2guh42HvjnhkA/lRdVNLNtZwaX7tUT/MsrrWkiOdh0w1tpmL15f4IBKzP4Kqxr55avr+enpQ5k64MjWrO2uaOCqx5dzz6VjQmHANE0m/vFj6lt8LL3j1FB7ebA60X2xrRx/wOSGZ7P50ZzBfHtmf6b9nxW63vnhLAzD4M01hSzeUcH1s/rz3NLd/Omi0aG1bi0+f6dbOHfE5w9w47PZLMutZNVdp7XZZWxrSR29EiIOu/9PfYvvgPVR+1ueW4HLYQtVkAC+9d/lLNyvUcM/rhjH/R9to7CqiRkDk3npJqvLo8cXIGCa/OR/a5m7qYQTh6byzPWHLupftbuSSx9ZCsD7Pz6BUZnHZx3nz19ZR3ykk9+eP5LqRg+VDZ4DQtdNz2bz0eZSYt0O1t99xhFPiw0ETN5eV8TZo3sdsn9WW8rrWrjmieVsLa3jgW+2va9QuFOwEZGvB9O09tJpqrbW4djssOppyF8Ge7da1Z2SDdBYYV22OazLrfpMt9paexqsttQD9vutrd9nPZ4qPyJfmmma1Db7iD+o09LcjXsYmh7bZmeor5q/f7SVgAm/OHNYm9c3efz86vX1/OS0IQxMjeGtNUUMTI0+ZDH/8eT1ByitbT7s9M9j7S8fbuHRz3P500WjafL4+daMfmzeU8slDy/hR3MG8/MzDnz9tpbU8fm2Mq6bOaDN9smNHh+jfjeP4RlxfNhGZa67/OHdzTy5eBcT+ybwRhetiWzV7PWzdGcFJw1N7ZG/dFGwERFp5W2yqjRLH4aaApj+Ayv0xGTA0n9DXTHYnBDwwrBz4aTbYPmjsPktiE6FS/8LffabgtJUtS/0rHnO2rOn3ywFIBGRY2BlXiV/em8zz90w7YBKUH5FI2lx7iOqUhzsHx9vY0LfBE4elnYsh/qlPLloF394bzNXTO7TYcvtrzsFGxGRIxXwW93Ylj9qre3xNVnNCiZeCzs/g7oSOOPPkDbC6ty28H7rfobNamMN4IqB6TdbTREUcEREpAMfbSrhpudWcee5I46oIcjXWXvBRl3RREQOZrODLRJO+AmM+ybkvGd1WuszFRor4cUr4MNf7rv9mMusKk1NIYy62GpqsONj+OI+WP4YxPWybpM5Hko3Q1SSVflJHgzJg8DbDM62F4mKiMjXw6je8cRGOA7o2Cido4qNiEhn+X1QvsVqVuD3wpDTD63KmKZV8dm7zfrKW9j2Y/U7AfKXwqwfw6m/O/RxavdA8RorbPUaD7Gd38hTRETkq0RT0UREulPxWqgtgr4zoKUO6ssg511Y9h/oNdbauye2lzUNrrnaquhEJUPZZgj4rMewu+HKF2HgyVC6AdJGQcUOqx1274lWtzefB7yNVmOEtsKWpsWJiEgPp2AjIhKOAn5rbc6G12Dbh+CMhKgUa1pbS53VonrEBWD64YNfQMlGiEyEpkpr81Jvo/U4NicMmgPFq62W1qnD4fQ/WtUkvxfWPg+f3A1n3Qvjv3n4MZmm1WDB1TM2ZBMRka8XBRsRkZ6usRJWPG61s+4/C4rWQO8JkD4aNr9jBaOEvlZFZ/WzViXHFQOe4M7kEQlWNWjSddYePwNOhMwJVpVn4+tWRSngg01vWueI7wNn/AlGXqhKj4iIhA0FGxGRrxNfC6x/xVqfE5thBZyJ18L8/4NlDwPBf/sT+ll7/rTUBO9oWGFn6FlW04SS9TD8PJj5Y6uVdfJgGH0pJPTZV21qL/SUb4N3b4XT7oa+07r+OYuIyNeCgo2IiFjqywHTqtLkL4PIBBh+PvSbYV3virb+9Ptg6UOw4C/ga7bW+PhbrOtaW1unDoeUIdBca63r8TVD8hBIGmBtjFq6EWLSYezlsGuhdXz6LVYw8jZBTJrVFa6pCip3wpAzVB0SEZHDUrAREZGjU7ETsp+Eyd+xQseWd60gY3PAtrlWKIlKgpZ6cERYDQ18Tda6n1PvsjY9bSi3WmJX7LBu356J14KnAbbNs9YMzfyRteancCW01EJ1gbWpalQSZE60ptaZpjVdrtc4yF1gteV2x1qP52uxQpjd2f45RUSkR1GwERGR4yMQsIKMw21Vg/bXUg/Z/7U2QI1KtqbBOSPBsFvT3tY8Z1V+Bp0KOz+F5poD79+6/0/lLqgvscITQMAL8X2hJt9qrhCXBWnDYetccMfAjFusdtn5S6Ew2zo2/FxrPVHRGjjrL5DzvrUeafrNULbFmsI34vwDz1+VZ91n2vetCpbNdvjXwjSt5g1gPZeY1KN7TUVEJETBRkREwptpQm2xFShsdqsr3Ka3rKDSZ6oVasCqGgUCVghxx1qVnJVPwJrnrcYIJRusqlD+MqsNdsAPuxfvO0/6aKvy01JjPabdDbWF1p+RCVBfuu+27uD0uszxVjXp879C9W6IzYS6PTDuSmsT1xWPWWEoYzQMPMWqKNXusZo4lG8BRyR4G+Ck2+Hk263HLllvVb8yxljT/yITrSrUh7+yAtjVr1qvhd8H+UusilRjpdUgwmb/cq91Y6VVXTu4851p7ntdRUTClIKNiIh8vey/b0/5Vis0pQ6HuF7WOqPiNVZnuNoiq8nBCT+1Gie88yPImmxNtavMtdpqb3rLCj+uWGt63MbXrKCx6S2rWuSOh4EnQt6iA6fapY201g156q3jG1+Hid+2zl2y/tAxx2VZ58GA6BRrfAE/bH5r320ik6wqUK+xVtjKX2qtUxp0inV9Q7m1b9JZ9xxYIaousCpipZtg+0eQMtSqTm2bawWvURfDysch93M45ddWVS0i3moekdDXai1eV2IFsKgk2L0EilZZz7GmAJY/Zr1+if2twNe6jsqwWdU7sALp6qet8Dn0bCvQZU0Bh6vt97AuWJWL7sRO7C111uvnjjny+4hIj6JgIyIicrS8zdY0tPjeB1Yz6susdT39ZlnX+b3WsaZKcMdBYr99tzVNePP7sP5/VivtWbdaYaJguVUtqtsDG16xqkhTb4Ll/4Gdn1lT2KbdbFWTolOsqXSOCOu8VbusD/4O97623mBN7YtJh34zrTFseM2qNBk2q9V35kTY9IbV3juhr1XB8dRbQSZlqLWmad+DtT6Bfd/HpB1Y2QIrNNaXWgHO7oLoNCs0YlqBMDLRqlo1VlhjDgSn6NndVmXq7HuttVsOtxWYDANWPml9P/JC63FTh0PaCOvY1g9hz1rwNFrPyR1rhZl1L1v7Pg09CwbMtppZ9J+9b9pg7udWZ8D00ZA+0gqjfq819t6TYPbPrVC76Q0o3QyjLrL2lipeY63pynkfMoKhMq6XtY6rvtR6HGfUoe3RvU2w6wvoM816fcs2W4GtphDWv2y9lyMvhKJsK5RNudFq0tF3hjXlcuH91uvTd4YVXl3RVqCuL4WxV0DBCtjyNoy7ymoD36p2j/Wz5Gu2pnu2VvkCfut99zVbP0sBn/WzOfg0sDva/zvg98HqZ6yfo2k3W8+9Pa0BNibdmvJpmtbr5Ixo/z4H3x/zwMqkaVqBfNXTcPofrKYlbd3P77F+PvZ/DwJ+6xcJaaOscD/gROvvW/Jga2Pjo9FSb72P/9/evcfYWdd5HP98nHZKO51ephesLW1pyxaLtoVKl5uIJe4WNaIJKiJIGhf+kD80WeOiWWLWhGR3TWR3s6xiRBddvGC1akxUsBDcJvYCpQXKpZ12aTtQOrTT6X1apv3uH9/fYcahRXTTOefZeb+SyZznd86c83ue7zlnns/5/Z7nNI/KabW18D5Q17Z8/pw1Jpd3b8p6tM164/t/aUP271QB/URvvn6Gj+xr696Zyy0Tc31PNap7/HD2ecLs0/f1yL58jo2f8Yf332AINgAA1Fvvsdwpnbs0d3L/mKP7pF1P5o7YwLPFnTwp7VydO48tE3OHJSJ3VF89kmeze+X5DBczrpD+4q+leR/KERVJav9thqZ5H8njlXZvyoDWNLxvJKZnfwax3mN5yvCWSTk6s78jQ8Y7Pyrt2pg72Quuz7/t3imtvUc6vCdDU9Nw6fDeDAVNzfkYc5fmqE3PgZxmt/lBac/zfetWCz5vnZ+P3b09w1T3Tr0WsEaMyamGzaPzBBe1EaVZ78nTmG9aIR3Zk7dtHp3BJyLXddTEDJ9xMq8bPiqv79oqDW8pUyEPnLomLZNzVKxpeD5O9/bcma5pm507sWeNyxB3tDuP/RpR2vbv6LvtuBkZZmpBWOp73LcMy1qOGJPb4MSxfM5MvzRH2aTsd++xXA9F1nnc9DxJR8faDJM9+3OUr7lFap2Sz4cje3NHvP/o4tnvyGPKpi7KbfHCqgwDe7ZkUD70cq63nNvsqttzFNTOddj86wydE+ZkMN61Mf/uPV/I6156Ip+roydL196d2/E3X5L2bsn2ve0ZQBffmiOoR7syuO1tz+BdC5ZShoK22fn87u3JnfBRE6QX10uHOzPAj5shXfKZHDl8+E5p91P5/K2tgyKnlH7kG/kYtdHF3ZvytXLieG6fo93SwZekHWtySuzURfmBwrp7+/rT3JrfKXaoM4Nq1//kaGnbrAxjw0ZKc6/JD0deWp81nfnufJ01j8o6nntlCcCLc9s8+o/5Glx8S27T1rfl94vtXC1t+nnW4+Jbsla7Nub3mNXquGdLjp5e+plcpycfkPZsztfk0a788uaLPpXP04jsU/dO6Sd/0/eBw9hzpCs/n8+vzmekfdulm1Y0zFkrCTYAAAw1EbnzNXJ8vXvyxo50Sau+Js15X35CPWFO7pA1l0+rT7ya09WOH86d2aP7MiANHAHoP/3wRG/uxO74fY6KHT+c1589T1q0LHfg9rZnQKud4nzzg9K2R/IT76mLMiRtfTj7N+1dudP61vkZZtZ+M0PCuOk5KnT2Bbnz3b4yQ8jRfX0jJvOvzwB3/HDu0E6elzv442dmIDvUmTviR/ZkoBjRmlP9zhojXVh2QHesztGGHatz3RffKj3+nRxpu+arGUDXfy+XWyZKc9+fgW/sVGl/+fLdvVsyuE2ck6Fy0c0Ztva9IK26K3fq1W+/sG2WNHFujoA1j87wOvE86cfLcrRsWBkJisgvBt7bniG3bZZ04Y3Shvtz5731bdKCj2egal+Zv0e05mjbjMsyII2elKNpiuzjqAkZAsfPzEA3ZUGOerVOkX7wiQwzUxbmqMLe9gyEbbPzmLXenhzRrI08jpueIXzD93O7dW/Ptt//R1/4rRk2Ms/q2N+IMXm/HetKiHWOnr3zY1m/jnW58z9mWo5Kts3OdepYK73jutx+m36WNV94Qx57t78jp3nW6vLyUzmS+spzeZ/n/KXU+Vy/7xgrmpoz3I5oze8ak/L1ffEtuS2e/1Vus82/6fvb5tY8nX9TcwaV9ocyOE9ZmK+DXRvzdpPOl5bckdvy0X/OAFe7/8kXSDf8sGGOvyPYAAAA4PR6DuQO9rGDGSRON92s91gGzMlvf+NTqZ88mSMEI8f3TY06+LL0u6/mCMKSO3KEoubF9dk+7WJp7LSc7nWq46t6j5/+uKyaiFyXrq15PNeppsEd6cqgOHpyhoKeA7neu5/OMDOqLYNf7bF6DvQF1oEn3vhTHD+S4WtUWy7XtlPLxAy/O9dI0y/LQHS0u9TkQIbfKQv61uXVngwrpzo7Y8+BDKxxMoNO7QyVJ09K21dJWx/JaYy9R3NkbMQYac7VuS2k3MYHOjJkjp7cMCM1NQQbAAAAAJV3umDzR07ADwAAAACNj2ADAAAAoPIINgAAAAAqj2ADAAAAoPIINgAAAAAqj2ADAAAAoPIINgAAAAAqj2ADAAAAoPIINgAAAAAqj2ADAAAAoPIINgAAAAAqj2ADAAAAoPIINgAAAAAqj2ADAAAAoPIINgAAAAAqj2ADAAAAoPIINgAAAAAqj2ADAAAAoPIINgAAAAAqj2ADAAAAoPIINgAAAAAqj2ADAAAAoPIINgAAAAAqzxFR7z68xvYrkrbXux/FREl76t0JvGnUq1qoV3VQq2qhXtVCvaqFejWOGRExaWBjQwWbRmL7sYh4V737gTeHelUL9aoOalUt1KtaqFe1UK/Gx1Q0AAAAAJVHsAEAAABQeQSb0/tmvTuAPwn1qhbqVR3UqlqoV7VQr2qhXg2OY2wAAAAAVB4jNgAAAAAqj2ADAAAAoPIINqdge6nt522327693v2BZPvbtjttP92vrc32Q7a3lN/jS7tt/1up35O2L6pfz4ce2+fYfsT2M7Y32f5saadeDcj2WbbX2t5Y6vUPpf1c22tKXX5ku7m0jyjL7eX6mXVdgSHIdpPtJ2z/sixTqwZl+wXbT9neYPux0sZ7YYOyPc72ctvP2X7W9qXUq1oINgPYbpJ0t6RrJM2T9Anb8+rbK0j6T0lLB7TdLmllRJwnaWVZlrJ255WfWyV9fZD6iNQr6W8jYp6kSyTdVl5D1KsxHZO0JCIWSFooaantSyT9k6S7ImKOpH2SPl1u/2lJ+0r7XeV2GFyflfRsv2Vq1djeGxEL+33/Ce+FjetfJf06Is6XtED5OqNeFUKweb3FktojYltEHJf0Q0nX1rlPQ15E/E5S14DmayXdVy7fJ+nD/dq/G2m1pHG2pwxKR6GI2BUR68vlg8p/DFNFvRpS2e6HyuLw8hOSlkhaXtoH1qtWx+WSrrbtwektbE+T9AFJ3yrLFrWqGt4LG5DtsZKulHSvJEXE8YjoFvWqFILN602VtLPfckdpQ+M5OyJ2lcsvSzq7XKaGDaJMfblQ0hpRr4ZVpjZtkNQp6SFJWyV1R0RvuUn/mrxWr3L9fkkTBrXDQ9u/SPqCpJNleYKoVSMLSQ/aftz2raWN98LGdK6kVyR9p0z1/JbtFlGvSiHY4P+FyPOWc+7yBmJ7tKSfSPpcRBzofx31aiwRcSIiFkqaphy1Pr++PcKp2P6gpM6IeLzefcGbdkVEXKSctnSb7Sv7X8l7YUMZJukiSV+PiAslHVbftDNJ1KsKCDav96Kkc/otTyttaDy7a8O+5XdnaaeGdWZ7uDLU3B8RPy3N1KvBlWkXj0i6VDmtYli5qn9NXqtXuX6spL2D29Mh63JJH7L9gnKa9BLlMQHUqkFFxIvld6ekFcoPDngvbEwdkjoiYk1ZXq4MOtSrQgg2r7dO0nnlLDPNkq6X9Is69wmn9gtJN5fLN0v6eb/2T5UzllwiaX+/YWScYWUO/72Sno2Ir/W7ino1INuTbI8rl0dKep/yuKhHJF1XbjawXrU6Xifp4eCbngdFRHwxIqZFxEzl/6aHI+KTolYNyXaL7dbaZUl/Jelp8V7YkCLiZUk7bc8tTVdLekbUq1LMe9zr2X6/ch5zk6RvR8Sd9e0RbP9A0lWSJkraLenLkn4m6QFJ0yVtl/SxiOgqO9b/rjyL2hFJyyLisTp0e0iyfYWk/5b0lPqOA/iS8jgb6tVgbM9XHhDbpPyw64GI+IrtWcpRgTZJT0i6MSKO2T5L0veUx051Sbo+IrbVp/dDl+2rJH0+Ij5IrRpTqcuKsjhM0vcj4k7bE8R7YUOyvVB5Yo5mSdskLVN5XxT1qgSCDQAAAIDKYyoaAAAAgMoj2AAAAACoPIINAAAAgMoj2AAAAACoPIINAAAAgMoj2AAAKs32VbZ/We9+AADqi2ADAAAAoPIINgCAQWH7RttrbW+wfY/tJtuHbN9le5PtlbYnldsutL3a9pO2V9geX9rn2P6t7Y2219ueXe5+tO3ltp+zfX/58jwAwBBCsAEAnHG23y7p45Iuj4iFkk5I+qSkFkmPRcQFkh6V9OXyJ9+V9HcRMV/SU/3a75d0d0QskHSZpF2l/UJJn5M0T9IsSZef4VUCADSYYfXuAABgSLha0iJJ68pgykhJnZJOSvpRuc1/Sfqp7bGSxkXEo6X9Pkk/tt0qaWpErJCkiOiRpHJ/ayOioyxvkDRT0qozvlYAgIZBsAEADAZLui8ivvgHjfYdA24Xf+b9H+t3+YT4/wYAQw5T0QAAg2GlpOtsT5Yk2222Zyj/D11XbnODpFURsV/SPtvvLu03SXo0Ig5K6rD94XIfI2yPGsyVAAA0Lj7RAgCccRHxjO2/l/Sg7bdIelXSbZIOS1pcrutUHocjSTdL+kYJLtskLSvtN0m6x/ZXyn18dBBXAwDQwBzx5476AwDwf2P7UESMrnc/AADVx1Q0AAAAAJXHiA0AAACAymPEBgAAAEDlEWwAAAAAVB7BBgAAAEDlEWwAAAAAVB7BBgAAAEDl/S/oUQY20BqU2gAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"603.474375pt\" version=\"1.1\" viewBox=\"0 0 829.003125 603.474375\" width=\"829.003125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-08-13T20:23:46.109925</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 603.474375 \nL 829.003125 603.474375 \nL 829.003125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 40.603125 565.918125 \nL 821.803125 565.918125 \nL 821.803125 22.318125 \nL 40.603125 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m0ef36042e6\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"76.112216\" xlink:href=\"#m0ef36042e6\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(72.930966 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"183.878804\" xlink:href=\"#m0ef36042e6\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 100 -->\n      <g transform=\"translate(174.335054 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"291.645393\" xlink:href=\"#m0ef36042e6\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 200 -->\n      <g transform=\"translate(282.101643 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"399.411981\" xlink:href=\"#m0ef36042e6\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 300 -->\n      <g transform=\"translate(389.868231 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"507.17857\" xlink:href=\"#m0ef36042e6\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 400 -->\n      <g transform=\"translate(497.63482 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"614.945158\" xlink:href=\"#m0ef36042e6\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 500 -->\n      <g transform=\"translate(605.401408 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"722.711747\" xlink:href=\"#m0ef36042e6\" y=\"565.918125\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 600 -->\n      <g transform=\"translate(713.167997 580.516562)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- epoch -->\n     <g transform=\"translate(415.975 594.194687)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n       <path d=\"M 18.109375 8.203125 \nL 18.109375 -20.796875 \nL 9.078125 -20.796875 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.390625 \nQ 20.953125 51.265625 25.265625 53.625 \nQ 29.59375 56 35.59375 56 \nQ 45.5625 56 51.78125 48.09375 \nQ 58.015625 40.1875 58.015625 27.296875 \nQ 58.015625 14.40625 51.78125 6.484375 \nQ 45.5625 -1.421875 35.59375 -1.421875 \nQ 29.59375 -1.421875 25.265625 0.953125 \nQ 20.953125 3.328125 18.109375 8.203125 \nz\nM 48.6875 27.296875 \nQ 48.6875 37.203125 44.609375 42.84375 \nQ 40.53125 48.484375 33.40625 48.484375 \nQ 26.265625 48.484375 22.1875 42.84375 \nQ 18.109375 37.203125 18.109375 27.296875 \nQ 18.109375 17.390625 22.1875 11.75 \nQ 26.265625 6.109375 33.40625 6.109375 \nQ 40.53125 6.109375 44.609375 11.75 \nQ 48.6875 17.390625 48.6875 27.296875 \nz\n\" id=\"DejaVuSans-112\"/>\n       <path d=\"M 30.609375 48.390625 \nQ 23.390625 48.390625 19.1875 42.75 \nQ 14.984375 37.109375 14.984375 27.296875 \nQ 14.984375 17.484375 19.15625 11.84375 \nQ 23.34375 6.203125 30.609375 6.203125 \nQ 37.796875 6.203125 41.984375 11.859375 \nQ 46.1875 17.53125 46.1875 27.296875 \nQ 46.1875 37.015625 41.984375 42.703125 \nQ 37.796875 48.390625 30.609375 48.390625 \nz\nM 30.609375 56 \nQ 42.328125 56 49.015625 48.375 \nQ 55.71875 40.765625 55.71875 27.296875 \nQ 55.71875 13.875 49.015625 6.21875 \nQ 42.328125 -1.421875 30.609375 -1.421875 \nQ 18.84375 -1.421875 12.171875 6.21875 \nQ 5.515625 13.875 5.515625 27.296875 \nQ 5.515625 40.765625 12.171875 48.375 \nQ 18.84375 56 30.609375 56 \nz\n\" id=\"DejaVuSans-111\"/>\n       <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 75.984375 \nL 18.109375 75.984375 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-104\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"61.523438\" xlink:href=\"#DejaVuSans-112\"/>\n      <use x=\"125\" xlink:href=\"#DejaVuSans-111\"/>\n      <use x=\"186.181641\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"241.162109\" xlink:href=\"#DejaVuSans-104\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mfd359d6351\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#mfd359d6351\" y=\"522.911538\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 5 -->\n      <g transform=\"translate(27.240625 526.710756)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#mfd359d6351\" y=\"458.026506\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 10 -->\n      <g transform=\"translate(20.878125 461.825725)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#mfd359d6351\" y=\"393.141475\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 15 -->\n      <g transform=\"translate(20.878125 396.940693)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#mfd359d6351\" y=\"328.256443\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 20 -->\n      <g transform=\"translate(20.878125 332.055662)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#mfd359d6351\" y=\"263.371411\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 25 -->\n      <g transform=\"translate(20.878125 267.17063)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#mfd359d6351\" y=\"198.48638\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 30 -->\n      <g transform=\"translate(20.878125 202.285599)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#mfd359d6351\" y=\"133.601348\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 35 -->\n      <g transform=\"translate(20.878125 137.400567)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"40.603125\" xlink:href=\"#mfd359d6351\" y=\"68.716317\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 40 -->\n      <g transform=\"translate(20.878125 72.515536)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_17\">\n     <!-- MSE -->\n     <g transform=\"translate(14.798438 304.765781)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 9.8125 72.90625 \nL 24.515625 72.90625 \nL 43.109375 23.296875 \nL 61.8125 72.90625 \nL 76.515625 72.90625 \nL 76.515625 0 \nL 66.890625 0 \nL 66.890625 64.015625 \nL 48.09375 14.015625 \nL 38.1875 14.015625 \nL 19.390625 64.015625 \nL 19.390625 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-77\"/>\n       <path d=\"M 53.515625 70.515625 \nL 53.515625 60.890625 \nQ 47.90625 63.578125 42.921875 64.890625 \nQ 37.9375 66.21875 33.296875 66.21875 \nQ 25.25 66.21875 20.875 63.09375 \nQ 16.5 59.96875 16.5 54.203125 \nQ 16.5 49.359375 19.40625 46.890625 \nQ 22.3125 44.4375 30.421875 42.921875 \nL 36.375 41.703125 \nQ 47.40625 39.59375 52.65625 34.296875 \nQ 57.90625 29 57.90625 20.125 \nQ 57.90625 9.515625 50.796875 4.046875 \nQ 43.703125 -1.421875 29.984375 -1.421875 \nQ 24.8125 -1.421875 18.96875 -0.25 \nQ 13.140625 0.921875 6.890625 3.21875 \nL 6.890625 13.375 \nQ 12.890625 10.015625 18.65625 8.296875 \nQ 24.421875 6.59375 29.984375 6.59375 \nQ 38.421875 6.59375 43.015625 9.90625 \nQ 47.609375 13.234375 47.609375 19.390625 \nQ 47.609375 24.75 44.3125 27.78125 \nQ 41.015625 30.8125 33.5 32.328125 \nL 27.484375 33.5 \nQ 16.453125 35.6875 11.515625 40.375 \nQ 6.59375 45.0625 6.59375 53.421875 \nQ 6.59375 63.09375 13.40625 68.65625 \nQ 20.21875 74.21875 32.171875 74.21875 \nQ 37.3125 74.21875 42.625 73.28125 \nQ 47.953125 72.359375 53.515625 70.515625 \nz\n\" id=\"DejaVuSans-83\"/>\n       <path d=\"M 9.8125 72.90625 \nL 55.90625 72.90625 \nL 55.90625 64.59375 \nL 19.671875 64.59375 \nL 19.671875 43.015625 \nL 54.390625 43.015625 \nL 54.390625 34.71875 \nL 19.671875 34.71875 \nL 19.671875 8.296875 \nL 56.78125 8.296875 \nL 56.78125 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-69\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-77\"/>\n      <use x=\"86.279297\" xlink:href=\"#DejaVuSans-83\"/>\n      <use x=\"149.755859\" xlink:href=\"#DejaVuSans-69\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#pc525ec3503)\" d=\"M 76.112216 47.027216 \nL 78.267548 158.239116 \nL 80.422879 251.733669 \nL 81.500545 294.118685 \nL 83.655877 366.636044 \nL 84.733543 394.76662 \nL 86.888875 442.835797 \nL 87.966541 461.489216 \nL 90.121872 481.918098 \nL 91.199538 490.527108 \nL 93.35487 498.694115 \nL 94.432536 500.872275 \nL 95.510202 500.697516 \nL 96.587868 502.999242 \nL 97.665534 503.038523 \nL 98.743199 503.631901 \nL 99.820865 504.811677 \nL 100.898531 504.898945 \nL 101.976197 505.505361 \nL 103.053863 504.129137 \nL 104.131529 505.296884 \nL 105.209195 504.899032 \nL 106.286861 506.34435 \nL 107.364527 505.664069 \nL 108.442192 504.1378 \nL 109.519858 505.068234 \nL 110.597524 505.054868 \nL 111.67519 504.78601 \nL 112.752856 506.42996 \nL 113.830522 506.62332 \nL 114.908188 503.725431 \nL 115.985854 505.657368 \nL 117.06352 502.424755 \nL 118.141185 504.86076 \nL 119.218851 506.517235 \nL 121.374183 506.369733 \nL 122.451849 506.959634 \nL 123.529515 504.711024 \nL 124.607181 507.248152 \nL 125.684847 505.450041 \nL 126.762513 507.87599 \nL 127.840178 504.631794 \nL 128.917844 508.331662 \nL 129.99551 504.227859 \nL 132.150842 508.298526 \nL 133.228508 507.672265 \nL 134.306174 507.718087 \nL 135.38384 507.569038 \nL 136.461505 507.110229 \nL 137.539171 508.586159 \nL 138.616837 507.489425 \nL 139.694503 508.090395 \nL 140.772169 508.440848 \nL 141.849835 509.844299 \nL 142.927501 507.843572 \nL 144.005167 504.321711 \nL 145.082833 504.129286 \nL 146.160498 509.179649 \nL 147.238164 508.606728 \nL 148.31583 504.130109 \nL 149.393496 507.196928 \nL 150.471162 505.854187 \nL 151.548828 507.69125 \nL 152.626494 507.239841 \nL 153.70416 508.419104 \nL 154.781826 506.781589 \nL 155.859491 509.694174 \nL 156.937157 506.41954 \nL 158.014823 510.141375 \nL 159.092489 508.852623 \nL 160.170155 506.544777 \nL 161.247821 507.862606 \nL 162.325487 509.592104 \nL 163.403153 508.082543 \nL 164.480818 509.914959 \nL 165.558484 508.932831 \nL 167.713816 509.949327 \nL 168.791482 513.539297 \nL 169.869148 509.305789 \nL 170.946814 509.228465 \nL 172.02448 510.77094 \nL 173.102146 507.850719 \nL 174.179811 507.275601 \nL 175.257477 509.039715 \nL 176.335143 511.315724 \nL 177.412809 510.299414 \nL 178.490475 511.29333 \nL 179.568141 510.422294 \nL 180.645807 511.2546 \nL 181.723473 510.409312 \nL 182.801139 510.638444 \nL 183.878804 508.415756 \nL 184.95647 511.764868 \nL 186.034136 508.44052 \nL 187.111802 508.84909 \nL 188.189468 510.291073 \nL 189.267134 510.721709 \nL 190.3448 507.879573 \nL 191.422466 510.182506 \nL 192.500131 511.653294 \nL 194.655463 511.320545 \nL 195.733129 509.821484 \nL 196.810795 512.192695 \nL 197.888461 512.926823 \nL 198.966127 513.860871 \nL 200.043793 508.273057 \nL 201.121459 509.512416 \nL 202.199124 513.12285 \nL 203.27679 508.555943 \nL 204.354456 512.443454 \nL 205.432122 510.912185 \nL 206.509788 511.180079 \nL 207.587454 511.302878 \nL 208.66512 513.609512 \nL 209.742786 509.69142 \nL 210.820452 511.858677 \nL 211.898117 509.93278 \nL 212.975783 514.041335 \nL 214.053449 512.601481 \nL 215.131115 512.40757 \nL 216.208781 511.771947 \nL 217.286447 513.353573 \nL 218.364113 512.236171 \nL 219.441779 511.998586 \nL 220.519444 511.970722 \nL 221.59711 515.559164 \nL 222.674776 514.873295 \nL 223.752442 514.447566 \nL 224.830108 512.061585 \nL 225.907774 516.496386 \nL 226.98544 513.429319 \nL 228.063106 515.191775 \nL 229.140772 514.047802 \nL 230.218437 514.654329 \nL 231.296103 515.757183 \nL 232.373769 513.396251 \nL 233.451435 514.367841 \nL 234.529101 514.346944 \nL 235.606767 513.230675 \nL 236.684433 516.359305 \nL 237.762099 517.654164 \nL 238.839765 514.495826 \nL 239.91743 516.134801 \nL 240.995096 515.223073 \nL 242.072762 513.458403 \nL 243.150428 517.792774 \nL 244.228094 513.880375 \nL 245.30576 514.899538 \nL 246.383426 514.628971 \nL 247.461092 515.559374 \nL 248.538758 516.760059 \nL 249.616423 513.73572 \nL 250.694089 517.670636 \nL 251.771755 515.278894 \nL 252.849421 515.178644 \nL 253.927087 515.243005 \nL 255.004753 514.547185 \nL 256.082419 517.499138 \nL 257.160085 513.672734 \nL 258.23775 517.792279 \nL 259.315416 517.983021 \nL 260.393082 515.858913 \nL 261.470748 514.224615 \nL 262.548414 514.36729 \nL 263.62608 516.577312 \nL 264.703746 517.866818 \nL 265.781412 515.444137 \nL 266.859078 515.756868 \nL 267.936743 518.960372 \nL 269.014409 516.504177 \nL 270.092075 518.328883 \nL 271.169741 516.296108 \nL 272.247407 519.361108 \nL 273.325073 518.023175 \nL 274.402739 517.418794 \nL 275.480405 517.746339 \nL 276.558071 520.331689 \nL 277.635736 518.18919 \nL 278.713402 518.917688 \nL 279.791068 516.952547 \nL 280.868734 517.256881 \nL 281.9464 517.826207 \nL 283.024066 520.644049 \nL 284.101732 518.807252 \nL 285.179398 517.803194 \nL 286.257063 519.263073 \nL 287.334729 517.310252 \nL 288.412395 516.973252 \nL 289.490061 518.154934 \nL 290.567727 519.769418 \nL 292.723059 516.60491 \nL 293.800725 518.349408 \nL 294.878391 519.258456 \nL 295.956056 519.455406 \nL 297.033722 517.438138 \nL 299.189054 520.615758 \nL 300.26672 520.292037 \nL 301.344386 519.051421 \nL 302.422052 521.388982 \nL 303.499718 520.227355 \nL 304.577384 520.806185 \nL 305.655049 519.02808 \nL 306.732715 520.99772 \nL 307.810381 518.001028 \nL 308.888047 520.064946 \nL 309.965713 519.069471 \nL 311.043379 521.624401 \nL 312.121045 520.914393 \nL 313.198711 520.753192 \nL 314.276376 517.507529 \nL 315.354042 521.684238 \nL 316.431708 519.565284 \nL 317.509374 518.08264 \nL 318.58704 520.920173 \nL 319.664706 518.407946 \nL 320.742372 520.324666 \nL 321.820038 519.488214 \nL 322.897704 519.927222 \nL 323.975369 521.018276 \nL 325.053035 519.741065 \nL 326.130701 522.072351 \nL 327.208367 516.742535 \nL 328.286033 520.779552 \nL 329.363699 521.533278 \nL 330.441365 521.034742 \nL 331.519031 523.277491 \nL 332.596697 520.86351 \nL 334.752028 522.237735 \nL 335.829694 519.289285 \nL 336.90736 522.123209 \nL 337.985026 521.467513 \nL 339.062692 521.950529 \nL 340.140358 522.202241 \nL 341.218024 518.829392 \nL 343.373355 522.56955 \nL 344.451021 521.321292 \nL 345.528687 520.295793 \nL 346.606353 520.258703 \nL 347.684019 521.202905 \nL 348.761685 521.562404 \nL 349.839351 521.540493 \nL 350.917017 522.717126 \nL 351.994682 522.45857 \nL 353.072348 522.4269 \nL 354.150014 520.845788 \nL 355.22768 521.867951 \nL 356.305346 524.34383 \nL 357.383012 520.942499 \nL 358.460678 522.965595 \nL 359.538344 521.440997 \nL 360.61601 519.368212 \nL 361.693675 522.186833 \nL 362.771341 520.962052 \nL 363.849007 521.739787 \nL 364.926673 519.423569 \nL 366.004339 520.599539 \nL 367.082005 520.786594 \nL 369.237337 522.429783 \nL 370.315003 520.261741 \nL 371.392668 519.626526 \nL 372.470334 521.618881 \nL 373.548 520.037639 \nL 374.625666 521.683223 \nL 375.703332 525.351446 \nL 376.780998 523.571937 \nL 377.858664 522.404005 \nL 378.93633 522.345485 \nL 380.013995 519.248401 \nL 381.091661 521.011729 \nL 382.169327 523.194152 \nL 383.246993 522.068502 \nL 384.324659 524.267973 \nL 385.402325 522.346457 \nL 386.479991 525.032657 \nL 387.557657 521.578678 \nL 388.635323 521.582769 \nL 389.712988 523.453785 \nL 390.790654 523.250419 \nL 392.945986 522.261336 \nL 394.023652 517.78554 \nL 395.101318 522.708234 \nL 396.178984 520.724801 \nL 397.25665 523.651662 \nL 398.334316 522.048113 \nL 399.411981 522.438601 \nL 400.489647 522.426925 \nL 401.567313 520.809211 \nL 402.644979 523.154723 \nL 403.722645 521.938698 \nL 404.800311 521.286801 \nL 405.877977 522.825099 \nL 406.955643 522.072153 \nL 408.033308 521.980689 \nL 409.110974 524.165662 \nL 410.18864 523.207221 \nL 411.266306 520.630528 \nL 412.343972 521.118495 \nL 413.421638 525.116912 \nL 414.499304 520.795307 \nL 417.732301 523.950582 \nL 418.809967 520.526138 \nL 419.887633 522.615786 \nL 420.965299 520.701819 \nL 422.042965 520.816048 \nL 423.120631 522.544644 \nL 424.198297 522.948442 \nL 425.275963 520.567195 \nL 426.353629 522.822172 \nL 427.431294 524.013167 \nL 429.586626 523.038415 \nL 430.664292 521.865451 \nL 431.741958 524.404206 \nL 432.819624 522.846583 \nL 433.89729 523.385285 \nL 434.974956 522.694224 \nL 436.052621 520.063208 \nL 437.130287 524.374448 \nL 438.207953 523.353831 \nL 439.285619 521.871676 \nL 440.363285 522.668278 \nL 441.440951 525.038443 \nL 442.518617 520.62069 \nL 443.596283 523.493914 \nL 444.673949 522.148654 \nL 445.751614 522.973126 \nL 446.82928 521.735363 \nL 447.906946 520.891714 \nL 448.984612 524.411446 \nL 450.062278 525.366687 \nL 451.139944 522.049418 \nL 452.21761 523.232134 \nL 453.295276 523.257436 \nL 454.372942 524.290286 \nL 455.450607 523.673165 \nL 456.528273 521.46961 \nL 457.605939 520.73943 \nL 458.683605 524.994886 \nL 459.761271 522.893605 \nL 460.838937 522.430049 \nL 461.916603 522.090122 \nL 462.994269 523.4168 \nL 464.071934 523.359308 \nL 465.1496 522.255488 \nL 466.227266 522.577359 \nL 467.304932 523.302237 \nL 468.382598 522.120981 \nL 469.460264 523.885986 \nL 470.53793 523.001819 \nL 471.615596 523.640066 \nL 472.693262 522.366054 \nL 473.770927 523.80792 \nL 474.848593 522.588466 \nL 475.926259 521.177695 \nL 478.081591 523.642566 \nL 479.159257 523.395872 \nL 480.236923 525.59496 \nL 481.314589 522.883698 \nL 482.392255 523.202648 \nL 483.46992 520.529975 \nL 484.547586 521.416462 \nL 485.625252 523.644911 \nL 486.702918 523.883913 \nL 487.780584 523.197122 \nL 488.85825 521.98671 \nL 489.935916 521.73613 \nL 491.013582 521.868075 \nL 492.091247 522.175181 \nL 493.168913 524.988265 \nL 494.246579 524.34956 \nL 495.324245 520.898843 \nL 496.401911 521.69813 \nL 497.479577 524.654643 \nL 498.557243 523.728584 \nL 499.634909 522.486192 \nL 500.712575 523.718832 \nL 503.945572 521.865284 \nL 505.023238 520.620801 \nL 506.100904 523.512725 \nL 507.17857 523.685949 \nL 508.256236 523.991175 \nL 509.333902 522.789153 \nL 510.411568 521.38642 \nL 511.489233 524.739065 \nL 512.566899 520.700594 \nL 513.644565 522.303606 \nL 514.722231 522.887448 \nL 515.799897 524.206904 \nL 516.877563 521.938586 \nL 517.955229 523.509253 \nL 519.032895 524.310044 \nL 520.110561 523.282237 \nL 521.188226 522.94572 \nL 522.265892 523.178707 \nL 523.343558 523.52692 \nL 524.421224 523.12103 \nL 525.49889 524.405474 \nL 526.576556 523.625376 \nL 527.654222 525.076164 \nL 528.731888 523.637919 \nL 529.809553 521.620991 \nL 530.887219 522.79247 \nL 531.964885 523.685349 \nL 533.042551 522.48011 \nL 534.120217 524.493003 \nL 535.197883 522.242982 \nL 536.275549 520.858355 \nL 537.353215 523.425048 \nL 538.430881 522.44641 \nL 539.508546 520.051636 \nL 540.586212 526.049741 \nL 541.663878 523.086272 \nL 542.741544 524.026205 \nL 543.81921 524.030388 \nL 544.896876 525.365629 \nL 545.974542 524.663127 \nL 547.052208 522.728499 \nL 548.129874 525.393301 \nL 549.207539 523.282268 \nL 550.285205 524.189467 \nL 551.362871 525.526639 \nL 552.440537 521.705122 \nL 553.518203 523.377525 \nL 554.595869 521.366235 \nL 555.673535 524.440678 \nL 557.828866 524.093511 \nL 558.906532 524.995988 \nL 559.984198 523.164896 \nL 561.061864 522.500784 \nL 562.13953 523.429405 \nL 563.217196 522.480939 \nL 564.294862 523.991998 \nL 565.372528 522.720145 \nL 566.450194 523.584288 \nL 567.527859 522.471385 \nL 568.605525 520.050089 \nL 569.683191 520.972423 \nL 570.760857 522.387452 \nL 571.838523 523.410872 \nL 572.916189 523.595464 \nL 573.993855 522.497683 \nL 575.071521 522.493723 \nL 576.149187 522.092529 \nL 577.226852 523.907106 \nL 578.304518 521.18655 \nL 579.382184 523.941832 \nL 580.45985 524.660392 \nL 581.537516 523.59378 \nL 582.615182 521.092122 \nL 583.692848 524.301889 \nL 584.770514 519.800549 \nL 585.848179 523.477008 \nL 586.925845 524.269761 \nL 588.003511 524.884568 \nL 589.081177 524.333391 \nL 590.158843 521.921539 \nL 591.236509 522.998113 \nL 592.314175 522.801857 \nL 593.391841 521.152015 \nL 594.469507 524.557425 \nL 595.547172 522.809889 \nL 596.624838 525.406804 \nL 597.702504 525.104926 \nL 598.78017 523.340577 \nL 599.857836 523.992975 \nL 600.935502 521.476231 \nL 602.013168 522.186586 \nL 603.090834 522.434103 \nL 604.1685 524.263047 \nL 605.246165 519.664792 \nL 606.323831 524.057918 \nL 607.401497 523.345447 \nL 608.479163 524.644297 \nL 609.556829 523.73351 \nL 610.634495 524.537846 \nL 611.712161 523.860585 \nL 612.789827 523.84251 \nL 613.867492 521.77879 \nL 614.945158 524.24548 \nL 616.022824 525.5498 \nL 617.10049 523.834515 \nL 618.178156 523.223588 \nL 619.255822 523.423105 \nL 620.333488 523.485677 \nL 621.411154 521.625428 \nL 622.48882 524.555624 \nL 623.566485 524.30023 \nL 624.644151 526.783696 \nL 625.721817 522.47701 \nL 626.799483 525.036197 \nL 627.877149 524.194838 \nL 628.954815 523.058111 \nL 630.032481 523.050896 \nL 631.110147 521.041976 \nL 632.187813 525.477562 \nL 633.265478 522.971115 \nL 634.343144 525.353581 \nL 636.498476 521.999284 \nL 637.576142 522.762434 \nL 638.653808 524.143237 \nL 639.731474 521.827971 \nL 640.80914 523.327391 \nL 641.886806 522.465197 \nL 642.964471 522.502095 \nL 644.042137 520.628647 \nL 645.119803 520.909845 \nL 646.197469 524.563254 \nL 647.275135 521.744744 \nL 648.352801 522.072901 \nL 649.430467 524.511177 \nL 650.508133 522.483853 \nL 651.585798 522.547292 \nL 652.663464 523.248346 \nL 653.74113 522.62482 \nL 654.818796 523.57125 \nL 655.896462 523.46764 \nL 656.974128 525.086993 \nL 658.051794 525.169231 \nL 659.12946 524.107291 \nL 660.207126 525.160295 \nL 661.284791 524.156114 \nL 662.362457 522.746722 \nL 663.440123 521.9709 \nL 664.517789 521.603572 \nL 665.595455 522.765416 \nL 666.673121 524.190822 \nL 667.750787 522.897776 \nL 668.828453 525.345685 \nL 669.906119 523.603267 \nL 670.983784 524.456494 \nL 672.06145 520.603085 \nL 673.139116 521.677462 \nL 674.216782 524.270739 \nL 675.294448 520.629377 \nL 676.372114 521.821857 \nL 677.44978 523.911184 \nL 678.527446 525.185146 \nL 679.605111 523.694142 \nL 681.760443 522.57593 \nL 682.838109 522.912819 \nL 683.915775 519.73617 \nL 684.993441 525.023332 \nL 686.071107 522.850017 \nL 687.148773 524.380791 \nL 688.226439 522.919774 \nL 689.304104 522.458631 \nL 690.38177 525.195325 \nL 691.459436 524.195952 \nL 692.537102 524.518812 \nL 693.614768 522.083118 \nL 694.692434 524.405085 \nL 695.7701 525.898557 \nL 696.847766 522.958739 \nL 697.925432 523.967426 \nL 699.003097 522.682999 \nL 700.080763 524.273653 \nL 701.158429 523.177135 \nL 702.236095 525.126082 \nL 703.313761 525.163915 \nL 704.391427 522.040638 \nL 705.469093 522.03612 \nL 706.546759 524.861499 \nL 707.624424 523.307094 \nL 708.70209 524.335545 \nL 709.779756 522.25758 \nL 710.857422 525.273732 \nL 711.935088 524.62983 \nL 713.012754 521.973393 \nL 714.09042 521.403338 \nL 715.168086 523.591522 \nL 716.245752 523.077887 \nL 717.323417 523.374827 \nL 718.401083 522.531544 \nL 719.478749 521.850427 \nL 720.556415 523.877441 \nL 721.634081 520.431624 \nL 722.711747 520.621748 \nL 723.789413 525.148532 \nL 724.867079 524.208816 \nL 727.02241 523.135274 \nL 728.100076 522.954717 \nL 729.177742 522.247085 \nL 730.255408 523.856829 \nL 731.333074 523.193849 \nL 732.41074 523.644231 \nL 733.488406 522.821955 \nL 734.566072 523.467813 \nL 735.643737 523.506333 \nL 736.721403 524.80712 \nL 737.799069 523.259107 \nL 738.876735 522.010174 \nL 739.954401 524.188736 \nL 741.032067 524.081506 \nL 742.109733 522.858371 \nL 743.187399 524.161324 \nL 745.34273 522.305852 \nL 746.420396 523.596843 \nL 747.498062 521.671194 \nL 748.575728 526.328636 \nL 749.653394 523.127849 \nL 750.73106 523.185594 \nL 751.808726 522.000193 \nL 752.886392 523.111296 \nL 753.964058 523.858333 \nL 756.119389 523.67332 \nL 757.197055 522.200255 \nL 758.274721 523.848221 \nL 759.352387 523.082819 \nL 760.430053 523.742773 \nL 761.507719 521.764762 \nL 762.585385 524.385624 \nL 763.663051 523.084471 \nL 764.740716 522.113711 \nL 765.818382 521.459116 \nL 766.896048 520.548836 \nL 767.973714 520.842143 \nL 769.05138 522.939816 \nL 770.129046 524.054131 \nL 771.206712 523.880745 \nL 772.284378 521.007125 \nL 773.362043 523.305819 \nL 775.517375 525.551248 \nL 776.595041 522.629498 \nL 777.672707 521.697511 \nL 778.750373 522.597761 \nL 779.828039 522.508054 \nL 780.905705 521.35014 \nL 781.983371 524.314023 \nL 783.061036 524.388786 \nL 784.138702 520.821593 \nL 785.216368 522.694775 \nL 786.294034 522.828452 \nL 786.294034 522.828452 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#pc525ec3503)\" d=\"M 76.112216 132.343518 \nL 78.267548 232.099452 \nL 80.422879 316.294948 \nL 82.578211 385.264056 \nL 83.655877 413.82494 \nL 84.733543 438.448612 \nL 85.811209 458.04976 \nL 86.888875 474.413353 \nL 87.966541 486.929879 \nL 89.044207 495.996702 \nL 90.121872 502.345965 \nL 91.199538 506.575481 \nL 92.277204 509.379951 \nL 93.35487 510.974844 \nL 94.432536 511.746564 \nL 95.510202 512.171959 \nL 96.587868 512.269549 \nL 98.743199 512.189588 \nL 99.820865 511.980202 \nL 107.364527 511.74102 \nL 108.442192 511.897667 \nL 109.519858 512.198883 \nL 112.752856 512.289975 \nL 115.985854 512.465501 \nL 117.06352 512.3915 \nL 119.218851 512.685581 \nL 120.296517 513.043546 \nL 122.451849 512.879263 \nL 134.306174 514.107026 \nL 135.38384 514.026014 \nL 137.539171 514.242641 \nL 142.927501 515.005772 \nL 144.005167 514.888189 \nL 145.082833 515.159938 \nL 146.160498 515.253419 \nL 147.238164 515.53518 \nL 148.31583 515.678832 \nL 149.393496 515.653975 \nL 150.471162 515.379095 \nL 151.548828 515.554845 \nL 153.70416 515.503033 \nL 154.781826 516.025999 \nL 155.859491 515.935921 \nL 156.937157 515.961156 \nL 158.014823 516.371471 \nL 159.092489 516.524077 \nL 160.170155 516.541149 \nL 161.247821 516.416816 \nL 163.403153 516.591111 \nL 164.480818 516.918996 \nL 166.63615 517.274071 \nL 167.713816 517.668161 \nL 168.791482 517.708556 \nL 169.869148 517.883055 \nL 170.946814 517.63914 \nL 172.02448 517.617816 \nL 174.179811 517.931748 \nL 175.257477 518.247784 \nL 176.335143 518.318951 \nL 177.412809 518.543671 \nL 178.490475 518.407147 \nL 180.645807 518.721308 \nL 182.801139 519.089217 \nL 183.878804 518.838637 \nL 184.95647 519.160069 \nL 186.034136 519.235289 \nL 187.111802 519.54544 \nL 189.267134 519.453221 \nL 191.422466 520.070441 \nL 192.500131 520.366966 \nL 193.577797 519.990407 \nL 194.655463 520.346825 \nL 195.733129 520.234984 \nL 196.810795 520.701782 \nL 197.888461 520.807899 \nL 198.966127 521.101912 \nL 200.043793 521.26221 \nL 201.121459 521.197961 \nL 203.27679 521.534979 \nL 205.432122 521.439067 \nL 207.587454 522.025972 \nL 209.742786 522.080983 \nL 210.820452 522.115307 \nL 211.898117 522.556716 \nL 214.053449 522.598447 \nL 215.131115 522.858946 \nL 216.208781 522.962829 \nL 217.286447 522.672727 \nL 218.364113 523.217307 \nL 219.441779 523.204047 \nL 220.519444 523.522093 \nL 221.59711 523.565167 \nL 222.674776 523.797338 \nL 223.752442 523.574567 \nL 224.830108 523.818062 \nL 225.907774 524.191199 \nL 226.98544 524.208915 \nL 228.063106 524.591582 \nL 229.140772 524.720322 \nL 230.218437 524.649563 \nL 231.296103 524.722543 \nL 233.451435 525.266455 \nL 237.762099 525.593202 \nL 238.839765 525.461115 \nL 239.91743 525.621091 \nL 240.995096 525.984922 \nL 242.072762 526.186939 \nL 244.228094 526.110939 \nL 251.771755 527.214208 \nL 252.849421 527.150305 \nL 253.927087 527.532224 \nL 258.23775 528.110782 \nL 259.315416 528.334005 \nL 260.393082 528.387202 \nL 261.470748 528.151876 \nL 262.548414 528.564276 \nL 263.62608 528.567196 \nL 264.703746 528.867502 \nL 267.936743 528.972258 \nL 270.092075 529.390617 \nL 271.169741 529.261196 \nL 275.480405 529.858374 \nL 276.558071 529.558278 \nL 277.635736 530.09219 \nL 281.9464 530.841486 \nL 285.179398 530.828509 \nL 286.257063 530.917461 \nL 287.334729 531.14965 \nL 288.412395 531.044889 \nL 289.490061 531.348505 \nL 290.567727 531.322281 \nL 291.645393 531.587749 \nL 295.956056 531.991752 \nL 298.111388 532.371566 \nL 301.344386 532.758398 \nL 303.499718 532.68499 \nL 305.655049 533.141683 \nL 307.810381 533.135947 \nL 308.888047 533.024348 \nL 309.965713 533.364449 \nL 313.198711 533.344759 \nL 316.431708 533.958705 \nL 317.509374 534.022756 \nL 319.664706 533.807466 \nL 320.742372 534.200566 \nL 322.897704 534.378531 \nL 323.975369 534.351174 \nL 327.208367 534.809823 \nL 328.286033 534.615745 \nL 329.363699 534.807502 \nL 330.441365 534.710383 \nL 331.519031 534.948568 \nL 334.752028 535.201493 \nL 336.90736 535.52415 \nL 337.985026 535.354904 \nL 339.062692 535.30691 \nL 341.218024 535.801925 \nL 343.373355 535.911315 \nL 344.451021 535.716489 \nL 346.606353 535.824883 \nL 347.684019 535.6462 \nL 348.761685 535.83982 \nL 349.839351 535.896078 \nL 350.917017 536.207952 \nL 353.072348 536.326166 \nL 354.150014 536.493874 \nL 355.22768 536.4187 \nL 358.460678 536.578225 \nL 359.538344 536.786089 \nL 360.61601 536.641004 \nL 361.693675 536.909591 \nL 363.849007 537.003978 \nL 370.315003 537.091902 \nL 371.392668 537.393208 \nL 372.470334 537.47474 \nL 373.548 537.382264 \nL 374.625666 537.518337 \nL 376.780998 537.42743 \nL 378.93633 537.681917 \nL 380.013995 537.543673 \nL 381.091661 537.593647 \nL 383.246993 537.929214 \nL 385.402325 537.947908 \nL 386.479991 537.636832 \nL 388.635323 538.150736 \nL 389.712988 538.135625 \nL 391.86832 538.317899 \nL 396.178984 538.173213 \nL 397.25665 538.023713 \nL 398.334316 538.075101 \nL 401.567313 538.658591 \nL 402.644979 538.494994 \nL 404.800311 538.696724 \nL 406.955643 538.708756 \nL 408.033308 538.817936 \nL 411.266306 538.824288 \nL 414.499304 538.938832 \nL 415.57697 538.512522 \nL 416.654636 538.943693 \nL 419.887633 538.979576 \nL 420.965299 539.125392 \nL 422.042965 539.058599 \nL 425.275963 539.146836 \nL 426.353629 539.053442 \nL 427.431294 539.314225 \nL 429.586626 539.170195 \nL 431.741958 539.409603 \nL 437.130287 539.297651 \nL 439.285619 539.393864 \nL 440.363285 539.367482 \nL 442.518617 539.618043 \nL 443.596283 539.449818 \nL 444.673949 539.588168 \nL 448.984612 539.6684 \nL 451.139944 539.743101 \nL 453.295276 539.659019 \nL 454.372942 539.806443 \nL 456.528273 539.613043 \nL 457.605939 539.904525 \nL 458.683605 539.681556 \nL 459.761271 539.703609 \nL 460.838937 539.926427 \nL 461.916603 539.730592 \nL 462.994269 539.912486 \nL 465.1496 539.913637 \nL 466.227266 540.029564 \nL 467.304932 540.023157 \nL 468.382598 539.763821 \nL 469.460264 540.005407 \nL 470.53793 539.898173 \nL 472.693262 540.118079 \nL 474.848593 539.965324 \nL 477.003925 540.09554 \nL 479.159257 540.062645 \nL 480.236923 539.941572 \nL 481.314589 540.005369 \nL 482.392255 539.9176 \nL 484.547586 540.343836 \nL 487.780584 540.092047 \nL 488.85825 540.22216 \nL 489.935916 540.158295 \nL 492.091247 540.32552 \nL 493.168913 540.005236 \nL 494.246579 540.279711 \nL 496.401911 540.437534 \nL 497.479577 540.193058 \nL 498.557243 540.283393 \nL 499.634909 540.236101 \nL 500.712575 540.326835 \nL 501.79024 540.290685 \nL 503.945572 540.491047 \nL 505.023238 540.345532 \nL 506.100904 540.468275 \nL 509.333902 540.371428 \nL 510.411568 540.568461 \nL 513.644565 540.561666 \nL 516.877563 540.401084 \nL 517.955229 540.281682 \nL 519.032895 540.555194 \nL 521.188226 540.382217 \nL 522.265892 540.53508 \nL 524.421224 540.301563 \nL 525.49889 540.531989 \nL 526.576556 540.445618 \nL 534.120217 540.606015 \nL 535.197883 540.470314 \nL 537.353215 540.592962 \nL 538.430881 540.374853 \nL 542.741544 540.636107 \nL 544.896876 540.597368 \nL 548.129874 540.620427 \nL 549.207539 540.439585 \nL 550.285205 540.566474 \nL 552.440537 540.640504 \nL 553.518203 540.653538 \nL 554.595869 540.849265 \nL 555.673535 540.75326 \nL 558.906532 540.77277 \nL 559.984198 540.579528 \nL 561.061864 540.775855 \nL 562.13953 540.707469 \nL 565.372528 540.824709 \nL 568.605525 540.685737 \nL 571.838523 540.773358 \nL 572.916189 540.609555 \nL 576.149187 540.813573 \nL 578.304518 540.905343 \nL 580.45985 540.884602 \nL 581.537516 540.720359 \nL 583.692848 540.842471 \nL 584.770514 540.750704 \nL 590.158843 540.89815 \nL 591.236509 540.766282 \nL 593.391841 540.894654 \nL 596.624838 540.729832 \nL 599.857836 540.941141 \nL 603.090834 540.791897 \nL 604.1685 540.948532 \nL 614.945158 540.830216 \nL 616.022824 540.70281 \nL 617.10049 540.865617 \nL 619.255822 540.742812 \nL 620.333488 540.916182 \nL 621.411154 540.86097 \nL 623.566485 540.932938 \nL 624.644151 540.756713 \nL 628.954815 541.039213 \nL 630.032481 540.807933 \nL 632.187813 541.016732 \nL 633.265478 540.777006 \nL 636.498476 541.03425 \nL 642.964471 540.969441 \nL 644.042137 541.047632 \nL 645.119803 540.927397 \nL 646.197469 541.025469 \nL 647.275135 540.888017 \nL 649.430467 540.869772 \nL 651.585798 541.074153 \nL 653.74113 541.120562 \nL 656.974128 540.974363 \nL 658.051794 541.00844 \nL 660.207126 540.778559 \nL 662.362457 541.113369 \nL 664.517789 541.048733 \nL 669.906119 540.997392 \nL 670.983784 540.808487 \nL 672.06145 541.093533 \nL 673.139116 541.080635 \nL 674.216782 540.943777 \nL 678.527446 541.208842 \nL 679.605111 541.035339 \nL 682.838109 540.974432 \nL 683.915775 541.151545 \nL 684.993441 541.153683 \nL 686.071107 540.955732 \nL 687.148773 541.12038 \nL 692.537102 540.753486 \nL 693.614768 541.086696 \nL 696.847766 540.983156 \nL 699.003097 541.02857 \nL 701.158429 540.95006 \nL 703.313761 541.086263 \nL 704.391427 541.151852 \nL 706.546759 540.890644 \nL 707.624424 541.063271 \nL 708.70209 540.827945 \nL 709.779756 541.007828 \nL 710.857422 540.867773 \nL 711.935088 541.107954 \nL 713.012754 541.147146 \nL 714.09042 541.045803 \nL 715.168086 541.146666 \nL 716.245752 541.017552 \nL 717.323417 541.123328 \nL 731.333074 540.984561 \nL 735.643737 541.064286 \nL 736.721403 540.8907 \nL 738.876735 541.067309 \nL 741.032067 540.868473 \nL 742.109733 541.104539 \nL 743.187399 540.968893 \nL 749.653394 541.12955 \nL 750.73106 540.866072 \nL 751.808726 541.083818 \nL 757.197055 541.021707 \nL 758.274721 540.916321 \nL 759.352387 541.075474 \nL 761.507719 541.054178 \nL 762.585385 540.911556 \nL 769.05138 541.102552 \nL 770.129046 540.979447 \nL 771.206712 541.021243 \nL 772.284378 540.892377 \nL 773.362043 541.105767 \nL 776.595041 541.209034 \nL 777.672707 541.108332 \nL 778.750373 541.160369 \nL 779.828039 540.875824 \nL 786.294034 541.019353 \nL 786.294034 541.019353 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 40.603125 565.918125 \nL 40.603125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 821.803125 565.918125 \nL 821.803125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 40.603125 565.918125 \nL 821.803125 565.918125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 40.603125 22.318125 \nL 821.803125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_18\">\n    <!-- Model MSE -->\n    <g transform=\"translate(398.503125 16.318125)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n      <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n      <path id=\"DejaVuSans-32\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-77\"/>\n     <use x=\"86.279297\" xlink:href=\"#DejaVuSans-111\"/>\n     <use x=\"147.460938\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"210.9375\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"272.460938\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"300.244141\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"332.03125\" xlink:href=\"#DejaVuSans-77\"/>\n     <use x=\"418.310547\" xlink:href=\"#DejaVuSans-83\"/>\n     <use x=\"481.787109\" xlink:href=\"#DejaVuSans-69\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 47.603125 59.674375 \nL 102.878125 59.674375 \nQ 104.878125 59.674375 104.878125 57.674375 \nL 104.878125 29.318125 \nQ 104.878125 27.318125 102.878125 27.318125 \nL 47.603125 27.318125 \nQ 45.603125 27.318125 45.603125 29.318125 \nL 45.603125 57.674375 \nQ 45.603125 59.674375 47.603125 59.674375 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_18\">\n     <path d=\"M 49.603125 35.416562 \nL 69.603125 35.416562 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_19\"/>\n    <g id=\"text_19\">\n     <!-- train -->\n     <g transform=\"translate(77.603125 38.916562)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n       <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n       <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n       <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n       <path d=\"M 54.890625 33.015625 \nL 54.890625 0 \nL 45.90625 0 \nL 45.90625 32.71875 \nQ 45.90625 40.484375 42.875 44.328125 \nQ 39.84375 48.1875 33.796875 48.1875 \nQ 26.515625 48.1875 22.3125 43.546875 \nQ 18.109375 38.921875 18.109375 30.90625 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 21.34375 51.125 25.703125 53.5625 \nQ 30.078125 56 35.796875 56 \nQ 45.21875 56 50.046875 50.171875 \nQ 54.890625 44.34375 54.890625 33.015625 \nz\n\" id=\"DejaVuSans-110\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"80.322266\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"141.601562\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"169.384766\" xlink:href=\"#DejaVuSans-110\"/>\n     </g>\n    </g>\n    <g id=\"line2d_20\">\n     <path d=\"M 49.603125 50.094687 \nL 69.603125 50.094687 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_21\"/>\n    <g id=\"text_20\">\n     <!-- test -->\n     <g transform=\"translate(77.603125 53.594687)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"39.208984\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"100.732422\" xlink:href=\"#DejaVuSans-115\"/>\n      <use x=\"152.832031\" xlink:href=\"#DejaVuSans-116\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pc525ec3503\">\n   <rect height=\"543.6\" width=\"781.2\" x=\"40.603125\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "11/11 [==============================] - 0s 728us/step\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}